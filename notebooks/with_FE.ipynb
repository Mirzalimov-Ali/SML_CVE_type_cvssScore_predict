{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f61dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e467514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\SML_Projects\\SML_CVE_type_cwe_predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0084885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f90519",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('data/preprocessed/preprocessed_x_train.csv')\n",
    "x_test = pd.read_csv('data/preprocessed/preprocessed_x_test.csv')\n",
    "\n",
    "y_train = pd.read_csv('data/split/y_train.csv')\n",
    "y_test = pd.read_csv('data/split/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e308f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c289fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcadd005",
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_types = y_train['type'].value_counts()\n",
    "rare_types = rare_types[rare_types < 3].index\n",
    "\n",
    "rare_cvss_scores = y_train['cvss_score'].value_counts()\n",
    "rare_cvss_scores = rare_cvss_scores[rare_cvss_scores < 3].index\n",
    "\n",
    "mask = (\n",
    "    (~y_train['type'].isin(rare_types)) &\n",
    "    (~y_train['cvss_score'].isin(rare_cvss_scores))\n",
    ")\n",
    "\n",
    "x_train = x_train[mask].reset_index(drop=True)\n",
    "y_train = y_train[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c873cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN type:\n",
      " type\n",
      "Other             30953\n",
      "XSS               15302\n",
      "InfoDisclosure     7784\n",
      "SQLi               6369\n",
      "RCE                5582\n",
      "DoS                4395\n",
      "CSRF               2000\n",
      "PathTraversal      2000\n",
      "PrivEsc            1580\n",
      "AuthBypass          957\n",
      "SSRF                733\n",
      "Name: count, dtype: int64\n",
      "TRAIN cvss:\n",
      " cvss_score\n",
      "Medium      39032\n",
      "High        27353\n",
      "Critical     7687\n",
      "Low          3583\n",
      "Name: count, dtype: int64\n",
      "TEST type:\n",
      " type\n",
      "Other             7699\n",
      "XSS               3883\n",
      "InfoDisclosure    1892\n",
      "SQLi              1551\n",
      "RCE               1448\n",
      "DoS               1104\n",
      "PathTraversal      508\n",
      "CSRF               483\n",
      "PrivEsc            357\n",
      "AuthBypass         266\n",
      "SSRF               223\n",
      "Name: count, dtype: int64\n",
      "TEST cvss:\n",
      " cvss_score\n",
      "Medium      9755\n",
      "High        6764\n",
      "Critical    1987\n",
      "Low          908\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN type:\\n\", y_train['type'].value_counts())\n",
    "print(\"TRAIN cvss:\\n\", y_train['cvss_score'].value_counts())\n",
    "\n",
    "print(\"TEST type:\\n\", y_test['type'].value_counts())\n",
    "print(\"TEST cvss:\\n\", y_test['cvss_score'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0efc8c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2967b0",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a58e9871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy for TYPE: 0.7809827959204698\n",
      "\n",
      "Precision for TYPE: 0.7830775736055254\n",
      "Recall for TYPE: 0.7216045026368297\n",
      "F1-score for TYPE: 0.7347641980050121\n",
      "\n",
      "K-Fold mean for TYPE: 0.7296981472306566\n",
      "K-Fold std for TYPE: 0.0013927753309158984\n",
      "\n",
      "Classification Report for TYPE:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    AuthBypass       0.52      0.06      0.11       266\n",
      "          CSRF       0.99      0.84      0.91       483\n",
      "           DoS       0.79      0.87      0.83      1104\n",
      "InfoDisclosure       0.34      0.37      0.35      1892\n",
      "         Other       0.75      0.78      0.76      7699\n",
      " PathTraversal       0.89      0.80      0.85       508\n",
      "       PrivEsc       0.74      0.71      0.72       357\n",
      "           RCE       0.83      0.71      0.77      1448\n",
      "          SQLi       1.00      0.97      0.98      1551\n",
      "          SSRF       0.83      0.87      0.85       223\n",
      "           XSS       0.95      0.95      0.95      3883\n",
      "\n",
      "      accuracy                           0.78     19414\n",
      "     macro avg       0.78      0.72      0.73     19414\n",
      "  weighted avg       0.78      0.78      0.78     19414\n",
      "\n",
      "\n",
      "========================================================================================\n",
      "\n",
      "Logistic Regression Accuracy for CVSS_SCORE: 0.5652106727104151\n",
      "\n",
      "Precision for CVSS_SCORE: 0.4773047875729124\n",
      "Recall for CVSS_SCORE: 0.301123255876824\n",
      "F1-score for CVSS_SCORE: 0.2659925912928526\n",
      "\n",
      "K-Fold mean for CVSS_SCORE: 0.33063105654991604\n",
      "K-Fold std for CVSS_SCORE: 0.003654843509840108\n",
      "\n",
      "Classification Report for CVSS_SCORE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.67      0.00      0.01      1987\n",
      "        High       0.59      0.25      0.35      6764\n",
      "         Low       0.09      0.00      0.00       908\n",
      "      Medium       0.56      0.95      0.71      9755\n",
      "\n",
      "    accuracy                           0.57     19414\n",
      "   macro avg       0.48      0.30      0.27     19414\n",
      "weighted avg       0.56      0.57      0.48     19414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "multi_lr = MultiOutputClassifier(lr)\n",
    "\n",
    "multi_lr.fit(x_train, y_train)\n",
    "y_pred = multi_lr.predict(x_test)\n",
    "\n",
    "#================[ Target - TYPE ]================\n",
    "lr_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "\n",
    "lr_precision_type = precision_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "lr_recall_type = recall_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "lr_f1_type = f1_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "\n",
    "lr_scores_type = cross_val_score(lr, x_train, y_train['type'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Logistic Regression Accuracy for TYPE: {lr_accuracy_type}')\n",
    "\n",
    "print(f'\\nPrecision for TYPE: {lr_precision_type}')\n",
    "print(f'Recall for TYPE: {lr_recall_type}')\n",
    "print(f'F1-score for TYPE: {lr_f1_type}')\n",
    "\n",
    "print(\"\\nK-Fold mean for TYPE:\", lr_scores_type.mean())\n",
    "print(\"K-Fold std for TYPE:\", lr_scores_type.std()) \n",
    "\n",
    "print(\"\\nClassification Report for TYPE:\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print('\\n========================================================================================')\n",
    "\n",
    "\n",
    "#================[ Target - CVSS_SCORE ]================\n",
    "lr_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "lr_precision_cvss_score = precision_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "lr_recall_cvss_score = recall_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "lr_f1_cvss_score = f1_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "\n",
    "lr_scores_cvss_score = cross_val_score(lr, x_train, y_train['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\nLogistic Regression Accuracy for CVSS_SCORE: {lr_accuracy_cvss_score}')\n",
    "\n",
    "print(f'\\nPrecision for CVSS_SCORE: {lr_precision_cvss_score}')\n",
    "print(f'Recall for CVSS_SCORE: {lr_recall_cvss_score}')\n",
    "print(f'F1-score for CVSS_SCORE: {lr_f1_cvss_score}')\n",
    "\n",
    "print(\"\\nK-Fold mean for CVSS_SCORE:\", lr_scores_cvss_score.mean())\n",
    "print(\"K-Fold std for CVSS_SCORE:\", lr_scores_cvss_score.std()) \n",
    "\n",
    "print(\"\\nClassification Report for CVSS_SCORE:\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccac186",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3f107db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDecisionTree Accuracy for TYPE: 0.8958998660760276\n",
      "\n",
      "Precision for TYPE: 0.882018247403296\n",
      "Recall for TYPE: 0.8717187261776363\n",
      "F1-score for TYPE: 0.8715562507120818\n",
      "\n",
      "K-Fold mean for TYPE: 0.9387253077073462\n",
      "K-Fold std for TYPE: 0.001061568633292554\n",
      "\n",
      "Classification Report for TYPE:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    AuthBypass       0.68      0.83      0.75       266\n",
      "          CSRF       0.99      0.98      0.98       483\n",
      "           DoS       0.93      0.58      0.72      1104\n",
      "InfoDisclosure       0.93      0.92      0.93      1892\n",
      "         Other       0.87      0.91      0.89      7699\n",
      " PathTraversal       0.91      0.94      0.93       508\n",
      "       PrivEsc       0.68      0.81      0.74       357\n",
      "           RCE       0.81      0.69      0.75      1448\n",
      "          SQLi       0.99      1.00      0.99      1551\n",
      "          SSRF       0.96      0.96      0.96       223\n",
      "           XSS       0.95      0.97      0.96      3883\n",
      "\n",
      "      accuracy                           0.90     19414\n",
      "     macro avg       0.88      0.87      0.87     19414\n",
      "  weighted avg       0.90      0.90      0.89     19414\n",
      "\n",
      "\n",
      "========================================================================================\n",
      "\n",
      "DecisionTree Accuracy for CVSS_SCORE: 0.45359019264448336\n",
      "\n",
      "Precision for CVSS_SCORE: 0.3578964067699749\n",
      "Recall for CVSS_SCORE: 0.39232239884237885\n",
      "F1-score for CVSS_SCORE: 0.36311024117301893\n",
      "\n",
      "K-Fold mean for CVSS_SCORE: 0.554507824812318\n",
      "K-Fold std for CVSS_SCORE: 0.0004176979554682895\n",
      "\n",
      "Classification Report for CVSS_SCORE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.23      0.29      0.26      1987\n",
      "        High       0.46      0.46      0.46      6764\n",
      "         Low       0.13      0.32      0.19       908\n",
      "      Medium       0.60      0.49      0.54      9755\n",
      "\n",
      "    accuracy                           0.45     19414\n",
      "   macro avg       0.36      0.39      0.36     19414\n",
      "weighted avg       0.49      0.45      0.47     19414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "multi_dt = MultiOutputClassifier(dt)\n",
    "\n",
    "multi_dt.fit(x_train, y_train)\n",
    "y_pred = multi_dt.predict(x_test)\n",
    "\n",
    "#================[ Target - TYPE ]================\n",
    "dt_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "\n",
    "dt_precision_type = precision_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "dt_recall_type = recall_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "dt_f1_type = f1_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "\n",
    "dt_scores_type = cross_val_score(dt, x_train, y_train['type'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'nDecisionTree Accuracy for TYPE: {dt_accuracy_type}')\n",
    "\n",
    "print(f'\\nPrecision for TYPE: {dt_precision_type}')\n",
    "print(f'Recall for TYPE: {dt_recall_type}')\n",
    "print(f'F1-score for TYPE: {dt_f1_type}')\n",
    "\n",
    "print(\"\\nK-Fold mean for TYPE:\", dt_scores_type.mean())\n",
    "print(\"K-Fold std for TYPE:\", dt_scores_type.std()) \n",
    "\n",
    "print(\"\\nClassification Report for TYPE:\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print('\\n========================================================================================')\n",
    "\n",
    "\n",
    "#================[ Target - CVSS_SCORE ]================\n",
    "dt_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "dt_precision_cvss_score = precision_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "dt_recall_cvss_score = recall_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "dt_f1_cvss_score = f1_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "\n",
    "dt_scores_cvss_score = cross_val_score(dt, x_train, y_train['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\nDecisionTree Accuracy for CVSS_SCORE: {dt_accuracy_cvss_score}')\n",
    "\n",
    "print(f'\\nPrecision for CVSS_SCORE: {dt_precision_cvss_score}')\n",
    "print(f'Recall for CVSS_SCORE: {dt_recall_cvss_score}')\n",
    "print(f'F1-score for CVSS_SCORE: {dt_f1_cvss_score}')\n",
    "\n",
    "print(\"\\nK-Fold mean for CVSS_SCORE:\", dt_scores_cvss_score.mean())\n",
    "print(\"K-Fold std for CVSS_SCORE:\", dt_scores_cvss_score.std()) \n",
    "\n",
    "print(\"\\nClassification Report for CVSS_SCORE:\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae481cb",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e83f05ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Accuracy for TYPE: 0.9404553415061296\n",
      "\n",
      "Precision for TYPE: 0.9359991212607962\n",
      "Recall for TYPE: 0.8723017247860199\n",
      "F1-score for TYPE: 0.8978052872631825\n",
      "\n",
      "K-Fold mean for TYPE: 0.9229909837957536\n",
      "K-Fold std for TYPE: 0.0015590338328815398\n",
      "\n",
      "Classification Report for TYPE:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    AuthBypass       0.96      0.56      0.71       266\n",
      "          CSRF       0.99      0.95      0.97       483\n",
      "           DoS       0.89      0.98      0.93      1104\n",
      "InfoDisclosure       0.88      0.92      0.90      1892\n",
      "         Other       0.94      0.95      0.95      7699\n",
      " PathTraversal       0.93      0.81      0.87       508\n",
      "       PrivEsc       0.83      0.73      0.78       357\n",
      "           RCE       0.95      0.87      0.91      1448\n",
      "          SQLi       1.00      0.99      0.99      1551\n",
      "          SSRF       0.96      0.83      0.89       223\n",
      "           XSS       0.96      0.98      0.97      3883\n",
      "\n",
      "      accuracy                           0.94     19414\n",
      "     macro avg       0.94      0.87      0.90     19414\n",
      "  weighted avg       0.94      0.94      0.94     19414\n",
      "\n",
      "\n",
      "========================================================================================\n",
      "\\RandomForest Accuracy for CVSS_SCORE: 0.6628206448954362\n",
      "\n",
      "Precision for CVSS_SCORE: 0.6958872214924484\n",
      "Recall for CVSS_SCORE: 0.4425809704811896\n",
      "F1-score for CVSS_SCORE: 0.4707702215053442\n",
      "\n",
      "K-Fold mean for CVSS_SCORE: 0.632817640348183\n",
      "K-Fold std for CVSS_SCORE: 0.0020947131843078934\n",
      "\n",
      "Classification Report for CVSS_SCORE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.68      0.23      0.34      1987\n",
      "        High       0.62      0.58      0.60      6764\n",
      "         Low       0.80      0.10      0.18       908\n",
      "      Medium       0.68      0.86      0.76      9755\n",
      "\n",
      "    accuracy                           0.66     19414\n",
      "   macro avg       0.70      0.44      0.47     19414\n",
      "weighted avg       0.67      0.66      0.63     19414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "multi_rf = MultiOutputClassifier(rf)\n",
    "\n",
    "multi_rf.fit(x_train, y_train)\n",
    "y_pred = multi_rf.predict(x_test)\n",
    "\n",
    "#================[ Target - TYPE ]================\n",
    "rf_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "\n",
    "rf_precision_type = precision_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "rf_recall_type = recall_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "rf_f1_type = f1_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "\n",
    "rf_scores_type = cross_val_score(rf, x_train, y_train['type'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'RandomForest Accuracy for TYPE: {rf_accuracy_type}')\n",
    "\n",
    "print(f'\\nPrecision for TYPE: {rf_precision_type}')\n",
    "print(f'Recall for TYPE: {rf_recall_type}')\n",
    "print(f'F1-score for TYPE: {rf_f1_type}')\n",
    "\n",
    "print(\"\\nK-Fold mean for TYPE:\", rf_scores_type.mean())\n",
    "print(\"K-Fold std for TYPE:\", rf_scores_type.std()) \n",
    "\n",
    "print(\"\\nClassification Report for TYPE:\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print('\\n========================================================================================')\n",
    "\n",
    "\n",
    "#================[ Target - CVSS_SCORE ]================\n",
    "rf_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "rf_precision_cvss_score = precision_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "rf_recall_cvss_score = recall_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "rf_f1_cvss_score = f1_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "\n",
    "rf_scores_cvss_score = cross_val_score(rf, x_train, y_train['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\RandomForest Accuracy for CVSS_SCORE: {rf_accuracy_cvss_score}')\n",
    "\n",
    "print(f'\\nPrecision for CVSS_SCORE: {rf_precision_cvss_score}')\n",
    "print(f'Recall for CVSS_SCORE: {rf_recall_cvss_score}')\n",
    "print(f'F1-score for CVSS_SCORE: {rf_f1_cvss_score}')\n",
    "\n",
    "print(\"\\nK-Fold mean for CVSS_SCORE:\", rf_scores_cvss_score.mean())\n",
    "print(\"K-Fold std for CVSS_SCORE:\", rf_scores_cvss_score.std()) \n",
    "\n",
    "print(\"\\nClassification Report for CVSS_SCORE:\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf91d951",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bc234d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting Accuracy for TYPE: 0.9457607911816215\n",
      "\n",
      "Precision for TYPE: 0.9419954574367527\n",
      "Recall for TYPE: 0.929884615438011\n",
      "F1-score for TYPE: 0.9338449862187244\n",
      "\n",
      "K-Fold mean for TYPE: 0.9624332855612724\n",
      "K-Fold std for TYPE: 0.0011524397255729584\n",
      "\n",
      "Classification Report for TYPE:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    AuthBypass       0.93      0.83      0.88       266\n",
      "          CSRF       0.93      0.99      0.96       483\n",
      "           DoS       0.98      0.75      0.85      1104\n",
      "InfoDisclosure       0.97      0.95      0.96      1892\n",
      "         Other       0.93      0.95      0.94      7699\n",
      " PathTraversal       0.94      0.96      0.95       508\n",
      "       PrivEsc       0.86      0.98      0.92       357\n",
      "           RCE       0.92      0.88      0.90      1448\n",
      "          SQLi       1.00      1.00      1.00      1551\n",
      "          SSRF       0.95      0.96      0.95       223\n",
      "           XSS       0.95      0.98      0.97      3883\n",
      "\n",
      "      accuracy                           0.95     19414\n",
      "     macro avg       0.94      0.93      0.93     19414\n",
      "  weighted avg       0.95      0.95      0.94     19414\n",
      "\n",
      "\n",
      "========================================================================================\n",
      "\\GradientBoosting Accuracy for CVSS_SCORE: 0.5423920881837849\n",
      "\n",
      "Precision for CVSS_SCORE: 0.4136093493434424\n",
      "Recall for CVSS_SCORE: 0.36980128735999107\n",
      "F1-score for CVSS_SCORE: 0.36465004787473027\n",
      "\n",
      "K-Fold mean for CVSS_SCORE: 0.6053698905323673\n",
      "K-Fold std for CVSS_SCORE: 0.0031151218293251405\n",
      "\n",
      "Classification Report for CVSS_SCORE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.33      0.26      0.29      1987\n",
      "        High       0.65      0.27      0.38      6764\n",
      "         Low       0.08      0.12      0.10       908\n",
      "      Medium       0.59      0.83      0.69      9755\n",
      "\n",
      "    accuracy                           0.54     19414\n",
      "   macro avg       0.41      0.37      0.36     19414\n",
      "weighted avg       0.56      0.54      0.51     19414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=220, max_depth=5, random_state=42)\n",
    "multi_gb = MultiOutputClassifier(gb)\n",
    "\n",
    "multi_gb.fit(x_train, y_train)\n",
    "y_pred = multi_gb.predict(x_test)\n",
    "\n",
    "#================[ Target - TYPE ]================\n",
    "gb_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "\n",
    "gb_precision_type = precision_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "gb_recall_type = recall_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "gb_f1_type = f1_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "\n",
    "gb_scores_type = cross_val_score(gb, x_train, y_train['type'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'GradientBoosting Accuracy for TYPE: {gb_accuracy_type}')\n",
    "\n",
    "print(f'\\nPrecision for TYPE: {gb_precision_type}')\n",
    "print(f'Recall for TYPE: {gb_recall_type}')\n",
    "print(f'F1-score for TYPE: {gb_f1_type}')\n",
    "\n",
    "print(\"\\nK-Fold mean for TYPE:\", gb_scores_type.mean())\n",
    "print(\"K-Fold std for TYPE:\", gb_scores_type.std()) \n",
    "\n",
    "print(\"\\nClassification Report for TYPE:\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print('\\n========================================================================================')\n",
    "\n",
    "\n",
    "#================[ Target - CVSS_SCORE ]================\n",
    "gb_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "gb_precision_cvss_score = precision_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "gb_recall_cvss_score = recall_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "gb_f1_cvss_score = f1_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "\n",
    "gb_scores_cvss_score = cross_val_score(gb, x_train, y_train['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\GradientBoosting Accuracy for CVSS_SCORE: {gb_accuracy_cvss_score}')\n",
    "\n",
    "print(f'\\nPrecision for CVSS_SCORE: {gb_precision_cvss_score}')\n",
    "print(f'Recall for CVSS_SCORE: {gb_recall_cvss_score}')\n",
    "print(f'F1-score for CVSS_SCORE: {gb_f1_cvss_score}')\n",
    "\n",
    "print(\"\\nK-Fold mean for CVSS_SCORE:\", gb_scores_cvss_score.mean())\n",
    "print(\"K-Fold std for CVSS_SCORE:\", gb_scores_cvss_score.std()) \n",
    "\n",
    "print(\"\\nClassification Report for CVSS_SCORE:\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a030b",
   "metadata": {},
   "source": [
    "# Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6f2ab3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees Accuracy for TYPE: 0.9278355825692799\n",
      "\n",
      "Precision for TYPE: 0.9228207283407179\n",
      "Recall for TYPE: 0.8472437873594164\n",
      "F1-score for TYPE: 0.8698675210365393\n",
      "\n",
      "K-Fold mean for TYPE: 0.899089314531488\n",
      "K-Fold std for TYPE: 0.002605582936667153\n",
      "\n",
      "Classification Report for TYPE:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    AuthBypass       0.93      0.31      0.47       266\n",
      "          CSRF       1.00      0.97      0.98       483\n",
      "           DoS       0.88      0.97      0.92      1104\n",
      "InfoDisclosure       0.84      0.89      0.86      1892\n",
      "         Other       0.92      0.96      0.94      7699\n",
      " PathTraversal       0.94      0.82      0.87       508\n",
      "       PrivEsc       0.82      0.73      0.77       357\n",
      "           RCE       0.94      0.86      0.90      1448\n",
      "          SQLi       1.00      0.99      0.99      1551\n",
      "          SSRF       0.92      0.87      0.89       223\n",
      "           XSS       0.97      0.95      0.96      3883\n",
      "\n",
      "      accuracy                           0.93     19414\n",
      "     macro avg       0.92      0.85      0.87     19414\n",
      "  weighted avg       0.93      0.93      0.93     19414\n",
      "\n",
      "\n",
      "========================================================================================\n",
      "\\ExtraTrees Accuracy for CVSS_SCORE: 0.6596785824662614\n",
      "\n",
      "Precision for CVSS_SCORE: 0.6060501175377868\n",
      "Recall for CVSS_SCORE: 0.479822661461751\n",
      "F1-score for CVSS_SCORE: 0.5085014123623909\n",
      "\n",
      "K-Fold mean for CVSS_SCORE: 0.6340692937509766\n",
      "K-Fold std for CVSS_SCORE: 0.0021332382181266703\n",
      "\n",
      "Classification Report for CVSS_SCORE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.68      0.24      0.35      1987\n",
      "        High       0.65      0.54      0.59      6764\n",
      "         Low       0.42      0.28      0.33       908\n",
      "      Medium       0.67      0.86      0.76      9755\n",
      "\n",
      "    accuracy                           0.66     19414\n",
      "   macro avg       0.61      0.48      0.51     19414\n",
      "weighted avg       0.65      0.66      0.64     19414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(random_state=42)\n",
    "multi_et = MultiOutputClassifier(et)\n",
    "\n",
    "multi_et.fit(x_train, y_train)\n",
    "y_pred = multi_et.predict(x_test)\n",
    "\n",
    "#================[ Target - TYPE ]================\n",
    "et_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "\n",
    "et_precision_type = precision_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "et_recall_type = recall_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "et_f1_type = f1_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "\n",
    "et_scores_type = cross_val_score(et, x_train, y_train['type'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'ExtraTrees Accuracy for TYPE: {et_accuracy_type}')\n",
    "\n",
    "print(f'\\nPrecision for TYPE: {et_precision_type}')\n",
    "print(f'Recall for TYPE: {et_recall_type}')\n",
    "print(f'F1-score for TYPE: {et_f1_type}')\n",
    "\n",
    "print(\"\\nK-Fold mean for TYPE:\", et_scores_type.mean())\n",
    "print(\"K-Fold std for TYPE:\", et_scores_type.std()) \n",
    "\n",
    "print(\"\\nClassification Report for TYPE:\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print('\\n========================================================================================')\n",
    "\n",
    "\n",
    "#================[ Target - CVSS_SCORE ]================\n",
    "et_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "et_precision_cvss_score = precision_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "et_recall_cvss_score = recall_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "et_f1_cvss_score = f1_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "\n",
    "et_scores_cvss_score = cross_val_score(et, x_train, y_train['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\ExtraTrees Accuracy for CVSS_SCORE: {et_accuracy_cvss_score}')\n",
    "\n",
    "print(f'\\nPrecision for CVSS_SCORE: {et_precision_cvss_score}')\n",
    "print(f'Recall for CVSS_SCORE: {et_recall_cvss_score}')\n",
    "print(f'F1-score for CVSS_SCORE: {et_f1_cvss_score}')\n",
    "\n",
    "print(\"\\nK-Fold mean for CVSS_SCORE:\", et_scores_cvss_score.mean())\n",
    "print(\"K-Fold std for CVSS_SCORE:\", et_scores_cvss_score.std()) \n",
    "\n",
    "print(\"\\nClassification Report for CVSS_SCORE:\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c653280",
   "metadata": {},
   "source": [
    "# Hist Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "291338f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoosting Accuracy for TYPE: 0.3265684557535799\n",
      "\n",
      "Precision for TYPE: 0.35416309168631166\n",
      "Recall for TYPE: 0.12759496868057285\n",
      "F1-score for TYPE: 0.12848258423773154\n",
      "\n",
      "K-Fold mean for TYPE: 0.8967407066638594\n",
      "K-Fold std for TYPE: 0.043455840729966916\n",
      "\n",
      "Classification Report for TYPE:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    AuthBypass       0.05      0.00      0.01       266\n",
      "          CSRF       0.02      0.02      0.02       483\n",
      "           DoS       0.53      0.13      0.21      1104\n",
      "InfoDisclosure       0.16      0.15      0.16      1892\n",
      "         Other       0.39      0.67      0.49      7699\n",
      " PathTraversal       0.03      0.16      0.05       508\n",
      "       PrivEsc       0.61      0.03      0.06       357\n",
      "           RCE       0.57      0.09      0.15      1448\n",
      "          SQLi       0.95      0.03      0.05      1551\n",
      "          SSRF       0.14      0.00      0.01       223\n",
      "           XSS       0.44      0.14      0.21      3883\n",
      "\n",
      "      accuracy                           0.33     19414\n",
      "     macro avg       0.35      0.13      0.13     19414\n",
      "  weighted avg       0.42      0.33      0.28     19414\n",
      "\n",
      "\n",
      "========================================================================================\n",
      "\\HistGradientBoosting Accuracy for CVSS_SCORE: 0.6397960234882044\n",
      "\n",
      "Precision for CVSS_SCORE: 0.5350351494212996\n",
      "Recall for CVSS_SCORE: 0.41897180157398783\n",
      "F1-score for CVSS_SCORE: 0.43626244200405034\n",
      "\n",
      "K-Fold mean for CVSS_SCORE: 0.6194409516634576\n",
      "K-Fold std for CVSS_SCORE: 0.0026868775685079034\n",
      "\n",
      "Classification Report for CVSS_SCORE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.59      0.19      0.29      1987\n",
      "        High       0.60      0.57      0.58      6764\n",
      "         Low       0.28      0.08      0.13       908\n",
      "      Medium       0.67      0.83      0.74      9755\n",
      "\n",
      "    accuracy                           0.64     19414\n",
      "   macro avg       0.54      0.42      0.44     19414\n",
      "weighted avg       0.62      0.64      0.61     19414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hgb = HistGradientBoostingClassifier(max_iter=200, random_state=42)\n",
    "multi_hgb = MultiOutputClassifier(hgb)\n",
    "\n",
    "multi_hgb.fit(x_train, y_train)\n",
    "y_pred = multi_hgb.predict(x_test)\n",
    "\n",
    "#================[ Target - TYPE ]================\n",
    "hgb_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "\n",
    "hgb_precision_type = precision_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "hgb_recall_type = recall_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "hgb_f1_type = f1_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "\n",
    "hgb_scores_type = cross_val_score(hgb, x_train, y_train['type'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'HistGradientBoosting Accuracy for TYPE: {hgb_accuracy_type}')\n",
    "\n",
    "print(f'\\nPrecision for TYPE: {hgb_precision_type}')\n",
    "print(f'Recall for TYPE: {hgb_recall_type}')\n",
    "print(f'F1-score for TYPE: {hgb_f1_type}')\n",
    "\n",
    "print(\"\\nK-Fold mean for TYPE:\", hgb_scores_type.mean())\n",
    "print(\"K-Fold std for TYPE:\", hgb_scores_type.std()) \n",
    "\n",
    "print(\"\\nClassification Report for TYPE:\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print('\\n========================================================================================')\n",
    "\n",
    "\n",
    "#================[ Target - CVSS_SCORE ]================\n",
    "hgb_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "hgb_precision_cvss_score = precision_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "hgb_recall_cvss_score = recall_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "hgb_f1_cvss_score = f1_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "\n",
    "hgb_scores_cvss_score = cross_val_score(hgb, x_train, y_train['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\HistGradientBoosting Accuracy for CVSS_SCORE: {hgb_accuracy_cvss_score}')\n",
    "\n",
    "print(f'\\nPrecision for CVSS_SCORE: {hgb_precision_cvss_score}')\n",
    "print(f'Recall for CVSS_SCORE: {hgb_recall_cvss_score}')\n",
    "print(f'F1-score for CVSS_SCORE: {hgb_f1_cvss_score}')\n",
    "\n",
    "print(\"\\nK-Fold mean for CVSS_SCORE:\", hgb_scores_cvss_score.mean())\n",
    "print(\"K-Fold std for CVSS_SCORE:\", hgb_scores_cvss_score.std()) \n",
    "\n",
    "print(\"\\nClassification Report for CVSS_SCORE:\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562983b6",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3e42f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = KNeighborsClassifier(n_neighbors=1)\n",
    "# multi_knn = MultiOutputClassifier(knn)\n",
    "\n",
    "# multi_knn.fit(x_train, y_train)\n",
    "# y_pred = multi_knn.predict(x_test)\n",
    "\n",
    "# knn_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "# knn_accuracy_cvss_score  = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "# knn_scores_type = cross_val_score(knn, x, y['type'], cv=kf, scoring='f1_macro')\n",
    "# knn_scores_cvss_score  = cross_val_score(knn, x, y['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "# print(\"KNN Accuracy for 'type':\", knn_accuracy_type)\n",
    "# print(\"KNN Accuracy for 'cvss_score' :\", knn_accuracy_cvss_score)\n",
    "\n",
    "# print(\"K-Fold mean F1 (type):\", knn_scores_type.mean())\n",
    "# print(\"K-Fold std  F1 (type):\", knn_scores_type.std())\n",
    "\n",
    "# print(\"K-Fold mean F1 (cvss_score):\", knn_scores_cvss_score.mean())\n",
    "# print(\"K-Fold std  F1 (cvss_score):\", knn_scores_cvss_score.std())\n",
    "\n",
    "# print(\"\\nClassification Report for 'type':\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "# print(\"\\nClassification Report for 'cvss_score':\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3ed620",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b730e8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy for TYPE: 0.8046255279695066\n",
      "\n",
      "Precision for TYPE: 0.8222754509857615\n",
      "Recall for TYPE: 0.6497081204026425\n",
      "F1-score for TYPE: 0.7066035962584457\n",
      "\n",
      "K-Fold mean for TYPE: 0.6955231434779016\n",
      "K-Fold std for TYPE: 0.04839976092655427\n",
      "\n",
      "Classification Report for TYPE:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    AuthBypass       0.60      0.34      0.44       266\n",
      "          CSRF       0.94      0.85      0.89       483\n",
      "           DoS       0.80      0.23      0.36      1104\n",
      "InfoDisclosure       0.78      0.56      0.65      1892\n",
      "         Other       0.72      0.95      0.82      7699\n",
      " PathTraversal       0.93      0.63      0.75       508\n",
      "       PrivEsc       0.64      0.38      0.47       357\n",
      "           RCE       0.75      0.47      0.58      1448\n",
      "          SQLi       1.00      0.97      0.98      1551\n",
      "          SSRF       0.94      0.82      0.88       223\n",
      "           XSS       0.96      0.94      0.95      3883\n",
      "\n",
      "      accuracy                           0.80     19414\n",
      "     macro avg       0.82      0.65      0.71     19414\n",
      "  weighted avg       0.81      0.80      0.79     19414\n",
      "\n",
      "\n",
      "========================================================================================\n",
      "\\AdaBoost Accuracy for CVSS_SCORE: 0.5869475636138869\n",
      "\n",
      "Precision for CVSS_SCORE: 0.3356251895548405\n",
      "Recall for CVSS_SCORE: 0.3248736197007724\n",
      "F1-score for CVSS_SCORE: 0.2984527876441252\n",
      "\n",
      "K-Fold mean for CVSS_SCORE: 0.30725875769620786\n",
      "K-Fold std for CVSS_SCORE: 0.0025975382461631844\n",
      "\n",
      "Classification Report for CVSS_SCORE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.20      0.00      0.00      1987\n",
      "        High       0.54      0.42      0.47      6764\n",
      "         Low       0.00      0.00      0.00       908\n",
      "      Medium       0.61      0.88      0.72      9755\n",
      "\n",
      "    accuracy                           0.59     19414\n",
      "   macro avg       0.34      0.32      0.30     19414\n",
      "weighted avg       0.51      0.59      0.53     19414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier(n_estimators=200)\n",
    "multi_ab = MultiOutputClassifier(ab)\n",
    "\n",
    "multi_ab.fit(x_train, y_train)\n",
    "y_pred = multi_ab.predict(x_test)\n",
    "\n",
    "#================[ Target - TYPE ]================\n",
    "ab_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "\n",
    "ab_precision_type = precision_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "ab_recall_type = recall_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "ab_f1_type = f1_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "\n",
    "ab_scores_type = cross_val_score(ab, x_train, y_train['type'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'AdaBoost Accuracy for TYPE: {ab_accuracy_type}')\n",
    "\n",
    "print(f'\\nPrecision for TYPE: {ab_precision_type}')\n",
    "print(f'Recall for TYPE: {ab_recall_type}')\n",
    "print(f'F1-score for TYPE: {ab_f1_type}')\n",
    "\n",
    "print(\"\\nK-Fold mean for TYPE:\", ab_scores_type.mean())\n",
    "print(\"K-Fold std for TYPE:\", ab_scores_type.std()) \n",
    "\n",
    "print(\"\\nClassification Report for TYPE:\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print('\\n========================================================================================')\n",
    "\n",
    "\n",
    "#================[ Target - CVSS_SCORE ]================\n",
    "ab_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "ab_precision_cvss_score = precision_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "ab_recall_cvss_score = recall_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "ab_f1_cvss_score = f1_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "\n",
    "ab_scores_cvss_score = cross_val_score(ab, x_train, y_train['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\AdaBoost Accuracy for CVSS_SCORE: {ab_accuracy_cvss_score}')\n",
    "\n",
    "print(f'\\nPrecision for CVSS_SCORE: {ab_precision_cvss_score}')\n",
    "print(f'Recall for CVSS_SCORE: {ab_recall_cvss_score}')\n",
    "print(f'F1-score for CVSS_SCORE: {ab_f1_cvss_score}')\n",
    "\n",
    "print(\"\\nK-Fold mean for CVSS_SCORE:\", ab_scores_cvss_score.mean())\n",
    "print(\"K-Fold std for CVSS_SCORE:\", ab_scores_cvss_score.std()) \n",
    "\n",
    "print(\"\\nClassification Report for CVSS_SCORE:\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd368705",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e947d290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3107\n",
      "[LightGBM] [Info] Number of data points in the train set: 77655, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -4.396228\n",
      "[LightGBM] [Info] Start training from score -3.659129\n",
      "[LightGBM] [Info] Start training from score -2.871808\n",
      "[LightGBM] [Info] Start training from score -2.300206\n",
      "[LightGBM] [Info] Start training from score -0.919806\n",
      "[LightGBM] [Info] Start training from score -3.659129\n",
      "[LightGBM] [Info] Start training from score -3.894851\n",
      "[LightGBM] [Info] Start training from score -2.632729\n",
      "[LightGBM] [Info] Start training from score -2.500833\n",
      "[LightGBM] [Info] Start training from score -4.662886\n",
      "[LightGBM] [Info] Start training from score -1.624292\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3107\n",
      "[LightGBM] [Info] Number of data points in the train set: 77655, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -2.312745\n",
      "[LightGBM] [Info] Start training from score -1.043450\n",
      "[LightGBM] [Info] Start training from score -3.076076\n",
      "[LightGBM] [Info] Start training from score -0.687894\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3094\n",
      "[LightGBM] [Info] Number of data points in the train set: 51770, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -4.405677\n",
      "[LightGBM] [Info] Start training from score -3.681374\n",
      "[LightGBM] [Info] Start training from score -2.880722\n",
      "[LightGBM] [Info] Start training from score -2.293930\n",
      "[LightGBM] [Info] Start training from score -0.923853\n",
      "[LightGBM] [Info] Start training from score -3.657880\n",
      "[LightGBM] [Info] Start training from score -3.907590\n",
      "[LightGBM] [Info] Start training from score -2.628795\n",
      "[LightGBM] [Info] Start training from score -2.488661\n",
      "[LightGBM] [Info] Start training from score -4.719001\n",
      "[LightGBM] [Info] Start training from score -1.616124\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3099\n",
      "[LightGBM] [Info] Number of data points in the train set: 51770, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -4.386867\n",
      "[LightGBM] [Info] Start training from score -3.654141\n",
      "[LightGBM] [Info] Start training from score -2.886247\n",
      "[LightGBM] [Info] Start training from score -2.292017\n",
      "[LightGBM] [Info] Start training from score -0.917402\n",
      "[LightGBM] [Info] Start training from score -3.682909\n",
      "[LightGBM] [Info] Start training from score -3.862470\n",
      "[LightGBM] [Info] Start training from score -2.639019\n",
      "[LightGBM] [Info] Start training from score -2.507924\n",
      "[LightGBM] [Info] Start training from score -4.662204\n",
      "[LightGBM] [Info] Start training from score -1.625600\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3100\n",
      "[LightGBM] [Info] Number of data points in the train set: 51770, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -4.396228\n",
      "[LightGBM] [Info] Start training from score -3.642272\n",
      "[LightGBM] [Info] Start training from score -2.848865\n",
      "[LightGBM] [Info] Start training from score -2.314829\n",
      "[LightGBM] [Info] Start training from score -0.918176\n",
      "[LightGBM] [Info] Start training from score -3.637123\n",
      "[LightGBM] [Info] Start training from score -3.915312\n",
      "[LightGBM] [Info] Start training from score -2.630403\n",
      "[LightGBM] [Info] Start training from score -2.506028\n",
      "[LightGBM] [Info] Start training from score -4.610399\n",
      "[LightGBM] [Info] Start training from score -1.631211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Accuracy for TYPE: 0.9543113217265891\n",
      "\n",
      "Precision for TYPE: 0.94639254063812\n",
      "Recall for TYPE: 0.9437201996998024\n",
      "F1-score for TYPE: 0.9432269771432441\n",
      "\n",
      "K-Fold mean for TYPE: 0.9568510110847906\n",
      "K-Fold std for TYPE: 0.001402370480932786\n",
      "\n",
      "Classification Report for TYPE:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    AuthBypass       0.97      0.78      0.87       266\n",
      "          CSRF       0.99      0.98      0.99       483\n",
      "           DoS       0.91      0.95      0.93      1104\n",
      "InfoDisclosure       0.98      0.90      0.94      1892\n",
      "         Other       0.95      0.96      0.95      7699\n",
      " PathTraversal       0.89      0.98      0.93       508\n",
      "       PrivEsc       0.85      0.97      0.90       357\n",
      "           RCE       0.95      0.89      0.92      1448\n",
      "          SQLi       1.00      1.00      1.00      1551\n",
      "          SSRF       0.96      0.98      0.97       223\n",
      "           XSS       0.97      0.98      0.97      3883\n",
      "\n",
      "      accuracy                           0.95     19414\n",
      "     macro avg       0.95      0.94      0.94     19414\n",
      "  weighted avg       0.96      0.95      0.95     19414\n",
      "\n",
      "\n",
      "========================================================================================\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3094\n",
      "[LightGBM] [Info] Number of data points in the train set: 51770, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -2.327225\n",
      "[LightGBM] [Info] Start training from score -1.041715\n",
      "[LightGBM] [Info] Start training from score -3.063870\n",
      "[LightGBM] [Info] Start training from score -0.687407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3099\n",
      "[LightGBM] [Info] Number of data points in the train set: 51770, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -2.306456\n",
      "[LightGBM] [Info] Start training from score -1.046104\n",
      "[LightGBM] [Info] Start training from score -3.094099\n",
      "[LightGBM] [Info] Start training from score -0.685642\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3100\n",
      "[LightGBM] [Info] Number of data points in the train set: 51770, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -2.304712\n",
      "[LightGBM] [Info] Start training from score -1.042536\n",
      "[LightGBM] [Info] Start training from score -3.070509\n",
      "[LightGBM] [Info] Start training from score -0.690639\n",
      "\\LightGBM Accuracy for CVSS_SCORE: 0.6426290305964768\n",
      "\n",
      "Precision for CVSS_SCORE: 0.5313848451553298\n",
      "Recall for CVSS_SCORE: 0.4259194968361059\n",
      "F1-score for CVSS_SCORE: 0.43948311968277987\n",
      "\n",
      "K-Fold mean for CVSS_SCORE: 0.6013735931192534\n",
      "K-Fold std for CVSS_SCORE: 0.004576980613719931\n",
      "\n",
      "Classification Report for CVSS_SCORE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.54      0.32      0.40      1987\n",
      "        High       0.71      0.42      0.53      6764\n",
      "         Low       0.24      0.04      0.07       908\n",
      "      Medium       0.64      0.92      0.75      9755\n",
      "\n",
      "    accuracy                           0.64     19414\n",
      "   macro avg       0.53      0.43      0.44     19414\n",
      "weighted avg       0.63      0.64      0.61     19414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "multi_lgbm = MultiOutputClassifier(lgbm)\n",
    "\n",
    "multi_lgbm.fit(x_train, y_train)\n",
    "y_pred = multi_lgbm.predict(x_test)\n",
    "\n",
    "#================[ Target - TYPE ]================\n",
    "lgbm_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "\n",
    "lgbm_precision_type = precision_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "lgbm_recall_type = recall_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "lgbm_f1_type = f1_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "\n",
    "lgbm_scores_type = cross_val_score(lgbm, x_train, y_train['type'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'LightGBM Accuracy for TYPE: {lgbm_accuracy_type}')\n",
    "\n",
    "print(f'\\nPrecision for TYPE: {lgbm_precision_type}')\n",
    "print(f'Recall for TYPE: {lgbm_recall_type}')\n",
    "print(f'F1-score for TYPE: {lgbm_f1_type}')\n",
    "\n",
    "print(\"\\nK-Fold mean for TYPE:\", lgbm_scores_type.mean())\n",
    "print(\"K-Fold std for TYPE:\", lgbm_scores_type.std()) \n",
    "\n",
    "print(\"\\nClassification Report for TYPE:\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print('\\n========================================================================================')\n",
    "\n",
    "\n",
    "#================[ Target - CVSS_SCORE ]================\n",
    "lgbm_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "lgbm_precision_cvss_score = precision_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "lgbm_recall_cvss_score = recall_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "lgbm_f1_cvss_score = f1_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "\n",
    "lgbm_scores_cvss_score = cross_val_score(lgbm, x_train, y_train['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\LightGBM Accuracy for CVSS_SCORE: {lgbm_accuracy_cvss_score}')\n",
    "\n",
    "print(f'\\nPrecision for CVSS_SCORE: {lgbm_precision_cvss_score}')\n",
    "print(f'Recall for CVSS_SCORE: {lgbm_recall_cvss_score}')\n",
    "print(f'F1-score for CVSS_SCORE: {lgbm_f1_cvss_score}')\n",
    "\n",
    "print(\"\\nK-Fold mean for CVSS_SCORE:\", lgbm_scores_cvss_score.mean())\n",
    "print(\"K-Fold std for CVSS_SCORE:\", lgbm_scores_cvss_score.std()) \n",
    "\n",
    "print(\"\\nClassification Report for CVSS_SCORE:\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a83138e",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f0f10f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy for TYPE: 0.9221180591325847\n",
      "\n",
      "Precision for TYPE: 0.9137811106928514\n",
      "Recall for TYPE: 0.8961460610607715\n",
      "F1-score for TYPE: 0.9028335329368681\n",
      "\n",
      "K-Fold mean for TYPE: 0.9487238216758639\n",
      "K-Fold std for TYPE: 0.001423554136301106\n",
      "\n",
      "Classification Report for TYPE:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    AuthBypass       0.74      0.83      0.78       266\n",
      "          CSRF       0.99      0.98      0.99       483\n",
      "           DoS       0.90      0.66      0.76      1104\n",
      "InfoDisclosure       0.94      0.93      0.93      1892\n",
      "         Other       0.90      0.94      0.92      7699\n",
      " PathTraversal       0.94      0.95      0.94       508\n",
      "       PrivEsc       0.86      0.84      0.85       357\n",
      "           RCE       0.87      0.79      0.83      1448\n",
      "          SQLi       1.00      1.00      1.00      1551\n",
      "          SSRF       0.95      0.96      0.96       223\n",
      "           XSS       0.97      0.98      0.97      3883\n",
      "\n",
      "      accuracy                           0.92     19414\n",
      "     macro avg       0.91      0.90      0.90     19414\n",
      "  weighted avg       0.92      0.92      0.92     19414\n",
      "\n",
      "\n",
      "========================================================================================\n",
      "\\Bagging Accuracy for CVSS_SCORE: 0.5401771917173174\n",
      "\n",
      "Precision for CVSS_SCORE: 0.4294581908778615\n",
      "Recall for CVSS_SCORE: 0.4004706122261127\n",
      "F1-score for CVSS_SCORE: 0.40674190747911\n",
      "\n",
      "K-Fold mean for CVSS_SCORE: 0.6166134226234404\n",
      "K-Fold std for CVSS_SCORE: 0.0031720042238938127\n",
      "\n",
      "Classification Report for CVSS_SCORE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.33      0.31      0.32      1987\n",
      "        High       0.48      0.57      0.52      6764\n",
      "         Low       0.26      0.11      0.16       908\n",
      "      Medium       0.65      0.60      0.63      9755\n",
      "\n",
      "    accuracy                           0.54     19414\n",
      "   macro avg       0.43      0.40      0.41     19414\n",
      "weighted avg       0.54      0.54      0.54     19414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging = BaggingClassifier(random_state=42)\n",
    "multi_bag = MultiOutputClassifier(bagging)\n",
    "\n",
    "multi_bag.fit(x_train, y_train)\n",
    "y_pred = multi_bag.predict(x_test)\n",
    "\n",
    "#================[ Target - TYPE ]================\n",
    "bagging_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "\n",
    "bagging_precision_type = precision_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "bagging_recall_type = recall_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "bagging_f1_type = f1_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "\n",
    "bagging_scores_type = cross_val_score(bagging, x_train, y_train['type'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Bagging Accuracy for TYPE: {bagging_accuracy_type}')\n",
    "\n",
    "print(f'\\nPrecision for TYPE: {bagging_precision_type}')\n",
    "print(f'Recall for TYPE: {bagging_recall_type}')\n",
    "print(f'F1-score for TYPE: {bagging_f1_type}')\n",
    "\n",
    "print(\"\\nK-Fold mean for TYPE:\", bagging_scores_type.mean())\n",
    "print(\"K-Fold std for TYPE:\", bagging_scores_type.std()) \n",
    "\n",
    "print(\"\\nClassification Report for TYPE:\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print('\\n========================================================================================')\n",
    "\n",
    "\n",
    "#================[ Target - CVSS_SCORE ]================\n",
    "bagging_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "bagging_precision_cvss_score = precision_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "bagging_recall_cvss_score = recall_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "bagging_f1_cvss_score = f1_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "\n",
    "bagging_scores_cvss_score = cross_val_score(bagging, x_train, y_train['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\Bagging Accuracy for CVSS_SCORE: {bagging_accuracy_cvss_score}')\n",
    "\n",
    "print(f'\\nPrecision for CVSS_SCORE: {bagging_precision_cvss_score}')\n",
    "print(f'Recall for CVSS_SCORE: {bagging_recall_cvss_score}')\n",
    "print(f'F1-score for CVSS_SCORE: {bagging_f1_cvss_score}')\n",
    "\n",
    "print(\"\\nK-Fold mean for CVSS_SCORE:\", bagging_scores_cvss_score.mean())\n",
    "print(\"K-Fold std for CVSS_SCORE:\", bagging_scores_cvss_score.std()) \n",
    "\n",
    "print(\"\\nClassification Report for CVSS_SCORE:\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506b3d61",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd3034d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# svc = SVC(kernel='rbf', C=5, probability=True)\n",
    "# multi_svc = MultiOutputClassifier(svc)\n",
    "\n",
    "# multi_svc.fit(x_train, y_train)\n",
    "# y_pred = multi_svc.predict(x_test)\n",
    "\n",
    "# svc_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "# svc_accuracy_cvss_score  = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "# svc_scores_type = cross_val_score(svc, x, y['type'], cv=kf, scoring='f1_macro')\n",
    "# svc_scores_cvss_score  = cross_val_score(svc, x, y['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "# print(\"SVC Accuracy for 'type':\", svc_accuracy_type)\n",
    "# print(\"SVC Accuracy for 'cvss_score' :\", svc_accuracy_cvss_score)\n",
    "\n",
    "# print(\"K-Fold mean F1 (type):\", svc_scores_type.mean())\n",
    "# print(\"K-Fold std  F1 (type):\", svc_scores_type.std())\n",
    "\n",
    "# print(\"K-Fold mean F1 (cvss_score):\", svc_scores_cvss_score.mean())\n",
    "# print(\"K-Fold std  F1 (cvss_score):\", svc_scores_cvss_score.std())\n",
    "\n",
    "# print(\"\\nClassification Report for 'type':\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "# print(\"\\nClassification Report for 'cvss_score':\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cbfac5",
   "metadata": {},
   "source": [
    "# Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d03ffb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HardBoting Accuracy for TYPE: 0.9313897187596579\n",
      "\n",
      "Precision for TYPE: 0.930837516869751\n",
      "Recall for TYPE: 0.8733443326868553\n",
      "F1-score for TYPE: 0.8973952144281754\n",
      "\n",
      "K-Fold mean for TYPE: 0.9181674770480633\n",
      "K-Fold std for TYPE: 0.0020231828381425585\n",
      "\n",
      "Classification Report for TYPE:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    AuthBypass       0.97      0.63      0.76       266\n",
      "          CSRF       0.99      0.95      0.97       483\n",
      "           DoS       0.87      0.98      0.92      1104\n",
      "InfoDisclosure       0.88      0.90      0.89      1892\n",
      "         Other       0.92      0.95      0.94      7699\n",
      " PathTraversal       0.93      0.81      0.86       508\n",
      "       PrivEsc       0.81      0.72      0.77       357\n",
      "           RCE       0.95      0.85      0.90      1448\n",
      "          SQLi       1.00      0.99      0.99      1551\n",
      "          SSRF       0.95      0.87      0.91       223\n",
      "           XSS       0.96      0.95      0.96      3883\n",
      "\n",
      "      accuracy                           0.93     19414\n",
      "     macro avg       0.93      0.87      0.90     19414\n",
      "  weighted avg       0.93      0.93      0.93     19414\n",
      "\n",
      "\n",
      "========================================================================================\n",
      "\\HardBoting Accuracy for CVSS_SCORE: 0.6662717626455136\n",
      "\n",
      "Precision for CVSS_SCORE: 0.7211620758889172\n",
      "Recall for CVSS_SCORE: 0.4464150690585929\n",
      "F1-score for CVSS_SCORE: 0.4808606818823907\n",
      "\n",
      "K-Fold mean for CVSS_SCORE: 0.6273660389683728\n",
      "K-Fold std for CVSS_SCORE: 0.00142376913090258\n",
      "\n",
      "Classification Report for CVSS_SCORE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.67      0.23      0.34      1987\n",
      "        High       0.69      0.50      0.58      6764\n",
      "         Low       0.87      0.14      0.24       908\n",
      "      Medium       0.66      0.92      0.77      9755\n",
      "\n",
      "    accuracy                           0.67     19414\n",
      "   macro avg       0.72      0.45      0.48     19414\n",
      "weighted avg       0.68      0.67      0.63     19414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "model1 = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model2 = ExtraTreesClassifier(n_estimators=200, random_state=42)\n",
    "model3 = LogisticRegression(max_iter=500)\n",
    "\n",
    "voting_hard = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', model1),\n",
    "        ('et', model2),\n",
    "        ('lr', model3)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "multi_voting_hard = MultiOutputClassifier(voting_hard)\n",
    "\n",
    "multi_voting_hard.fit(x_train, y_train)\n",
    "y_pred = multi_voting_hard.predict(x_test)\n",
    "\n",
    "#================[ Target - TYPE ]================\n",
    "hard_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "\n",
    "hard_precision_type = precision_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "hard_recall_type = recall_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "hard_f1_type = f1_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "\n",
    "hard_scores_type = cross_val_score(voting_hard, x_train, y_train['type'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'HardBoting Accuracy for TYPE: {hard_accuracy_type}')\n",
    "\n",
    "print(f'\\nPrecision for TYPE: {hard_precision_type}')\n",
    "print(f'Recall for TYPE: {hard_recall_type}')\n",
    "print(f'F1-score for TYPE: {hard_f1_type}')\n",
    "\n",
    "print(\"\\nK-Fold mean for TYPE:\", hard_scores_type.mean())\n",
    "print(\"K-Fold std for TYPE:\", hard_scores_type.std()) \n",
    "\n",
    "print(\"\\nClassification Report for TYPE:\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print('\\n========================================================================================')\n",
    "\n",
    "\n",
    "#================[ Target - CVSS_SCORE ]================\n",
    "hard_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "hard_precision_cvss_score = precision_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "hard_recall_cvss_score = recall_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "hard_f1_cvss_score = f1_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "\n",
    "hard_scores_cvss_score = cross_val_score(voting_hard, x_train, y_train['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\HardBoting Accuracy for CVSS_SCORE: {hard_accuracy_cvss_score}')\n",
    "\n",
    "print(f'\\nPrecision for CVSS_SCORE: {hard_precision_cvss_score}')\n",
    "print(f'Recall for CVSS_SCORE: {hard_recall_cvss_score}')\n",
    "print(f'F1-score for CVSS_SCORE: {hard_f1_cvss_score}')\n",
    "\n",
    "print(\"\\nK-Fold mean for CVSS_SCORE:\", hard_scores_cvss_score.mean())\n",
    "print(\"K-Fold std for CVSS_SCORE:\", hard_scores_cvss_score.std()) \n",
    "\n",
    "print(\"\\nClassification Report for CVSS_SCORE:\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab9bf68",
   "metadata": {},
   "source": [
    "# Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04a06c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftVoting Accuracy for TYPE: 0.9313897187596579\n",
      "\n",
      "Precision for TYPE: 0.930837516869751\n",
      "Recall for TYPE: 0.8733443326868553\n",
      "F1-score for TYPE: 0.8973952144281754\n",
      "\n",
      "K-Fold mean for TYPE: 0.8916673856847708\n",
      "K-Fold std for TYPE: 0.0025945605302186213\n",
      "\n",
      "Classification Report for TYPE:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    AuthBypass       0.97      0.63      0.76       266\n",
      "          CSRF       0.99      0.95      0.97       483\n",
      "           DoS       0.87      0.98      0.92      1104\n",
      "InfoDisclosure       0.88      0.90      0.89      1892\n",
      "         Other       0.92      0.95      0.94      7699\n",
      " PathTraversal       0.93      0.81      0.86       508\n",
      "       PrivEsc       0.81      0.72      0.77       357\n",
      "           RCE       0.95      0.85      0.90      1448\n",
      "          SQLi       1.00      0.99      0.99      1551\n",
      "          SSRF       0.95      0.87      0.91       223\n",
      "           XSS       0.96      0.95      0.96      3883\n",
      "\n",
      "      accuracy                           0.93     19414\n",
      "     macro avg       0.93      0.87      0.90     19414\n",
      "  weighted avg       0.93      0.93      0.93     19414\n",
      "\n",
      "\n",
      "========================================================================================\n",
      "\\SoftVoting Accuracy for CVSS_SCORE: 0.6662717626455136\n",
      "\n",
      "Precision for CVSS_SCORE: 0.7211620758889172\n",
      "Recall for CVSS_SCORE: 0.4464150690585929\n",
      "F1-score for CVSS_SCORE: 0.4808606818823907\n",
      "\n",
      "K-Fold mean for CVSS_SCORE: 0.6134206713995344\n",
      "K-Fold std for CVSS_SCORE: 0.001866818833590022\n",
      "\n",
      "Classification Report for CVSS_SCORE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.67      0.23      0.34      1987\n",
      "        High       0.69      0.50      0.58      6764\n",
      "         Low       0.87      0.14      0.24       908\n",
      "      Medium       0.66      0.92      0.77      9755\n",
      "\n",
      "    accuracy                           0.67     19414\n",
      "   macro avg       0.72      0.45      0.48     19414\n",
      "weighted avg       0.68      0.67      0.63     19414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model2 = ExtraTreesClassifier(n_estimators=200, random_state=42)\n",
    "model3 = LogisticRegression(max_iter=500)\n",
    "\n",
    "voting_soft = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', model1),\n",
    "        ('et', model2),\n",
    "        ('lr', model3)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "multi_voting_soft = MultiOutputClassifier(voting_hard)\n",
    "\n",
    "multi_voting_hard.fit(x_train, y_train)\n",
    "y_pred = multi_voting_hard.predict(x_test)\n",
    "\n",
    "#================[ Target - TYPE ]================\n",
    "soft_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "\n",
    "soft_precision_type = precision_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "soft_recall_type = recall_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "soft_f1_type = f1_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "\n",
    "soft_scores_type = cross_val_score(voting_soft, x_train, y_train['type'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'SoftVoting Accuracy for TYPE: {soft_accuracy_type}')\n",
    "\n",
    "print(f'\\nPrecision for TYPE: {soft_precision_type}')\n",
    "print(f'Recall for TYPE: {soft_recall_type}')\n",
    "print(f'F1-score for TYPE: {soft_f1_type}')\n",
    "\n",
    "print(\"\\nK-Fold mean for TYPE:\", soft_scores_type.mean())\n",
    "print(\"K-Fold std for TYPE:\", soft_scores_type.std()) \n",
    "\n",
    "print(\"\\nClassification Report for TYPE:\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print('\\n========================================================================================')\n",
    "\n",
    "\n",
    "#================[ Target - CVSS_SCORE ]================\n",
    "soft_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "soft_precision_cvss_score = precision_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "soft_recall_cvss_score = recall_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "soft_f1_cvss_score = f1_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "\n",
    "soft_scores_cvss_score = cross_val_score(voting_soft, x_train, y_train['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\SoftVoting Accuracy for CVSS_SCORE: {soft_accuracy_cvss_score}')\n",
    "\n",
    "print(f'\\nPrecision for CVSS_SCORE: {soft_precision_cvss_score}')\n",
    "print(f'Recall for CVSS_SCORE: {soft_recall_cvss_score}')\n",
    "print(f'F1-score for CVSS_SCORE: {soft_f1_cvss_score}')\n",
    "\n",
    "print(\"\\nK-Fold mean for CVSS_SCORE:\", soft_scores_cvss_score.mean())\n",
    "print(\"K-Fold std for CVSS_SCORE:\", soft_scores_cvss_score.std()) \n",
    "\n",
    "print(\"\\nClassification Report for CVSS_SCORE:\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176261b6",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "482a4635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Accuracy for TYPE: 0.9511177500772638\n",
      "\n",
      "Precision for TYPE: 0.943309608097309\n",
      "Recall for TYPE: 0.9162735471308868\n",
      "F1-score for TYPE: 0.9286719902453556\n",
      "\n",
      "K-Fold mean for TYPE: 0.9397779554427195\n",
      "K-Fold std for TYPE: 0.0006594541515654048\n",
      "\n",
      "Classification Report for TYPE:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    AuthBypass       0.96      0.79      0.87       266\n",
      "          CSRF       0.99      0.98      0.98       483\n",
      "           DoS       0.91      0.96      0.93      1104\n",
      "InfoDisclosure       0.94      0.93      0.94      1892\n",
      "         Other       0.95      0.95      0.95      7699\n",
      " PathTraversal       0.94      0.94      0.94       508\n",
      "       PrivEsc       0.85      0.78      0.81       357\n",
      "           RCE       0.94      0.89      0.91      1448\n",
      "          SQLi       1.00      0.99      1.00      1551\n",
      "          SSRF       0.94      0.88      0.91       223\n",
      "           XSS       0.96      0.99      0.97      3883\n",
      "\n",
      "      accuracy                           0.95     19414\n",
      "     macro avg       0.94      0.92      0.93     19414\n",
      "  weighted avg       0.95      0.95      0.95     19414\n",
      "\n",
      "\n",
      "========================================================================================\n",
      "\\Stacking Accuracy for CVSS_SCORE: 0.6638508292984444\n",
      "\n",
      "Precision for CVSS_SCORE: 0.619204295470266\n",
      "Recall for CVSS_SCORE: 0.47966715012570227\n",
      "F1-score for CVSS_SCORE: 0.5070481798886073\n",
      "\n",
      "K-Fold mean for CVSS_SCORE: 0.6393389205344684\n",
      "K-Fold std for CVSS_SCORE: 0.0022202697647995466\n",
      "\n",
      "Classification Report for CVSS_SCORE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.71      0.20      0.31      1987\n",
      "        High       0.62      0.61      0.61      6764\n",
      "         Low       0.45      0.28      0.34       908\n",
      "      Medium       0.70      0.83      0.76      9755\n",
      "\n",
      "    accuracy                           0.66     19414\n",
      "   macro avg       0.62      0.48      0.51     19414\n",
      "weighted avg       0.66      0.66      0.64     19414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "base1 = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "base2 = ExtraTreesClassifier(n_estimators=200, random_state=42)\n",
    "base3 = LogisticRegression(max_iter=500)\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', base1),\n",
    "        ('et', base2),\n",
    "        ('lr', base3)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=500)\n",
    ")\n",
    "\n",
    "multi_stacking = MultiOutputClassifier(stacking)\n",
    "\n",
    "multi_stacking.fit(x_train, y_train)\n",
    "y_pred = multi_stacking.predict(x_test)\n",
    "\n",
    "#================[ Target - TYPE ]================\n",
    "stacking_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "\n",
    "stacking_precision_type = precision_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "stacking_recall_type = recall_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "stacking_f1_type = f1_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "\n",
    "stacking_scores_type = cross_val_score(stacking, x_train, y_train['type'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Stacking Accuracy for TYPE: {stacking_accuracy_type}')\n",
    "\n",
    "print(f'\\nPrecision for TYPE: {stacking_precision_type}')\n",
    "print(f'Recall for TYPE: {stacking_recall_type}')\n",
    "print(f'F1-score for TYPE: {stacking_f1_type}')\n",
    "\n",
    "print(\"\\nK-Fold mean for TYPE:\", stacking_scores_type.mean())\n",
    "print(\"K-Fold std for TYPE:\", stacking_scores_type.std()) \n",
    "\n",
    "print(\"\\nClassification Report for TYPE:\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print('\\n========================================================================================')\n",
    "\n",
    "\n",
    "#================[ Target - CVSS_SCORE ]================\n",
    "stacking_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "stacking_precision_cvss_score = precision_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "stacking_recall_cvss_score = recall_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "stacking_f1_cvss_score = f1_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "\n",
    "stacking_scores_cvss_score = cross_val_score(stacking, x_train, y_train['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\Stacking Accuracy for CVSS_SCORE: {stacking_accuracy_cvss_score}')\n",
    "\n",
    "print(f'\\nPrecision for CVSS_SCORE: {stacking_precision_cvss_score}')\n",
    "print(f'Recall for CVSS_SCORE: {stacking_recall_cvss_score}')\n",
    "print(f'F1-score for CVSS_SCORE: {stacking_f1_cvss_score}')\n",
    "\n",
    "print(\"\\nK-Fold mean for CVSS_SCORE:\", stacking_scores_cvss_score.mean())\n",
    "print(\"K-Fold std for CVSS_SCORE:\", stacking_scores_cvss_score.std()) \n",
    "\n",
    "print(\"\\nClassification Report for CVSS_SCORE:\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98a957e",
   "metadata": {},
   "source": [
    "# Bagged KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4705fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = KNeighborsClassifier()\n",
    "# bag_knn = BaggingClassifier(estimator=knn, n_estimators=100, random_state=42)\n",
    "# multi_bag_knn = MultiOutputClassifier(bag_knn)\n",
    "\n",
    "# multi_bag_knn.fit(x_train, y_train)\n",
    "# y_pred = multi_bag_knn.predict(x_test)\n",
    "\n",
    "# bag_knn_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "# bag_knn_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "# bag_knn_scores_type = cross_val_score(bag_knn, x, y['type'], cv=kf, scoring='f1_macro')\n",
    "# bag_knn_scores_cvss_score = cross_val_score(bag_knn, x, y['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "# print(\"Bagging KNN Accuracy for 'type':\", bag_knn_accuracy_type)\n",
    "# print(\"Bagging KNN Accuracy for 'cvss_score':\", bag_knn_accuracy_cvss_score)\n",
    "\n",
    "# print(\"K-Fold mean F1 (type):\", bag_knn_scores_type.mean())\n",
    "# print(\"K-Fold std  F1 (type):\", bag_knn_scores_type.std())\n",
    "\n",
    "# print(\"K-Fold mean F1 (cvss_score):\", bag_knn_scores_cvss_score.mean())\n",
    "# print(\"K-Fold std  F1 (cvss_score):\", bag_knn_scores_cvss_score.std())\n",
    "\n",
    "# print(\"\\nClassification Report for 'type':\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "# print(\"\\nClassification Report for 'cvss_score':\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8560251c",
   "metadata": {},
   "source": [
    "# bagged DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fea00ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged DT Accuracy for TYPE: 0.9325229216029669\n",
      "\n",
      "Precision for TYPE: 0.922796515070393\n",
      "Recall for TYPE: 0.9180346862768821\n",
      "F1-score for TYPE: 0.9189338932578597\n",
      "\n",
      "K-Fold mean for TYPE: 0.9530827739027373\n",
      "K-Fold std for TYPE: 0.0012014767229538452\n",
      "\n",
      "Classification Report for TYPE:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    AuthBypass       0.76      0.83      0.79       266\n",
      "          CSRF       0.99      0.98      0.99       483\n",
      "           DoS       0.91      0.71      0.80      1104\n",
      "InfoDisclosure       0.96      0.91      0.94      1892\n",
      "         Other       0.92      0.94      0.93      7699\n",
      " PathTraversal       0.93      0.96      0.95       508\n",
      "       PrivEsc       0.88      0.94      0.91       357\n",
      "           RCE       0.86      0.90      0.88      1448\n",
      "          SQLi       1.00      1.00      1.00      1551\n",
      "          SSRF       0.97      0.95      0.96       223\n",
      "           XSS       0.97      0.98      0.97      3883\n",
      "\n",
      "      accuracy                           0.93     19414\n",
      "     macro avg       0.92      0.92      0.92     19414\n",
      "  weighted avg       0.93      0.93      0.93     19414\n",
      "\n",
      "\n",
      "========================================================================================\n",
      "\\Bagged DT Accuracy for CVSS_SCORE: 0.5935922530132893\n",
      "\n",
      "Precision for CVSS_SCORE: 0.5547417519377876\n",
      "Recall for CVSS_SCORE: 0.40808053835773206\n",
      "F1-score for CVSS_SCORE: 0.42117189392477705\n",
      "\n",
      "K-Fold mean for CVSS_SCORE: 0.6349532473975352\n",
      "K-Fold std for CVSS_SCORE: 0.0024860446482537837\n",
      "\n",
      "Classification Report for CVSS_SCORE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Critical       0.46      0.27      0.34      1987\n",
      "        High       0.53      0.61      0.56      6764\n",
      "         Low       0.57      0.06      0.10       908\n",
      "      Medium       0.66      0.70      0.68      9755\n",
      "\n",
      "    accuracy                           0.59     19414\n",
      "   macro avg       0.55      0.41      0.42     19414\n",
      "weighted avg       0.59      0.59      0.58     19414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "bag_dt = BaggingClassifier(estimator=dt, n_estimators=100, random_state=42)\n",
    "multi_bag_dt = MultiOutputClassifier(bag_dt)\n",
    "\n",
    "multi_bag_dt.fit(x_train, y_train)\n",
    "\n",
    "y_pred = multi_bag_dt.predict(x_test)\n",
    "\n",
    "#================[ Target - TYPE ]================\n",
    "bag_dt_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "\n",
    "bag_dt_precision_type = precision_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "bag_dt_recall_type = recall_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "bag_dt_f1_type = f1_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "\n",
    "bag_dt_scores_type = cross_val_score(bag_dt, x_train, y_train['type'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'Bagged DT Accuracy for TYPE: {bag_dt_accuracy_type}')\n",
    "\n",
    "print(f'\\nPrecision for TYPE: {bag_dt_precision_type}')\n",
    "print(f'Recall for TYPE: {bag_dt_recall_type}')\n",
    "print(f'F1-score for TYPE: {bag_dt_f1_type}')\n",
    "\n",
    "print(\"\\nK-Fold mean for TYPE:\", bag_dt_scores_type.mean())\n",
    "print(\"K-Fold std for TYPE:\", bag_dt_scores_type.std()) \n",
    "\n",
    "print(\"\\nClassification Report for TYPE:\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print('\\n========================================================================================')\n",
    "\n",
    "\n",
    "#================[ Target - CVSS_SCORE ]================\n",
    "bag_dt_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "bag_dt_precision_cvss_score = precision_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "bag_dt_recall_cvss_score = recall_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "bag_dt_f1_cvss_score = f1_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "\n",
    "bag_dt_scores_cvss_score = cross_val_score(bag_dt, x_train, y_train['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(f'\\Bagged DT Accuracy for CVSS_SCORE: {bag_dt_accuracy_cvss_score}')\n",
    "\n",
    "print(f'\\nPrecision for CVSS_SCORE: {bag_dt_precision_cvss_score}')\n",
    "print(f'Recall for CVSS_SCORE: {bag_dt_recall_cvss_score}')\n",
    "print(f'F1-score for CVSS_SCORE: {bag_dt_f1_cvss_score}')\n",
    "\n",
    "print(\"\\nK-Fold mean for CVSS_SCORE:\", bag_dt_scores_cvss_score.mean())\n",
    "print(\"K-Fold std for CVSS_SCORE:\", bag_dt_scores_cvss_score.std()) \n",
    "\n",
    "print(\"\\nClassification Report for CVSS_SCORE:\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9219fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                Without Feature Selection Method                                                                </span>\n",
       "\n",
       "<span style=\"font-weight: bold\">          </span><span style=\"font-weight: bold\">   TYPE   </span><span style=\"font-weight: bold\">   TYPE   </span><span style=\"font-weight: bold\">   TYPE    </span><span style=\"font-weight: bold\">   TYPE   </span><span style=\"font-weight: bold\">  TYPE CV  </span><span style=\"font-weight: bold\"> TYPE CV  </span><span style=\"font-weight: bold\">   CVSS    </span><span style=\"font-weight: bold\">   CVSS   </span><span style=\"font-weight: bold\">   CVSS    </span><span style=\"font-weight: bold\">   CVSS   </span><span style=\"font-weight: bold\">  CVSS CV  </span><span style=\"font-weight: bold\"> CVSS CV  </span><span style=\"font-weight: bold\">          </span>\n",
       "<span style=\"font-weight: bold\">  Model   </span><span style=\"font-weight: bold\"> Accuracy </span><span style=\"font-weight: bold\"> Precisi </span><span style=\"font-weight: bold\">  Recall   </span><span style=\"font-weight: bold\"> F1-score </span><span style=\"font-weight: bold\">   mean    </span><span style=\"font-weight: bold\">   std    </span><span style=\"font-weight: bold\"> Accuracy  </span><span style=\"font-weight: bold\"> Precisi </span><span style=\"font-weight: bold\">  Recall   </span><span style=\"font-weight: bold\"> F1-score </span><span style=\"font-weight: bold\">   mean    </span><span style=\"font-weight: bold\">   std    </span><span style=\"font-weight: bold\"> Combined </span>\n",
       "\n",
       " <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ExtraTr</span>    <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.93</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.92</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.85</span>       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.87</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.90</span>       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.66</span>       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.61</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.48</span>       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.51</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.63</span>       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.79</span>   \n",
       "\n",
       " Stacking    0.95      0.94      0.92       0.93      0.94       0.00      0.66       0.62      0.48       0.51      0.64       0.00      0.81   \n",
       "\n",
       "   Hard      0.93      0.93      0.87       0.90      0.92       0.00      0.67       0.72      0.45       0.48      0.63       0.00      0.80   \n",
       "  Voting                                                                                                                                         \n",
       "\n",
       "   Soft      0.93      0.93      0.87       0.90      0.89       0.00      0.67       0.72      0.45       0.48      0.61       0.00      0.80   \n",
       "  Voting                                                                                                                                         \n",
       "\n",
       " RandomF    0.94      0.94      0.87       0.90      0.92       0.00      0.66       0.70      0.44       0.47      0.63       0.00      0.80   \n",
       "\n",
       " LightGBM    0.95      0.95      0.94       0.94      0.96       0.00      0.64       0.53      0.43       0.44      0.60       0.00      0.80   \n",
       "\n",
       " HistGra    0.33      0.35      0.13       0.13      0.90       0.04      0.64       0.54      0.42       0.44      0.62       0.00      0.48   \n",
       "\n",
       "  Bagged     0.93      0.92      0.92       0.92      0.95       0.00      0.59       0.55      0.41       0.42      0.63       0.00      0.76   \n",
       "    DT                                                                                                                                           \n",
       "\n",
       " Bagging     0.92      0.91      0.90       0.90      0.95       0.00      0.54       0.43      0.40       0.41      0.62       0.00      0.73   \n",
       "\n",
       " Decisio    0.90      0.88      0.87       0.87      0.94       0.00      0.45       0.36      0.39       0.36      0.55       0.00      0.67   \n",
       "\n",
       " Gradien    0.95      0.94      0.93       0.93      0.96       0.00      0.54       0.41      0.37       0.36      0.61       0.00      0.74   \n",
       "\n",
       " AdaBoost    0.80      0.82      0.65       0.71      0.70       0.05      0.59       0.34      0.32       0.30      0.31       0.00      0.70   \n",
       "\n",
       " Logisti    0.78      0.78      0.72       0.73      0.73       0.00      0.57       0.48      0.30       0.27      0.33       0.00      0.67   \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                Without Feature Selection Method                                                                \u001b[0m\n",
       "\n",
       "\u001b[1m          \u001b[0m\u001b[1m \u001b[0m\u001b[1m  TYPE  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  TYPE  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  TYPE   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  TYPE  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m TYPE CV \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTYPE CV \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  CVSS   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  CVSS  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  CVSS   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  CVSS  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m CVSS CV \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCVSS CV \u001b[0m\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m Model  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mAccuracy\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mPrecisi\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m Recall  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mF1-score\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  mean   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  std   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mAccuracy \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mPrecisi\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m Recall  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mF1-score\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  mean   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  std   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCombined\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " \u001b[1;32mExtraTr\u001b[0m    \u001b[1;32m0.93\u001b[0m      \u001b[1;32m0.92\u001b[0m      \u001b[1;32m0.85\u001b[0m       \u001b[1;32m0.87\u001b[0m      \u001b[1;32m0.90\u001b[0m       \u001b[1;32m0.00\u001b[0m      \u001b[1;32m0.66\u001b[0m       \u001b[1;32m0.61\u001b[0m      \u001b[1;32m0.48\u001b[0m       \u001b[1;32m0.51\u001b[0m      \u001b[1;32m0.63\u001b[0m       \u001b[1;32m0.00\u001b[0m      \u001b[1;32m0.79\u001b[0m   \n",
       "\n",
       " Stacking    0.95      0.94      0.92       0.93      0.94       0.00      0.66       0.62      0.48       0.51      0.64       0.00      0.81   \n",
       "\n",
       "   Hard      0.93      0.93      0.87       0.90      0.92       0.00      0.67       0.72      0.45       0.48      0.63       0.00      0.80   \n",
       "  Voting                                                                                                                                         \n",
       "\n",
       "   Soft      0.93      0.93      0.87       0.90      0.89       0.00      0.67       0.72      0.45       0.48      0.61       0.00      0.80   \n",
       "  Voting                                                                                                                                         \n",
       "\n",
       " RandomF    0.94      0.94      0.87       0.90      0.92       0.00      0.66       0.70      0.44       0.47      0.63       0.00      0.80   \n",
       "\n",
       " LightGBM    0.95      0.95      0.94       0.94      0.96       0.00      0.64       0.53      0.43       0.44      0.60       0.00      0.80   \n",
       "\n",
       " HistGra    0.33      0.35      0.13       0.13      0.90       0.04      0.64       0.54      0.42       0.44      0.62       0.00      0.48   \n",
       "\n",
       "  Bagged     0.93      0.92      0.92       0.92      0.95       0.00      0.59       0.55      0.41       0.42      0.63       0.00      0.76   \n",
       "    DT                                                                                                                                           \n",
       "\n",
       " Bagging     0.92      0.91      0.90       0.90      0.95       0.00      0.54       0.43      0.40       0.41      0.62       0.00      0.73   \n",
       "\n",
       " Decisio    0.90      0.88      0.87       0.87      0.94       0.00      0.45       0.36      0.39       0.36      0.55       0.00      0.67   \n",
       "\n",
       " Gradien    0.95      0.94      0.93       0.93      0.96       0.00      0.54       0.41      0.37       0.36      0.61       0.00      0.74   \n",
       "\n",
       " AdaBoost    0.80      0.82      0.65       0.71      0.70       0.05      0.59       0.34      0.32       0.30      0.31       0.00      0.70   \n",
       "\n",
       " Logisti    0.78      0.78      0.72       0.73      0.73       0.00      0.57       0.48      0.30       0.27      0.33       0.00      0.67   \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console(width=160)\n",
    "\n",
    "results = [\n",
    "    ['LogisticRegression', lr_accuracy_type, lr_precision_type, lr_recall_type, lr_f1_type, lr_scores_type.mean(), lr_scores_type.std(), lr_accuracy_cvss_score, lr_precision_cvss_score, lr_recall_cvss_score, lr_f1_cvss_score, lr_scores_cvss_score.mean(), lr_scores_cvss_score.std()],\n",
    "    ['DecisionTree', dt_accuracy_type, dt_precision_type, dt_recall_type, dt_f1_type, dt_scores_type.mean(), dt_scores_type.std(), dt_accuracy_cvss_score, dt_precision_cvss_score, dt_recall_cvss_score, dt_f1_cvss_score, dt_scores_cvss_score.mean(), dt_scores_cvss_score.std()],\n",
    "    ['RandomForest', rf_accuracy_type, rf_precision_type, rf_recall_type, rf_f1_type, rf_scores_type.mean(), rf_scores_type.std(), rf_accuracy_cvss_score, rf_precision_cvss_score, rf_recall_cvss_score, rf_f1_cvss_score, rf_scores_cvss_score.mean(), rf_scores_cvss_score.std()],\n",
    "    ['ExtraTrees', et_accuracy_type, et_precision_type, et_recall_type, et_f1_type, et_scores_type.mean(), et_scores_type.std(), et_accuracy_cvss_score, et_precision_cvss_score, et_recall_cvss_score, et_f1_cvss_score, et_scores_cvss_score.mean(), et_scores_cvss_score.std()],\n",
    "    ['GradientBoosting', gb_accuracy_type, gb_precision_type, gb_recall_type, gb_f1_type, gb_scores_type.mean(), gb_scores_type.std(), gb_accuracy_cvss_score, gb_precision_cvss_score, gb_recall_cvss_score, gb_f1_cvss_score, gb_scores_cvss_score.mean(), gb_scores_cvss_score.std()],\n",
    "    ['HistGradientBoosting', hgb_accuracy_type, hgb_precision_type, hgb_recall_type, hgb_f1_type, hgb_scores_type.mean(), hgb_scores_type.std(), hgb_accuracy_cvss_score, hgb_precision_cvss_score, hgb_recall_cvss_score, hgb_f1_cvss_score, hgb_scores_cvss_score.mean(), hgb_scores_cvss_score.std()],\n",
    "    # ['KNN', knn_accuracy_type, knn_scores_type.mean(), knn_scores_type.std(), knn_accuracy_cvss_score, knn_scores_cvss_score.mean(), knn_scores_cvss_score.std()],\n",
    "    ['AdaBoost', ab_accuracy_type, ab_precision_type, ab_recall_type, ab_f1_type, ab_scores_type.mean(), ab_scores_type.std(), ab_accuracy_cvss_score, ab_precision_cvss_score, ab_recall_cvss_score, ab_f1_cvss_score, ab_scores_cvss_score.mean(), ab_scores_cvss_score.std()],\n",
    "    ['LightGBM', lgbm_accuracy_type, lgbm_precision_type, lgbm_recall_type, lgbm_f1_type, lgbm_scores_type.mean(), lgbm_scores_type.std(), lgbm_accuracy_cvss_score, lgbm_precision_cvss_score, lgbm_recall_cvss_score, lgbm_f1_cvss_score, lgbm_scores_cvss_score.mean(), lgbm_scores_cvss_score.std()],\n",
    "    ['Bagging', bagging_accuracy_type, bagging_precision_type, bagging_recall_type, bagging_f1_type, bagging_scores_type.mean(), bagging_scores_type.std(), bagging_accuracy_cvss_score, bagging_precision_cvss_score, bagging_recall_cvss_score, bagging_f1_cvss_score, bagging_scores_cvss_score.mean(), bagging_scores_cvss_score.std()],\n",
    "    ['Hard Voting', hard_accuracy_type, hard_precision_type, hard_recall_type, hard_f1_type, hard_scores_type.mean(), hard_scores_type.std(), hard_accuracy_cvss_score, hard_precision_cvss_score, hard_recall_cvss_score, hard_f1_cvss_score,  hard_scores_cvss_score.mean(), hard_scores_cvss_score.std()],\n",
    "    ['Soft Voting', soft_accuracy_type, soft_precision_type, soft_recall_type, soft_f1_type, soft_scores_type.mean(), soft_scores_type.std(), soft_accuracy_cvss_score, soft_precision_cvss_score, soft_recall_cvss_score, soft_f1_cvss_score,  soft_scores_cvss_score.mean(), soft_scores_cvss_score.std()],\n",
    "    ['Stacking', stacking_accuracy_type, stacking_precision_type, stacking_recall_type, stacking_f1_type, stacking_scores_type.mean(), stacking_scores_type.std(), stacking_accuracy_cvss_score, stacking_precision_cvss_score, stacking_recall_cvss_score, stacking_f1_cvss_score, stacking_scores_cvss_score.mean(), stacking_scores_cvss_score.std()],\n",
    "    # ['SVM', svc_accuracy_type, svc_scores_type.mean(), svc_scores_type.std(), svc_accuracy_cvss_score, svc_scores_cvss_score.mean(), svc_scores_cvss_score.std()],\n",
    "    # ['Bagged KNN', bag_knn_accuracy_type, bag_knn_scores_type.mean(), bag_knn_scores_type.std(), bag_knn_accuracy_cvss_score, bag_knn_scores_cvss_score.mean(), bag_knn_scores_cvss_score.std()],\n",
    "    ['Bagged DT', bag_dt_accuracy_type, bag_dt_precision_type, bag_dt_recall_type, bag_dt_f1_type, bag_dt_scores_type.mean(), bag_dt_scores_type.std(), bag_dt_accuracy_cvss_score, bag_dt_precision_cvss_score, bag_dt_recall_cvss_score, bag_dt_f1_cvss_score, bag_dt_scores_cvss_score.mean(), bag_dt_scores_cvss_score.std()],\n",
    "]\n",
    "\n",
    "for row in results:\n",
    "    type_acc = row[1]\n",
    "    cvss_score_acc = row[7]\n",
    "    combined = (type_acc + cvss_score_acc) / 2\n",
    "    row.append(combined)\n",
    "\n",
    "result_sorted = sorted(results, key=lambda i: i[3] and i[9], reverse=True)\n",
    "best_model = max(results, key=lambda x: x[3] and x[9])\n",
    "\n",
    "table = Table(title=\"Without Feature Selection Method\", show_lines=True)\n",
    "table.add_column(\"Model\", justify=\"center\", vertical=\"middle\")\n",
    "table.add_column(\"TYPE Accuracy\", justify=\"center\", vertical=\"middle\")\n",
    "table.add_column(\"TYPE Precision\", justify=\"center\", vertical=\"middle\")\n",
    "table.add_column(\"TYPE Recall\", justify=\"center\", vertical=\"middle\")\n",
    "table.add_column(\"TYPE F1-score\", justify=\"center\", vertical=\"middle\")\n",
    "table.add_column(\"TYPE CV mean\", justify=\"center\", vertical=\"middle\")\n",
    "table.add_column(\"TYPE CV std\", justify=\"center\", vertical=\"middle\")\n",
    "\n",
    "table.add_column(\"CVSS Accuracy\", justify=\"center\", vertical=\"middle\")\n",
    "table.add_column(\"CVSS Precision\", justify=\"center\", vertical=\"middle\")\n",
    "table.add_column(\"CVSS Recall\", justify=\"center\", vertical=\"middle\")\n",
    "table.add_column(\"CVSS F1-score\", justify=\"center\", vertical=\"middle\")\n",
    "table.add_column(\"CVSS CV mean\", justify=\"center\", vertical=\"middle\")\n",
    "table.add_column(\"CVSS CV std\", justify=\"center\", vertical=\"middle\")\n",
    "\n",
    "table.add_column(\"Combined\", justify=\"center\", vertical=\"middle\")\n",
    "\n",
    "for row in result_sorted:\n",
    "    algo, type_acc, type_pre, type_recall, type_f1, type_kmean, type_kstd, cvss_score_acc, cvss_score_pre, cvss_score_recall, cvss_score_f1, cvss_score_kmean, cvss_score_kstd, combined = row\n",
    "\n",
    "    if row == best_model:\n",
    "        table.add_row(\n",
    "            # TYPE\n",
    "            f\"[bold green]{algo}[/bold green]\",\n",
    "            f\"[bold green]{type_acc:.2f}[/bold green]\",\n",
    "            f\"[bold green]{type_pre:.2f}[/bold green]\",\n",
    "            f\"[bold green]{type_recall:.2f}[/bold green]\",\n",
    "            f\"[bold green]{type_f1:.2f}[/bold green]\",\n",
    "            f\"[bold green]{type_kmean:.2f}[/bold green]\",\n",
    "            f\"[bold green]{type_kstd:.2f}[/bold green]\",\n",
    "\n",
    "            # CVSS_SCORE\n",
    "            f\"[bold green]{cvss_score_acc:.2f}[/bold green]\",\n",
    "            f\"[bold green]{cvss_score_pre:.2f}[/bold green]\",\n",
    "            f\"[bold green]{cvss_score_recall:.2f}[/bold green]\",\n",
    "            f\"[bold green]{cvss_score_f1:.2f}[/bold green]\",\n",
    "            f\"[bold green]{cvss_score_kmean:.2f}[/bold green]\",\n",
    "            f\"[bold green]{cvss_score_kstd:.2f}[/bold green]\",\n",
    "            f\"[bold green]{combined:.2f}[/bold green]\",\n",
    "        )\n",
    "    else: table.add_row(algo, f\"{type_acc:.2f}\", f\"{type_pre:.2f}\", f\"{type_recall:.2f}\", f\"{type_f1:.2f}\", f\"{type_kmean:.2f}\", f\"{type_kstd:.2f}\",\n",
    "                      f\"{cvss_score_acc:.2f}\", f\"{cvss_score_pre:.2f}\", f\"{cvss_score_recall:.2f}\", f\"{cvss_score_f1:.2f}\", f\"{cvss_score_kmean:.2f}\", f\"{cvss_score_kstd:.2f}\", f\"{combined:.2f}\")\n",
    "\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a77d3d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                Without Feature Selection Method                                                                </span>\n",
       "\n",
       "<span style=\"font-weight: bold\">          </span><span style=\"font-weight: bold\">   TYPE   </span><span style=\"font-weight: bold\">   TYPE   </span><span style=\"font-weight: bold\">   TYPE    </span><span style=\"font-weight: bold\">   TYPE   </span><span style=\"font-weight: bold\">  TYPE CV  </span><span style=\"font-weight: bold\"> TYPE CV  </span><span style=\"font-weight: bold\">   CVSS    </span><span style=\"font-weight: bold\">   CVSS   </span><span style=\"font-weight: bold\">   CVSS    </span><span style=\"font-weight: bold\">   CVSS   </span><span style=\"font-weight: bold\">  CVSS CV  </span><span style=\"font-weight: bold\"> CVSS CV  </span><span style=\"font-weight: bold\">          </span>\n",
       "<span style=\"font-weight: bold\">  Model   </span><span style=\"font-weight: bold\"> Accuracy </span><span style=\"font-weight: bold\"> Precisi </span><span style=\"font-weight: bold\">  Recall   </span><span style=\"font-weight: bold\"> F1-score </span><span style=\"font-weight: bold\">   mean    </span><span style=\"font-weight: bold\">   std    </span><span style=\"font-weight: bold\"> Accuracy  </span><span style=\"font-weight: bold\"> Precisi </span><span style=\"font-weight: bold\">  Recall   </span><span style=\"font-weight: bold\"> F1-score </span><span style=\"font-weight: bold\">   mean    </span><span style=\"font-weight: bold\">   std    </span><span style=\"font-weight: bold\"> Combined </span>\n",
       "\n",
       " <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ExtraTr</span>    <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.93</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.92</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.85</span>       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.87</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.90</span>       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.66</span>       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.61</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.48</span>       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.51</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.63</span>       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.79</span>   \n",
       "\n",
       " Stacking    0.95      0.94      0.92       0.93      0.94       0.00      0.66       0.62      0.48       0.51      0.64       0.00      0.81   \n",
       "\n",
       "   Hard      0.93      0.93      0.87       0.90      0.92       0.00      0.67       0.72      0.45       0.48      0.63       0.00      0.80   \n",
       "  Voting                                                                                                                                         \n",
       "\n",
       "   Soft      0.93      0.93      0.87       0.90      0.89       0.00      0.67       0.72      0.45       0.48      0.61       0.00      0.80   \n",
       "  Voting                                                                                                                                         \n",
       "\n",
       " RandomF    0.94      0.94      0.87       0.90      0.92       0.00      0.66       0.70      0.44       0.47      0.63       0.00      0.80   \n",
       "\n",
       " LightGBM    0.95      0.95      0.94       0.94      0.96       0.00      0.64       0.53      0.43       0.44      0.60       0.00      0.80   \n",
       "\n",
       " HistGra    0.33      0.35      0.13       0.13      0.90       0.04      0.64       0.54      0.42       0.44      0.62       0.00      0.48   \n",
       "\n",
       "  Bagged     0.93      0.92      0.92       0.92      0.95       0.00      0.59       0.55      0.41       0.42      0.63       0.00      0.76   \n",
       "    DT                                                                                                                                           \n",
       "\n",
       " Bagging     0.92      0.91      0.90       0.90      0.95       0.00      0.54       0.43      0.40       0.41      0.62       0.00      0.73   \n",
       "\n",
       " Decisio    0.90      0.88      0.87       0.87      0.94       0.00      0.45       0.36      0.39       0.36      0.55       0.00      0.67   \n",
       "\n",
       " Gradien    0.95      0.94      0.93       0.93      0.96       0.00      0.54       0.41      0.37       0.36      0.61       0.00      0.74   \n",
       "\n",
       " AdaBoost    0.80      0.82      0.65       0.71      0.70       0.05      0.59       0.34      0.32       0.30      0.31       0.00      0.70   \n",
       "\n",
       " Logisti    0.78      0.78      0.72       0.73      0.73       0.00      0.57       0.48      0.30       0.27      0.33       0.00      0.67   \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                Without Feature Selection Method                                                                \u001b[0m\n",
       "\n",
       "\u001b[1m          \u001b[0m\u001b[1m \u001b[0m\u001b[1m  TYPE  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  TYPE  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  TYPE   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  TYPE  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m TYPE CV \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTYPE CV \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  CVSS   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  CVSS  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  CVSS   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  CVSS  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m CVSS CV \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCVSS CV \u001b[0m\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m Model  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mAccuracy\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mPrecisi\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m Recall  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mF1-score\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  mean   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  std   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mAccuracy \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mPrecisi\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m Recall  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mF1-score\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  mean   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  std   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCombined\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " \u001b[1;32mExtraTr\u001b[0m    \u001b[1;32m0.93\u001b[0m      \u001b[1;32m0.92\u001b[0m      \u001b[1;32m0.85\u001b[0m       \u001b[1;32m0.87\u001b[0m      \u001b[1;32m0.90\u001b[0m       \u001b[1;32m0.00\u001b[0m      \u001b[1;32m0.66\u001b[0m       \u001b[1;32m0.61\u001b[0m      \u001b[1;32m0.48\u001b[0m       \u001b[1;32m0.51\u001b[0m      \u001b[1;32m0.63\u001b[0m       \u001b[1;32m0.00\u001b[0m      \u001b[1;32m0.79\u001b[0m   \n",
       "\n",
       " Stacking    0.95      0.94      0.92       0.93      0.94       0.00      0.66       0.62      0.48       0.51      0.64       0.00      0.81   \n",
       "\n",
       "   Hard      0.93      0.93      0.87       0.90      0.92       0.00      0.67       0.72      0.45       0.48      0.63       0.00      0.80   \n",
       "  Voting                                                                                                                                         \n",
       "\n",
       "   Soft      0.93      0.93      0.87       0.90      0.89       0.00      0.67       0.72      0.45       0.48      0.61       0.00      0.80   \n",
       "  Voting                                                                                                                                         \n",
       "\n",
       " RandomF    0.94      0.94      0.87       0.90      0.92       0.00      0.66       0.70      0.44       0.47      0.63       0.00      0.80   \n",
       "\n",
       " LightGBM    0.95      0.95      0.94       0.94      0.96       0.00      0.64       0.53      0.43       0.44      0.60       0.00      0.80   \n",
       "\n",
       " HistGra    0.33      0.35      0.13       0.13      0.90       0.04      0.64       0.54      0.42       0.44      0.62       0.00      0.48   \n",
       "\n",
       "  Bagged     0.93      0.92      0.92       0.92      0.95       0.00      0.59       0.55      0.41       0.42      0.63       0.00      0.76   \n",
       "    DT                                                                                                                                           \n",
       "\n",
       " Bagging     0.92      0.91      0.90       0.90      0.95       0.00      0.54       0.43      0.40       0.41      0.62       0.00      0.73   \n",
       "\n",
       " Decisio    0.90      0.88      0.87       0.87      0.94       0.00      0.45       0.36      0.39       0.36      0.55       0.00      0.67   \n",
       "\n",
       " Gradien    0.95      0.94      0.93       0.93      0.96       0.00      0.54       0.41      0.37       0.36      0.61       0.00      0.74   \n",
       "\n",
       " AdaBoost    0.80      0.82      0.65       0.71      0.70       0.05      0.59       0.34      0.32       0.30      0.31       0.00      0.70   \n",
       "\n",
       " Logisti    0.78      0.78      0.72       0.73      0.73       0.00      0.57       0.48      0.30       0.27      0.33       0.00      0.67   \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "temp_console = Console(record=True, width=160)\n",
    "temp_console.print(table)\n",
    "text = temp_console.export_text()\n",
    "with open('results/feature_selection_compare.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3155c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
