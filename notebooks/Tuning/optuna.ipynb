{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc12a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00df71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\SML_Projects\\SML_CVE_type_cwe_predict')\n",
    "os.makedirs('results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "923af740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4116188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('data/preprocessed/preprocessed_x_train.csv')\n",
    "x_test = pd.read_csv('data/preprocessed/preprocessed_x_test.csv')\n",
    "\n",
    "y_train = pd.read_csv('data/split/y_train.csv')[['type', 'cvss_score']]\n",
    "y_test  = pd.read_csv('data/split/y_test.csv')[['type', 'cvss_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4469cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbeb4526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier, AdaBoostClassifier,\n",
    "    BaggingClassifier, VotingClassifier, StackingClassifier\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8d4371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimators = [\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('xgb', XGBClassifier(random_state=42, eval_metric='logloss')),\n",
    "    ('lgbm', LGBMClassifier(random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a956475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(trial, name):\n",
    "\n",
    "    # ===== Linear =====\n",
    "    if name == 'Logistic Regression':\n",
    "        return LogisticRegression(\n",
    "            C=trial.suggest_float('C', 1e-2, 10.0, log=True),\n",
    "            solver=trial.suggest_categorical('solver', ['lbfgs', 'liblinear']),\n",
    "            max_iter=1000\n",
    "        )\n",
    "\n",
    "    # ===== Tree =====\n",
    "    if name == 'DecisionTree':\n",
    "        return DecisionTreeClassifier(\n",
    "            max_depth=trial.suggest_int('max_depth', 2, 30),\n",
    "            min_samples_split=trial.suggest_int('min_samples_split', 2, 20),\n",
    "            min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == 'RandomForest':\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=trial.suggest_int('n_estimators', 100, 600),\n",
    "            max_depth=trial.suggest_int('max_depth', 3, 30),\n",
    "            min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "            min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 4),\n",
    "            max_features=trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == 'ExtraTrees':\n",
    "        return ExtraTreesClassifier(\n",
    "            n_estimators=trial.suggest_int('n_estimators', 100, 600),\n",
    "            max_depth=trial.suggest_int('max_depth', 3, 30),\n",
    "            min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == 'Bagging':\n",
    "        return BaggingClassifier(\n",
    "            n_estimators=trial.suggest_int('n_estimators', 50, 400),\n",
    "            max_samples=trial.suggest_float('max_samples', 0.5, 1.0),\n",
    "            max_features=trial.suggest_float('max_features', 0.5, 1.0),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == 'Bagged DT':\n",
    "        return BaggingClassifier(\n",
    "            estimator=DecisionTreeClassifier(),\n",
    "            n_estimators=trial.suggest_int('n_estimators', 50, 400),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    # ===== Boosting =====\n",
    "    if name == 'GradientBoosting':\n",
    "        return GradientBoostingClassifier(\n",
    "            n_estimators=trial.suggest_int('n_estimators', 100, 500),\n",
    "            learning_rate=trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "            max_depth=trial.suggest_int('max_depth', 2, 6),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == 'HistGradientBoosting':\n",
    "        return HistGradientBoostingClassifier(\n",
    "            learning_rate=trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "            max_depth=trial.suggest_int('max_depth', 2, 10),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == 'AdaBoost':\n",
    "        return AdaBoostClassifier(\n",
    "            n_estimators=trial.suggest_int('n_estimators', 100, 500),\n",
    "            learning_rate=trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == 'XGBoost':\n",
    "        return XGBClassifier(\n",
    "            n_estimators=trial.suggest_int('n_estimators', 100, 500),\n",
    "            max_depth=trial.suggest_int('max_depth', 3, 10),\n",
    "            learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            subsample=trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            colsample_bytree=trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            eval_metric='logloss',\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    if name == 'LGBMClassifier':\n",
    "        return LGBMClassifier(\n",
    "            n_estimators=trial.suggest_int('n_estimators', 100, 500),\n",
    "            learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            num_leaves=trial.suggest_int('num_leaves', 31, 255),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    # ===== Ensembles =====\n",
    "    if name == 'Hard Voting':\n",
    "        return VotingClassifier(estimators=base_estimators, voting='hard')\n",
    "\n",
    "    if name == 'Soft Voting':\n",
    "        return VotingClassifier(estimators=base_estimators, voting='soft')\n",
    "\n",
    "    if name == 'Stacking':\n",
    "        return StackingClassifier(\n",
    "            estimators=base_estimators,\n",
    "            final_estimator=LogisticRegression(max_iter=1000)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b0517d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def objective(trial, name):\n",
    "\n",
    "    base_model = get_model(trial, name)\n",
    "    model = MultiOutputClassifier(base_model)\n",
    "\n",
    "    y_pred = cross_val_predict(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        cv=kf,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    recall_type = recall_score(\n",
    "        y_train['type'],\n",
    "        y_pred[:, 0],\n",
    "        average='macro'\n",
    "    )\n",
    "\n",
    "    recall_cvss = recall_score(\n",
    "        y_train['cvss_score'],\n",
    "        y_pred[:, 1],\n",
    "        average='macro'\n",
    "    )\n",
    "\n",
    "    return (recall_type + recall_cvss) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9ed54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:03:46,750] A new study created in memory with name: no-name-d86f4222-d6b0-410c-bdd6-e73c34bd88b7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üî• NOW TUNING: Logistic Regression\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:03:49,719] Trial 0 finished with value: 0.5214358858346004 and parameters: {'C': 0.10538748974652203, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5214358858346004.\n",
      "[I 2026-01-17 11:03:52,401] Trial 1 finished with value: 0.5235182854201758 and parameters: {'C': 0.3286854872303982, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.5235182854201758.\n",
      "[I 2026-01-17 11:04:00,537] Trial 2 finished with value: 0.5182944723658953 and parameters: {'C': 0.22815696726795595, 'solver': 'liblinear'}. Best is trial 1 with value: 0.5235182854201758.\n",
      "[I 2026-01-17 11:04:10,398] Trial 3 finished with value: 0.5185208083272399 and parameters: {'C': 1.3040019144118806, 'solver': 'liblinear'}. Best is trial 1 with value: 0.5235182854201758.\n",
      "[I 2026-01-17 11:04:18,123] Trial 4 finished with value: 0.5181019411733838 and parameters: {'C': 0.10436177280780859, 'solver': 'liblinear'}. Best is trial 1 with value: 0.5235182854201758.\n",
      "[I 2026-01-17 11:04:20,384] Trial 5 finished with value: 0.5193126290056637 and parameters: {'C': 0.039532517892229044, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.5235182854201758.\n",
      "[I 2026-01-17 11:04:23,357] Trial 6 finished with value: 0.5248378819526959 and parameters: {'C': 3.1685279290174573, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.5248378819526959.\n",
      "[I 2026-01-17 11:04:25,449] Trial 7 finished with value: 0.5245433754231772 and parameters: {'C': 0.7184779219955345, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.5248378819526959.\n",
      "[I 2026-01-17 11:04:34,675] Trial 8 finished with value: 0.5185650902630912 and parameters: {'C': 1.193418277876312, 'solver': 'liblinear'}. Best is trial 6 with value: 0.5248378819526959.\n",
      "[I 2026-01-17 11:04:36,298] Trial 9 finished with value: 0.5206773322757086 and parameters: {'C': 0.08391283732149246, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.5248378819526959.\n",
      "[I 2026-01-17 11:04:38,705] Trial 10 finished with value: 0.5248863601043036 and parameters: {'C': 7.746637222206949, 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5248863601043036.\n",
      "[I 2026-01-17 11:04:40,942] Trial 11 finished with value: 0.5251087988064514 and parameters: {'C': 6.54228844945378, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.5251087988064514.\n",
      "[I 2026-01-17 11:04:43,325] Trial 12 finished with value: 0.5249082091555377 and parameters: {'C': 8.11374670099886, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.5251087988064514.\n",
      "[I 2026-01-17 11:04:45,967] Trial 13 finished with value: 0.525291895054278 and parameters: {'C': 9.640530386386231, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:04:48,149] Trial 14 finished with value: 0.5248186044411649 and parameters: {'C': 3.1547635458946064, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:04:49,340] Trial 15 finished with value: 0.5180359187596509 and parameters: {'C': 0.012200894522798152, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:04:51,606] Trial 16 finished with value: 0.5250355102558579 and parameters: {'C': 3.199637539747927, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:04:53,981] Trial 17 finished with value: 0.5251517858568684 and parameters: {'C': 8.817424285510928, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:05:03,338] Trial 18 finished with value: 0.518574093980358 and parameters: {'C': 1.8132431644128586, 'solver': 'liblinear'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:05:05,415] Trial 19 finished with value: 0.5241508592060994 and parameters: {'C': 0.5486856392761577, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:05:07,878] Trial 20 finished with value: 0.5249653306387931 and parameters: {'C': 4.822498992197417, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:05:10,306] Trial 21 finished with value: 0.5249039629398262 and parameters: {'C': 9.736065967682132, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:05:12,603] Trial 22 finished with value: 0.5249407057101367 and parameters: {'C': 4.682046390755814, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:05:14,853] Trial 23 finished with value: 0.5248846895808907 and parameters: {'C': 5.297566614267433, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:05:17,144] Trial 24 finished with value: 0.5247843869827166 and parameters: {'C': 2.015728231965264, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:05:19,622] Trial 25 finished with value: 0.5252507842892392 and parameters: {'C': 9.739253807334661, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:05:29,285] Trial 26 finished with value: 0.5187191799490514 and parameters: {'C': 3.1165841086889867, 'solver': 'liblinear'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:05:31,423] Trial 27 finished with value: 0.5245120866496988 and parameters: {'C': 0.8470749538131626, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:05:33,864] Trial 28 finished with value: 0.5251743837069709 and parameters: {'C': 9.08250774669428, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:05:36,093] Trial 29 finished with value: 0.5249624751431275 and parameters: {'C': 2.015758433167418, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.525291895054278.\n",
      "[I 2026-01-17 11:05:41,131] A new study created in memory with name: no-name-20fa901c-09b8-448a-8aa9-aa0c9e0842a6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä RESULTS FOR MODEL: Logistic Regression\n",
      "=======================================================\n",
      "üéØüéØ TARGET: TYPE\n",
      "-------------------------------------------------------\n",
      "üìà Accuracy        : 0.78\n",
      "üß† Precision (mac) : 0.79\n",
      "üîÅ Recall    (mac) : 0.72\n",
      "üèÜ F1-score  (mac) : 0.74\n",
      "üìä K-Fold F1 Mean  : 0.73\n",
      "üìâ K-Fold F1 Std   : 0.00\n",
      "\n",
      "-------------------------------------------------------\n",
      "üéØ TARGET: CVSS_SCORE\n",
      "-------------------------------------------------------\n",
      "üìà Accuracy        : 0.57\n",
      "üß† Precision (mac) : 0.48\n",
      "üîÅ Recall    (mac) : 0.30\n",
      "üèÜ F1-score  (mac) : 0.27\n",
      "üìä K-Fold F1 Mean  : 0.33\n",
      "üìâ K-Fold F1 Std   : 0.00\n",
      "\n",
      "=======================================================\n",
      "üìå MEAN F1 (TYPE + CVSS) / 2 : 0.50\n",
      "=======================================================\n",
      "\n",
      "============================================================\n",
      "üî• NOW TUNING: DecisionTree\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:05:42,338] Trial 0 finished with value: 0.6936605538806662 and parameters: {'max_depth': 12, 'min_samples_split': 19, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.6936605538806662.\n",
      "[I 2026-01-17 11:05:43,850] Trial 1 finished with value: 0.739064710631262 and parameters: {'max_depth': 25, 'min_samples_split': 17, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.739064710631262.\n",
      "[I 2026-01-17 11:05:44,934] Trial 2 finished with value: 0.645574179731276 and parameters: {'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.739064710631262.\n",
      "[I 2026-01-17 11:05:45,668] Trial 3 finished with value: 0.356427856620105 and parameters: {'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.739064710631262.\n",
      "[I 2026-01-17 11:05:46,946] Trial 4 finished with value: 0.7164992091690978 and parameters: {'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.739064710631262.\n",
      "[I 2026-01-17 11:05:48,467] Trial 5 finished with value: 0.7433271767072247 and parameters: {'max_depth': 26, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.7433271767072247.\n",
      "[I 2026-01-17 11:05:49,961] Trial 6 finished with value: 0.739763622696743 and parameters: {'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 5 with value: 0.7433271767072247.\n",
      "[I 2026-01-17 11:05:51,233] Trial 7 finished with value: 0.7188419155405117 and parameters: {'max_depth': 14, 'min_samples_split': 11, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.7433271767072247.\n",
      "[I 2026-01-17 11:05:52,680] Trial 8 finished with value: 0.737759393666471 and parameters: {'max_depth': 23, 'min_samples_split': 15, 'min_samples_leaf': 6}. Best is trial 5 with value: 0.7433271767072247.\n",
      "[I 2026-01-17 11:05:53,980] Trial 9 finished with value: 0.7157908525313046 and parameters: {'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 5 with value: 0.7433271767072247.\n",
      "[I 2026-01-17 11:05:55,492] Trial 10 finished with value: 0.7440328942538545 and parameters: {'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.7440328942538545.\n",
      "[I 2026-01-17 11:05:57,009] Trial 11 finished with value: 0.7439821203568819 and parameters: {'max_depth': 29, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.7440328942538545.\n",
      "[I 2026-01-17 11:05:58,511] Trial 12 finished with value: 0.7448357279044218 and parameters: {'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:05:59,943] Trial 13 finished with value: 0.7348732908869502 and parameters: {'max_depth': 19, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:01,448] Trial 14 finished with value: 0.7431926404665263 and parameters: {'max_depth': 30, 'min_samples_split': 13, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:02,909] Trial 15 finished with value: 0.7346338534455643 and parameters: {'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:04,461] Trial 16 finished with value: 0.7429806366471531 and parameters: {'max_depth': 29, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:05,918] Trial 17 finished with value: 0.7374460201705199 and parameters: {'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:07,387] Trial 18 finished with value: 0.741640464725101 and parameters: {'max_depth': 27, 'min_samples_split': 13, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:08,836] Trial 19 finished with value: 0.7397539677564762 and parameters: {'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:09,599] Trial 20 finished with value: 0.3988019379770097 and parameters: {'max_depth': 4, 'min_samples_split': 15, 'min_samples_leaf': 10}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:11,221] Trial 21 finished with value: 0.7440328942538545 and parameters: {'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:12,736] Trial 22 finished with value: 0.7418325632054986 and parameters: {'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:14,340] Trial 23 finished with value: 0.7435569065012217 and parameters: {'max_depth': 28, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:15,821] Trial 24 finished with value: 0.7408807354768101 and parameters: {'max_depth': 23, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:17,311] Trial 25 finished with value: 0.7418593637619832 and parameters: {'max_depth': 27, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:18,707] Trial 26 finished with value: 0.732576735619223 and parameters: {'max_depth': 18, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:20,345] Trial 27 finished with value: 0.7428924438160955 and parameters: {'max_depth': 25, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:22,741] Trial 28 finished with value: 0.7433433497139368 and parameters: {'max_depth': 30, 'min_samples_split': 12, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:24,459] Trial 29 finished with value: 0.6611893676381068 and parameters: {'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 12 with value: 0.7448357279044218.\n",
      "[I 2026-01-17 11:06:29,668] A new study created in memory with name: no-name-022ab168-1841-4d28-bc67-27d3bac19e32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä RESULTS FOR MODEL: DecisionTree\n",
      "=======================================================\n",
      "üéØüéØ TARGET: TYPE\n",
      "-------------------------------------------------------\n",
      "üìà Accuracy        : 0.93\n",
      "üß† Precision (mac) : 0.92\n",
      "üîÅ Recall    (mac) : 0.91\n",
      "üèÜ F1-score  (mac) : 0.91\n",
      "üìä K-Fold F1 Mean  : 0.94\n",
      "üìâ K-Fold F1 Std   : 0.00\n",
      "\n",
      "-------------------------------------------------------\n",
      "üéØ TARGET: CVSS_SCORE\n",
      "-------------------------------------------------------\n",
      "üìà Accuracy        : 0.49\n",
      "üß† Precision (mac) : 0.37\n",
      "üîÅ Recall    (mac) : 0.36\n",
      "üèÜ F1-score  (mac) : 0.36\n",
      "üìä K-Fold F1 Mean  : 0.56\n",
      "üìâ K-Fold F1 Std   : 0.00\n",
      "\n",
      "=======================================================\n",
      "üìå MEAN F1 (TYPE + CVSS) / 2 : 0.64\n",
      "=======================================================\n",
      "\n",
      "============================================================\n",
      "üî• NOW TUNING: RandomForest\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:06:48,575] Trial 0 finished with value: 0.7182559448535657 and parameters: {'n_estimators': 434, 'max_depth': 29, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7182559448535657.\n",
      "[I 2026-01-17 11:06:52,583] Trial 1 finished with value: 0.6654749261926152 and parameters: {'n_estimators': 135, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 0 with value: 0.7182559448535657.\n",
      "[I 2026-01-17 11:07:10,834] Trial 2 finished with value: 0.7295546199800387 and parameters: {'n_estimators': 512, 'max_depth': 28, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:07:19,619] Trial 3 finished with value: 0.5030320166153281 and parameters: {'n_estimators': 459, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:07:34,172] Trial 4 finished with value: 0.7060614460212098 and parameters: {'n_estimators': 470, 'max_depth': 21, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:07:41,586] Trial 5 finished with value: 0.5530072261526275 and parameters: {'n_estimators': 421, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:07:54,179] Trial 6 finished with value: 0.6690474890776061 and parameters: {'n_estimators': 460, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:08:09,097] Trial 7 finished with value: 0.7205589123800635 and parameters: {'n_estimators': 406, 'max_depth': 24, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:08:14,805] Trial 8 finished with value: 0.6864878383277742 and parameters: {'n_estimators': 188, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:08:31,448] Trial 9 finished with value: 0.7151903996484624 and parameters: {'n_estimators': 509, 'max_depth': 27, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:08:40,248] Trial 10 finished with value: 0.7020012439012441 and parameters: {'n_estimators': 285, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:09:00,730] Trial 11 finished with value: 0.7206520510435781 and parameters: {'n_estimators': 564, 'max_depth': 24, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:09:22,831] Trial 12 finished with value: 0.7250990237676778 and parameters: {'n_estimators': 596, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:09:44,872] Trial 13 finished with value: 0.7250617769487663 and parameters: {'n_estimators': 597, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:09:55,254] Trial 14 finished with value: 0.7146910530595236 and parameters: {'n_estimators': 315, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:10:00,177] Trial 15 finished with value: 0.3046311059413646 and parameters: {'n_estimators': 538, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:10:21,564] Trial 16 finished with value: 0.71846785288418 and parameters: {'n_estimators': 596, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:10:37,791] Trial 17 finished with value: 0.7082436413796914 and parameters: {'n_estimators': 515, 'max_depth': 27, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:10:52,239] Trial 18 finished with value: 0.7250773747502022 and parameters: {'n_estimators': 377, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:11:02,749] Trial 19 finished with value: 0.6988798959960572 and parameters: {'n_estimators': 344, 'max_depth': 23, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:11:10,408] Trial 20 finished with value: 0.6998225756223024 and parameters: {'n_estimators': 254, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:11:24,737] Trial 21 finished with value: 0.7251135777591959 and parameters: {'n_estimators': 372, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:11:45,580] Trial 22 finished with value: 0.7245089710340367 and parameters: {'n_estimators': 549, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:12:04,038] Trial 23 finished with value: 0.725350231852757 and parameters: {'n_estimators': 490, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:12:27,852] Trial 24 finished with value: 0.7292870183324182 and parameters: {'n_estimators': 494, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.7295546199800387.\n",
      "[I 2026-01-17 11:12:46,445] Trial 25 finished with value: 0.7295918410310667 and parameters: {'n_estimators': 488, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 25 with value: 0.7295918410310667.\n",
      "[I 2026-01-17 11:13:05,451] Trial 26 finished with value: 0.7230477737345813 and parameters: {'n_estimators': 514, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 25 with value: 0.7295918410310667.\n",
      "[I 2026-01-17 11:13:21,804] Trial 27 finished with value: 0.7375650714390046 and parameters: {'n_estimators': 412, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 27 with value: 0.7375650714390046.\n",
      "[I 2026-01-17 11:13:33,329] Trial 28 finished with value: 0.6996364346877553 and parameters: {'n_estimators': 388, 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 27 with value: 0.7375650714390046.\n",
      "[I 2026-01-17 11:13:51,167] Trial 29 finished with value: 0.7423821743318446 and parameters: {'n_estimators': 442, 'max_depth': 28, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 29 with value: 0.7423821743318446.\n",
      "[I 2026-01-17 11:14:18,391] A new study created in memory with name: no-name-eb954607-e3f3-4847-b69f-c0c3704c158f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä RESULTS FOR MODEL: RandomForest\n",
      "=======================================================\n",
      "üéØüéØ TARGET: TYPE\n",
      "-------------------------------------------------------\n",
      "üìà Accuracy        : 0.94\n",
      "üß† Precision (mac) : 0.94\n",
      "üîÅ Recall    (mac) : 0.88\n",
      "üèÜ F1-score  (mac) : 0.91\n",
      "üìä K-Fold F1 Mean  : 0.92\n",
      "üìâ K-Fold F1 Std   : 0.00\n",
      "\n",
      "-------------------------------------------------------\n",
      "üéØ TARGET: CVSS_SCORE\n",
      "-------------------------------------------------------\n",
      "üìà Accuracy        : 0.68\n",
      "üß† Precision (mac) : 0.72\n",
      "üîÅ Recall    (mac) : 0.46\n",
      "üèÜ F1-score  (mac) : 0.50\n",
      "üìä K-Fold F1 Mean  : 0.63\n",
      "üìâ K-Fold F1 Std   : 0.00\n",
      "\n",
      "=======================================================\n",
      "üìå MEAN F1 (TYPE + CVSS) / 2 : 0.70\n",
      "=======================================================\n",
      "\n",
      "============================================================\n",
      "üî• NOW TUNING: ExtraTrees\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:14:20,527] Trial 0 finished with value: 0.45631281241825705 and parameters: {'n_estimators': 249, 'max_depth': 9, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.45631281241825705.\n",
      "[I 2026-01-17 11:14:22,130] Trial 1 finished with value: 0.47774278490452055 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.47774278490452055.\n",
      "[I 2026-01-17 11:14:25,752] Trial 2 finished with value: 0.4118738052456574 and parameters: {'n_estimators': 583, 'max_depth': 7, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.47774278490452055.\n",
      "[I 2026-01-17 11:14:28,986] Trial 3 finished with value: 0.6167060960735498 and parameters: {'n_estimators': 273, 'max_depth': 15, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.6167060960735498.\n",
      "[I 2026-01-17 11:14:31,924] Trial 4 finished with value: 0.29309124628930966 and parameters: {'n_estimators': 406, 'max_depth': 4, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.6167060960735498.\n",
      "[I 2026-01-17 11:14:36,962] Trial 5 finished with value: 0.6117356488655636 and parameters: {'n_estimators': 460, 'max_depth': 15, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.6167060960735498.\n",
      "[I 2026-01-17 11:14:41,592] Trial 6 finished with value: 0.5781619780519123 and parameters: {'n_estimators': 456, 'max_depth': 14, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.6167060960735498.\n",
      "[I 2026-01-17 11:14:46,224] Trial 7 finished with value: 0.6578785356363825 and parameters: {'n_estimators': 374, 'max_depth': 19, 'min_samples_leaf': 4}. Best is trial 7 with value: 0.6578785356363825.\n",
      "[I 2026-01-17 11:14:53,424] Trial 8 finished with value: 0.6842363290397564 and parameters: {'n_estimators': 535, 'max_depth': 23, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.6842363290397564.\n",
      "[I 2026-01-17 11:14:58,075] Trial 9 finished with value: 0.6843523061325215 and parameters: {'n_estimators': 325, 'max_depth': 23, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.6843523061325215.\n",
      "[I 2026-01-17 11:15:01,031] Trial 10 finished with value: 0.7234438683941987 and parameters: {'n_estimators': 132, 'max_depth': 30, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.7234438683941987.\n",
      "[I 2026-01-17 11:15:03,480] Trial 11 finished with value: 0.7238649697869511 and parameters: {'n_estimators': 102, 'max_depth': 30, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.7238649697869511.\n",
      "[I 2026-01-17 11:15:06,359] Trial 12 finished with value: 0.721074058880852 and parameters: {'n_estimators': 128, 'max_depth': 29, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.7238649697869511.\n",
      "[I 2026-01-17 11:15:10,637] Trial 13 finished with value: 0.7242670605399869 and parameters: {'n_estimators': 197, 'max_depth': 30, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:15:14,289] Trial 14 finished with value: 0.701181244224151 and parameters: {'n_estimators': 207, 'max_depth': 26, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:15:17,856] Trial 15 finished with value: 0.7012618485017064 and parameters: {'n_estimators': 205, 'max_depth': 26, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:15:19,770] Trial 16 finished with value: 0.6763347041139263 and parameters: {'n_estimators': 108, 'max_depth': 19, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:15:23,133] Trial 17 finished with value: 0.7028601636473788 and parameters: {'n_estimators': 188, 'max_depth': 27, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:15:28,124] Trial 18 finished with value: 0.7058717133161525 and parameters: {'n_estimators': 297, 'max_depth': 23, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:15:32,608] Trial 19 finished with value: 0.7071388839489117 and parameters: {'n_estimators': 238, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:15:35,702] Trial 20 finished with value: 0.6778243726032798 and parameters: {'n_estimators': 169, 'max_depth': 19, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:15:38,248] Trial 21 finished with value: 0.723515018446701 and parameters: {'n_estimators': 106, 'max_depth': 30, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:15:40,591] Trial 22 finished with value: 0.7172877260802001 and parameters: {'n_estimators': 100, 'max_depth': 27, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:15:43,621] Trial 23 finished with value: 0.7046149093145915 and parameters: {'n_estimators': 163, 'max_depth': 28, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:15:47,913] Trial 24 finished with value: 0.7116881589619146 and parameters: {'n_estimators': 228, 'max_depth': 25, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:15:50,876] Trial 25 finished with value: 0.7070630043737767 and parameters: {'n_estimators': 150, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:15:53,032] Trial 26 finished with value: 0.7085839246860046 and parameters: {'n_estimators': 100, 'max_depth': 24, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:15:56,043] Trial 27 finished with value: 0.6761295161868173 and parameters: {'n_estimators': 190, 'max_depth': 20, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:16:01,505] Trial 28 finished with value: 0.7203812844626656 and parameters: {'n_estimators': 280, 'max_depth': 28, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:16:03,953] Trial 29 finished with value: 0.5190446929169308 and parameters: {'n_estimators': 240, 'max_depth': 12, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.7242670605399869.\n",
      "[I 2026-01-17 11:16:10,234] A new study created in memory with name: no-name-1535694c-9119-4430-8ddd-b8f898718f82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä RESULTS FOR MODEL: ExtraTrees\n",
      "=======================================================\n",
      "üéØüéØ TARGET: TYPE\n",
      "-------------------------------------------------------\n",
      "üìà Accuracy        : 0.93\n",
      "üß† Precision (mac) : 0.92\n",
      "üîÅ Recall    (mac) : 0.85\n",
      "üèÜ F1-score  (mac) : 0.87\n",
      "üìä K-Fold F1 Mean  : 0.89\n",
      "üìâ K-Fold F1 Std   : 0.00\n",
      "\n",
      "-------------------------------------------------------\n",
      "üéØ TARGET: CVSS_SCORE\n",
      "-------------------------------------------------------\n",
      "üìà Accuracy        : 0.66\n",
      "üß† Precision (mac) : 0.60\n",
      "üîÅ Recall    (mac) : 0.48\n",
      "üèÜ F1-score  (mac) : 0.51\n",
      "üìä K-Fold F1 Mean  : 0.63\n",
      "üìâ K-Fold F1 Std   : 0.00\n",
      "\n",
      "=======================================================\n",
      "üìå MEAN F1 (TYPE + CVSS) / 2 : 0.69\n",
      "=======================================================\n",
      "\n",
      "============================================================\n",
      "üî• NOW TUNING: Bagging\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 11:17:24,858] Trial 0 finished with value: 0.7606890466558739 and parameters: {'n_estimators': 202, 'max_samples': 0.7515379893026695, 'max_features': 0.6021710088428585}. Best is trial 0 with value: 0.7606890466558739.\n",
      "[I 2026-01-17 11:19:19,968] Trial 1 finished with value: 0.7550448811346854 and parameters: {'n_estimators': 333, 'max_samples': 0.75088009565467, 'max_features': 0.5743405689739394}. Best is trial 0 with value: 0.7606890466558739.\n",
      "[I 2026-01-17 11:22:00,592] Trial 2 finished with value: 0.7712048451485611 and parameters: {'n_estimators': 295, 'max_samples': 0.7795760272394714, 'max_features': 0.8927569321734097}. Best is trial 2 with value: 0.7712048451485611.\n",
      "[I 2026-01-17 11:25:27,275] Trial 3 finished with value: 0.7715542618058419 and parameters: {'n_estimators': 376, 'max_samples': 0.8031005971973714, 'max_features': 0.8954462467161454}. Best is trial 3 with value: 0.7715542618058419.\n",
      "[I 2026-01-17 11:28:09,634] Trial 4 finished with value: 0.7589705711720676 and parameters: {'n_estimators': 399, 'max_samples': 0.9710604892403715, 'max_features': 0.5738089468104115}. Best is trial 3 with value: 0.7715542618058419.\n",
      "[I 2026-01-17 11:29:29,109] Trial 5 finished with value: 0.769940588055972 and parameters: {'n_estimators': 147, 'max_samples': 0.7479293128180429, 'max_features': 0.9264082495606036}. Best is trial 3 with value: 0.7715542618058419.\n",
      "[I 2026-01-17 11:30:38,507] Trial 6 finished with value: 0.7708157660659185 and parameters: {'n_estimators': 124, 'max_samples': 0.8220342218068425, 'max_features': 0.8780979637499879}. Best is trial 3 with value: 0.7715542618058419.\n",
      "[I 2026-01-17 11:32:51,716] Trial 7 finished with value: 0.76554511279546 and parameters: {'n_estimators': 187, 'max_samples': 0.9413291103346431, 'max_features': 0.6436521187559192}. Best is trial 3 with value: 0.7715542618058419.\n",
      "[I 2026-01-17 11:36:05,170] Trial 8 finished with value: 0.7666375084032884 and parameters: {'n_estimators': 302, 'max_samples': 0.5981102074570788, 'max_features': 0.8630611668053823}. Best is trial 3 with value: 0.7715542618058419.\n",
      "[I 2026-01-17 11:39:52,668] Trial 9 finished with value: 0.7723507316466398 and parameters: {'n_estimators': 303, 'max_samples': 0.908871911272835, 'max_features': 0.9315942669372199}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 11:40:28,842] Trial 10 finished with value: 0.7646881010339355 and parameters: {'n_estimators': 58, 'max_samples': 0.5376160387641806, 'max_features': 0.9924984379305246}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 11:43:48,060] Trial 11 finished with value: 0.7700043938100223 and parameters: {'n_estimators': 371, 'max_samples': 0.876073763865538, 'max_features': 0.7656493039894305}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 11:47:17,609] Trial 12 finished with value: 0.7702474388986605 and parameters: {'n_estimators': 260, 'max_samples': 0.8902421568727372, 'max_features': 0.7820277012242726}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 11:50:56,982] Trial 13 finished with value: 0.76844623438334 and parameters: {'n_estimators': 357, 'max_samples': 0.6793587242497571, 'max_features': 0.9832150294628215}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 11:53:46,014] Trial 14 finished with value: 0.7708951679091618 and parameters: {'n_estimators': 251, 'max_samples': 0.8655140953319311, 'max_features': 0.8288157479531645}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 11:57:16,203] Trial 15 finished with value: 0.7670760386153014 and parameters: {'n_estimators': 329, 'max_samples': 0.993161202909776, 'max_features': 0.6922527742187725}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 12:00:18,362] Trial 16 finished with value: 0.7688298561719908 and parameters: {'n_estimators': 282, 'max_samples': 0.6651663646935189, 'max_features': 0.9352857117194334}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 12:05:12,819] Trial 17 finished with value: 0.7711211538685285 and parameters: {'n_estimators': 391, 'max_samples': 0.9173328777692172, 'max_features': 0.8173383188930776}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 12:08:42,705] Trial 18 finished with value: 0.7657295114719127 and parameters: {'n_estimators': 336, 'max_samples': 0.8214360593472064, 'max_features': 0.7023704530275814}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 12:11:37,383] Trial 19 finished with value: 0.7705997210956057 and parameters: {'n_estimators': 228, 'max_samples': 0.823375939680721, 'max_features': 0.941806134523657}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 12:13:24,257] Trial 20 finished with value: 0.7441952346311971 and parameters: {'n_estimators': 310, 'max_samples': 0.6750274272743736, 'max_features': 0.5150858232815257}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 12:16:31,772] Trial 21 finished with value: 0.7704092208393356 and parameters: {'n_estimators': 284, 'max_samples': 0.7767567853267083, 'max_features': 0.9057394871156083}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 12:20:04,993] Trial 22 finished with value: 0.7693718050620489 and parameters: {'n_estimators': 361, 'max_samples': 0.7082219573258025, 'max_features': 0.8735101423649899}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 12:23:00,272] Trial 23 finished with value: 0.7700841880268251 and parameters: {'n_estimators': 265, 'max_samples': 0.8022902399266725, 'max_features': 0.8166294029089203}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 12:27:02,133] Trial 24 finished with value: 0.7720377248957535 and parameters: {'n_estimators': 306, 'max_samples': 0.8560959761829486, 'max_features': 0.9624840501847085}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 12:31:13,871] Trial 25 finished with value: 0.7712384914773549 and parameters: {'n_estimators': 329, 'max_samples': 0.8575620966863235, 'max_features': 0.9643809797321695}. Best is trial 9 with value: 0.7723507316466398.\n",
      "[I 2026-01-17 12:37:03,095] Trial 26 finished with value: 0.77235124642833 and parameters: {'n_estimators': 377, 'max_samples': 0.9498869117037269, 'max_features': 0.996932379397286}. Best is trial 26 with value: 0.77235124642833.\n",
      "[I 2026-01-17 12:39:59,704] Trial 27 finished with value: 0.7718229183344419 and parameters: {'n_estimators': 228, 'max_samples': 0.9407612175474505, 'max_features': 0.9978392153872393}. Best is trial 26 with value: 0.77235124642833.\n",
      "[I 2026-01-17 12:44:37,600] Trial 28 finished with value: 0.7722375424076424 and parameters: {'n_estimators': 347, 'max_samples': 0.9091318534708142, 'max_features': 0.9447382165948138}. Best is trial 26 with value: 0.77235124642833.\n",
      "[I 2026-01-17 12:48:40,774] Trial 29 finished with value: 0.7713499219130233 and parameters: {'n_estimators': 357, 'max_samples': 0.9209926688747342, 'max_features': 0.8420294099475615}. Best is trial 26 with value: 0.77235124642833.\n",
      "[I 2026-01-17 13:01:17,327] A new study created in memory with name: no-name-9b4f3cb3-7488-4281-bd3b-0f544117a25f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä RESULTS FOR MODEL: Bagging\n",
      "=======================================================\n",
      "üéØüéØ TARGET: TYPE\n",
      "-------------------------------------------------------\n",
      "üìà Accuracy        : 0.94\n",
      "üß† Precision (mac) : 0.93\n",
      "üîÅ Recall    (mac) : 0.93\n",
      "üèÜ F1-score  (mac) : 0.93\n",
      "üìä K-Fold F1 Mean  : 0.95\n",
      "üìâ K-Fold F1 Std   : 0.00\n",
      "\n",
      "-------------------------------------------------------\n",
      "üéØ TARGET: CVSS_SCORE\n",
      "-------------------------------------------------------\n",
      "üìà Accuracy        : 0.61\n",
      "üß† Precision (mac) : 0.62\n",
      "üîÅ Recall    (mac) : 0.41\n",
      "üèÜ F1-score  (mac) : 0.43\n",
      "üìä K-Fold F1 Mean  : 0.64\n",
      "üìâ K-Fold F1 Std   : 0.00\n",
      "\n",
      "=======================================================\n",
      "üìå MEAN F1 (TYPE + CVSS) / 2 : 0.68\n",
      "=======================================================\n",
      "\n",
      "============================================================\n",
      "üî• NOW TUNING: Bagged DT\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 13:04:43,639] Trial 0 finished with value: 0.7716735680221729 and parameters: {'n_estimators': 228}. Best is trial 0 with value: 0.7716735680221729.\n",
      "[I 2026-01-17 13:05:55,124] Trial 1 finished with value: 0.7709765595469276 and parameters: {'n_estimators': 86}. Best is trial 0 with value: 0.7716735680221729.\n",
      "[I 2026-01-17 13:07:10,287] Trial 2 finished with value: 0.7713206623722857 and parameters: {'n_estimators': 81}. Best is trial 0 with value: 0.7716735680221729.\n",
      "[I 2026-01-17 13:12:18,452] Trial 3 finished with value: 0.771593061918053 and parameters: {'n_estimators': 324}. Best is trial 0 with value: 0.7716735680221729.\n",
      "[I 2026-01-17 13:14:54,848] Trial 4 finished with value: 0.771539818041038 and parameters: {'n_estimators': 188}. Best is trial 0 with value: 0.7716735680221729.\n",
      "[I 2026-01-17 13:20:21,110] Trial 5 finished with value: 0.7719989681566057 and parameters: {'n_estimators': 377}. Best is trial 5 with value: 0.7719989681566057.\n",
      "[I 2026-01-17 13:26:27,236] Trial 6 finished with value: 0.7719403211196086 and parameters: {'n_estimators': 400}. Best is trial 5 with value: 0.7719989681566057.\n",
      "[I 2026-01-17 13:28:34,080] Trial 7 finished with value: 0.771263203344728 and parameters: {'n_estimators': 135}. Best is trial 5 with value: 0.7719989681566057.\n",
      "[I 2026-01-17 13:30:20,039] Trial 8 finished with value: 0.7717909889862895 and parameters: {'n_estimators': 105}. Best is trial 5 with value: 0.7719989681566057.\n",
      "[I 2026-01-17 13:36:01,168] Trial 9 finished with value: 0.7717630287015497 and parameters: {'n_estimators': 389}. Best is trial 5 with value: 0.7719989681566057.\n",
      "[I 2026-01-17 13:39:55,504] Trial 10 finished with value: 0.7719359623990685 and parameters: {'n_estimators': 288}. Best is trial 5 with value: 0.7719989681566057.\n",
      "[I 2026-01-17 13:46:20,593] Trial 11 finished with value: 0.771920966297511 and parameters: {'n_estimators': 397}. Best is trial 5 with value: 0.7719989681566057.\n",
      "[I 2026-01-17 13:52:17,684] Trial 12 finished with value: 0.7715766395878236 and parameters: {'n_estimators': 329}. Best is trial 5 with value: 0.7719989681566057.\n",
      "[I 2026-01-17 13:56:57,208] Trial 13 finished with value: 0.771823563644404 and parameters: {'n_estimators': 354}. Best is trial 5 with value: 0.7719989681566057.\n",
      "[I 2026-01-17 13:59:55,426] Trial 14 finished with value: 0.7715439288966942 and parameters: {'n_estimators': 250}. Best is trial 5 with value: 0.7719989681566057.\n",
      "[I 2026-01-17 14:03:24,672] Trial 15 finished with value: 0.7719999596939104 and parameters: {'n_estimators': 291}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 14:07:03,929] Trial 16 finished with value: 0.7715806110419733 and parameters: {'n_estimators': 276}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 14:09:22,014] Trial 17 finished with value: 0.7716092228780582 and parameters: {'n_estimators': 170}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 14:13:29,173] Trial 18 finished with value: 0.7717281661746362 and parameters: {'n_estimators': 346}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 14:17:17,811] Trial 19 finished with value: 0.7719999596939104 and parameters: {'n_estimators': 291}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 14:21:00,916] Trial 20 finished with value: 0.7719507876254725 and parameters: {'n_estimators': 298}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 14:24:11,578] Trial 21 finished with value: 0.771753241473863 and parameters: {'n_estimators': 256}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 14:28:11,279] Trial 22 finished with value: 0.7717182398612483 and parameters: {'n_estimators': 307}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 14:30:43,521] Trial 23 finished with value: 0.7714083234430423 and parameters: {'n_estimators': 212}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 14:35:25,243] Trial 24 finished with value: 0.7718374975513544 and parameters: {'n_estimators': 356}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 14:38:37,115] Trial 25 finished with value: 0.7715672565724503 and parameters: {'n_estimators': 269}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 14:44:04,780] Trial 26 finished with value: 0.7719750354312787 and parameters: {'n_estimators': 367}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 14:48:12,217] Trial 27 finished with value: 0.7717174125874119 and parameters: {'n_estimators': 314}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 14:51:53,791] Trial 28 finished with value: 0.7716467611050026 and parameters: {'n_estimators': 230}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 14:56:06,858] Trial 29 finished with value: 0.7716348374804113 and parameters: {'n_estimators': 235}. Best is trial 15 with value: 0.7719999596939104.\n",
      "[I 2026-01-17 15:08:40,112] A new study created in memory with name: no-name-71587919-42a5-45f3-82fd-90492a746349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä RESULTS FOR MODEL: Bagged DT\n",
      "=======================================================\n",
      "üéØüéØ TARGET: TYPE\n",
      "-------------------------------------------------------\n",
      "üìà Accuracy        : 0.93\n",
      "üß† Precision (mac) : 0.92\n",
      "üîÅ Recall    (mac) : 0.92\n",
      "üèÜ F1-score  (mac) : 0.92\n",
      "üìä K-Fold F1 Mean  : 0.95\n",
      "üìâ K-Fold F1 Std   : 0.00\n",
      "\n",
      "-------------------------------------------------------\n",
      "üéØ TARGET: CVSS_SCORE\n",
      "-------------------------------------------------------\n",
      "üìà Accuracy        : 0.59\n",
      "üß† Precision (mac) : 0.57\n",
      "üîÅ Recall    (mac) : 0.41\n",
      "üèÜ F1-score  (mac) : 0.42\n",
      "üìä K-Fold F1 Mean  : 0.64\n",
      "üìâ K-Fold F1 Std   : 0.00\n",
      "\n",
      "=======================================================\n",
      "üìå MEAN F1 (TYPE + CVSS) / 2 : 0.67\n",
      "=======================================================\n",
      "\n",
      "============================================================\n",
      "üî• NOW TUNING: GradientBoosting\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-17 15:19:07,886] Trial 0 finished with value: 0.716202703475722 and parameters: {'n_estimators': 248, 'learning_rate': 0.013608700544063471, 'max_depth': 4}. Best is trial 0 with value: 0.716202703475722.\n",
      "[I 2026-01-17 15:31:26,379] Trial 1 finished with value: 0.7685906384053242 and parameters: {'n_estimators': 198, 'learning_rate': 0.12167376249832161, 'max_depth': 6}. Best is trial 1 with value: 0.7685906384053242.\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    'Logistic Regression', 'DecisionTree', 'RandomForest', 'ExtraTrees', 'Bagging', \n",
    "    'Bagged DT', 'GradientBoosting', 'HistGradientBoosting', 'AdaBoost', 'XGBoost',\n",
    "    'LGBMClassifier', 'Hard Voting', 'Soft Voting', 'Stacking'\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for name in models:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"üî• NOW TUNING: {name}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, name), n_trials=30)\n",
    "\n",
    "    best_base = get_model(study.best_trial, name)\n",
    "    best_model = MultiOutputClassifier(best_base)\n",
    "\n",
    "    best_model.fit(x_train, y_train)\n",
    "    y_pred = best_model.predict(x_test)\n",
    "\n",
    "\n",
    "    # ===== TYPE =====\n",
    "    acc_type  = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "    prec_type = precision_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "    rec_type  = recall_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "    f1_type   = f1_score(y_test['type'], y_pred[:,0], average='macro')\n",
    "\n",
    "    type_scores = cross_val_score(best_base, x_train, y_train['type'], cv=kf, scoring='f1_macro', n_jobs=-1)\n",
    "    type_kf_mean = type_scores.mean()\n",
    "    type_kf_std = type_scores.std()\n",
    "\n",
    "    # ===== CVSS =====\n",
    "    acc_cvss  = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "    prec_cvss = precision_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "    rec_cvss  = recall_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "    f1_cvss   = f1_score(y_test['cvss_score'], y_pred[:,1], average='macro')\n",
    "\n",
    "    cvss_scores = cross_val_score(best_base, x_train, y_train['cvss_score'], cv=kf, scoring='f1_macro', n_jobs=-1)\n",
    "    cvss_kf_mean = cvss_scores.mean()\n",
    "    cvss_kf_std = cvss_scores.std()\n",
    "\n",
    "    # ===== MEAN =====\n",
    "    f1_mean = (f1_type + f1_cvss) / 2\n",
    "\n",
    "    # ===== PRINT RESULTS =====\n",
    "    print(f\"\\nüìä RESULTS FOR MODEL: {name}\")\n",
    "    print(\"=\" * 55)\n",
    "\n",
    "    # ===================== TYPE =====================\n",
    "    print(\"üéØüéØ TARGET: TYPE\")\n",
    "    print(\"-\" * 55)\n",
    "    print(f\"üìà Accuracy        : {acc_type:.2f}\")\n",
    "    print(f\"üß† Precision (mac) : {prec_type:.2f}\")\n",
    "    print(f\"üîÅ Recall    (mac) : {rec_type:.2f}\")\n",
    "    print(f\"üèÜ F1-score  (mac) : {f1_type:.2f}\")\n",
    "    print(f\"üìä K-Fold F1 Mean  : {type_kf_mean:.2f}\")\n",
    "    print(f\"üìâ K-Fold F1 Std   : {type_kf_std:.2f}\")\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 55)\n",
    "\n",
    "    # ===================== CVSS =====================\n",
    "    print(\"üéØ TARGET: CVSS_SCORE\")\n",
    "    print(\"-\" * 55)\n",
    "    print(f\"üìà Accuracy        : {acc_cvss:.2f}\")\n",
    "    print(f\"üß† Precision (mac) : {prec_cvss:.2f}\")\n",
    "    print(f\"üîÅ Recall    (mac) : {rec_cvss:.2f}\")\n",
    "    print(f\"üèÜ F1-score  (mac) : {f1_cvss:.2f}\")\n",
    "    print(f\"üìä K-Fold F1 Mean  : {cvss_kf_mean:.2f}\")\n",
    "    print(f\"üìâ K-Fold F1 Std   : {cvss_kf_std:.2f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 55)\n",
    "    print(f\"üìå MEAN F1 (TYPE + CVSS) / 2 : {f1_mean:.2f}\")\n",
    "    print(\"=\" * 55)\n",
    "\n",
    "\n",
    "    results.append([\n",
    "        name,\n",
    "\n",
    "        # ===== TYPE =====\n",
    "        acc_type,\n",
    "        prec_type,\n",
    "        rec_type,\n",
    "        f1_type,\n",
    "        type_kf_mean,\n",
    "        type_kf_std,\n",
    "\n",
    "        # ===== CVSS =====\n",
    "        acc_cvss,\n",
    "        prec_cvss,\n",
    "        rec_cvss,\n",
    "        f1_cvss,\n",
    "        cvss_kf_mean,\n",
    "        cvss_kf_std\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b136f127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                            Optuna                                            </span>\n",
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Algorithm            </span>‚îÉ<span style=\"font-weight: bold\"> Accuracy </span>‚îÉ<span style=\"font-weight: bold\"> Precision </span>‚îÉ<span style=\"font-weight: bold\"> Recall </span>‚îÉ<span style=\"font-weight: bold\"> F1-score </span>‚îÉ<span style=\"font-weight: bold\"> K-Fold mean </span>‚îÉ<span style=\"font-weight: bold\"> K-Fold std </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">SGDC</span>                 ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.38</span>     ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.38</span>      ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>   ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.55</span>     ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.33</span>        ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span>       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Stacking             ‚îÇ 0.89     ‚îÇ 0.86      ‚îÇ 0.83   ‚îÇ 0.85     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagged DT            ‚îÇ 0.88     ‚îÇ 0.85      ‚îÇ 0.83   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagging              ‚îÇ 0.89     ‚îÇ 0.86      ‚îÇ 0.83   ‚îÇ 0.85     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ LGBMClassifier       ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.83   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ GradientBoosting     ‚îÇ 0.88     ‚îÇ 0.85      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ HistGradientBoosting ‚îÇ 0.87     ‚îÇ 0.84      ‚îÇ 0.82   ‚îÇ 0.83     ‚îÇ 0.89        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Soft Voting          ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ CatBoost             ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ XGBoost              ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Hard Voting          ‚îÇ 0.88     ‚îÇ 0.85      ‚îÇ 0.82   ‚îÇ 0.83     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RandomForest         ‚îÇ 0.88     ‚îÇ 0.87      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ ExtraTrees           ‚îÇ 0.87     ‚îÇ 0.84      ‚îÇ 0.81   ‚îÇ 0.83     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ SVC                  ‚îÇ 0.84     ‚îÇ 0.77      ‚îÇ 0.81   ‚îÇ 0.79     ‚îÇ 0.84        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ DecisionTree         ‚îÇ 0.85     ‚îÇ 0.81      ‚îÇ 0.80   ‚îÇ 0.80     ‚îÇ 0.86        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ AdaBoost             ‚îÇ 0.83     ‚îÇ 0.76      ‚îÇ 0.80   ‚îÇ 0.78     ‚îÇ 0.83        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Passive Aggressive   ‚îÇ 0.76     ‚îÇ 0.65      ‚îÇ 0.79   ‚îÇ 0.71     ‚îÇ 0.73        ‚îÇ 0.02       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ KNN                  ‚îÇ 0.78     ‚îÇ 0.68      ‚îÇ 0.79   ‚îÇ 0.73     ‚îÇ 0.83        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ MLPC                 ‚îÇ 0.84     ‚îÇ 0.78      ‚îÇ 0.78   ‚îÇ 0.78     ‚îÇ 0.85        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Logistic Regression  ‚îÇ 0.79     ‚îÇ 0.70      ‚îÇ 0.77   ‚îÇ 0.74     ‚îÇ 0.79        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RidgeClassifier      ‚îÇ 0.80     ‚îÇ 0.71      ‚îÇ 0.77   ‚îÇ 0.74     ‚îÇ 0.79        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">DummyClassifier</span>      ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.62</span>     ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>      ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>   ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>     ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.33</span>        ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>       ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                            Optuna                                            \u001b[0m\n",
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mAlgorithm           \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mAccuracy\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mPrecision\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mRecall\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mF1-score\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mK-Fold mean\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mK-Fold std\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ \u001b[1;32mSGDC\u001b[0m                 ‚îÇ \u001b[1;32m0.38\u001b[0m     ‚îÇ \u001b[1;32m0.38\u001b[0m      ‚îÇ \u001b[1;32m1.00\u001b[0m   ‚îÇ \u001b[1;32m0.55\u001b[0m     ‚îÇ \u001b[1;32m0.33\u001b[0m        ‚îÇ \u001b[1;32m0.00\u001b[0m       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Stacking             ‚îÇ 0.89     ‚îÇ 0.86      ‚îÇ 0.83   ‚îÇ 0.85     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagged DT            ‚îÇ 0.88     ‚îÇ 0.85      ‚îÇ 0.83   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagging              ‚îÇ 0.89     ‚îÇ 0.86      ‚îÇ 0.83   ‚îÇ 0.85     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ LGBMClassifier       ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.83   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ GradientBoosting     ‚îÇ 0.88     ‚îÇ 0.85      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ HistGradientBoosting ‚îÇ 0.87     ‚îÇ 0.84      ‚îÇ 0.82   ‚îÇ 0.83     ‚îÇ 0.89        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Soft Voting          ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ CatBoost             ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ XGBoost              ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Hard Voting          ‚îÇ 0.88     ‚îÇ 0.85      ‚îÇ 0.82   ‚îÇ 0.83     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RandomForest         ‚îÇ 0.88     ‚îÇ 0.87      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ ExtraTrees           ‚îÇ 0.87     ‚îÇ 0.84      ‚îÇ 0.81   ‚îÇ 0.83     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ SVC                  ‚îÇ 0.84     ‚îÇ 0.77      ‚îÇ 0.81   ‚îÇ 0.79     ‚îÇ 0.84        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ DecisionTree         ‚îÇ 0.85     ‚îÇ 0.81      ‚îÇ 0.80   ‚îÇ 0.80     ‚îÇ 0.86        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ AdaBoost             ‚îÇ 0.83     ‚îÇ 0.76      ‚îÇ 0.80   ‚îÇ 0.78     ‚îÇ 0.83        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Passive Aggressive   ‚îÇ 0.76     ‚îÇ 0.65      ‚îÇ 0.79   ‚îÇ 0.71     ‚îÇ 0.73        ‚îÇ 0.02       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ KNN                  ‚îÇ 0.78     ‚îÇ 0.68      ‚îÇ 0.79   ‚îÇ 0.73     ‚îÇ 0.83        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ MLPC                 ‚îÇ 0.84     ‚îÇ 0.78      ‚îÇ 0.78   ‚îÇ 0.78     ‚îÇ 0.85        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Logistic Regression  ‚îÇ 0.79     ‚îÇ 0.70      ‚îÇ 0.77   ‚îÇ 0.74     ‚îÇ 0.79        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RidgeClassifier      ‚îÇ 0.80     ‚îÇ 0.71      ‚îÇ 0.77   ‚îÇ 0.74     ‚îÇ 0.79        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ \u001b[1;31mDummyClassifier\u001b[0m      ‚îÇ \u001b[1;31m0.62\u001b[0m     ‚îÇ \u001b[1;31m0.00\u001b[0m      ‚îÇ \u001b[1;31m0.00\u001b[0m   ‚îÇ \u001b[1;31m0.00\u001b[0m     ‚îÇ \u001b[1;31m0.33\u001b[0m        ‚îÇ \u001b[1;31m0.00\u001b[0m       ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console = Console()\n",
    "\n",
    "result_sorted = sorted(results, key=lambda i: i[3], reverse=True)\n",
    "\n",
    "best_model = max(results, key=lambda x: x[3])\n",
    "worst_model = min(results, key=lambda x: x[3])\n",
    "\n",
    "table = Table(title=\"Optuna\", show_lines=True)\n",
    "table.add_column(\"Algorithm\")\n",
    "table.add_column(\"Accuracy\")\n",
    "table.add_column(\"Precision\")\n",
    "table.add_column(\"Recall\")\n",
    "table.add_column(\"F1-score\")\n",
    "table.add_column(\"K-Fold mean\")\n",
    "table.add_column(\"K-Fold std\")\n",
    "\n",
    "for row in result_sorted:\n",
    "    algo, acc, presicion, recall, f1, kmean, kstd = row\n",
    "\n",
    "    if row == best_model:\n",
    "        table.add_row(\n",
    "            f\"[bold green]{algo}[/bold green]\",\n",
    "            f\"[bold green]{acc:.2f}[/bold green]\",\n",
    "            f\"[bold green]{presicion:.2f}[/bold green]\",\n",
    "            f\"[bold green]{recall:.2f}[/bold green]\",\n",
    "            f\"[bold green]{f1:.2f}[/bold green]\",\n",
    "            f\"[bold green]{kmean:.2f}[/bold green]\",\n",
    "            f\"[bold green]{kstd:.2f}[/bold green]\",\n",
    "        )\n",
    "    elif row == worst_model:\n",
    "        table.add_row(\n",
    "            f\"[bold red]{algo}[/bold red]\",\n",
    "            f\"[bold red]{acc:.2f}[/bold red]\",\n",
    "            f\"[bold red]{presicion:.2f}[/bold red]\",\n",
    "            f\"[bold red]{recall:.2f}[/bold red]\",\n",
    "            f\"[bold red]{f1:.2f}[/bold red]\",\n",
    "            f\"[bold red]{kmean:.2f}[/bold red]\",\n",
    "            f\"[bold red]{kstd:.2f}[/bold red]\",\n",
    "        )\n",
    "    else:\n",
    "        table.add_row(algo, f\"{acc:.2f}\", f\"{presicion:.2f}\", f\"{recall:.2f}\", f\"{f1:.2f}\", f\"{kmean:.2f}\", f\"{kstd:.2f}\")\n",
    "\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42bbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                            Optuna                                            </span>\n",
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Algorithm            </span>‚îÉ<span style=\"font-weight: bold\"> Accuracy </span>‚îÉ<span style=\"font-weight: bold\"> Precision </span>‚îÉ<span style=\"font-weight: bold\"> Recall </span>‚îÉ<span style=\"font-weight: bold\"> F1-score </span>‚îÉ<span style=\"font-weight: bold\"> K-Fold mean </span>‚îÉ<span style=\"font-weight: bold\"> K-Fold std </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">SGDC</span>                 ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.38</span>     ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.38</span>      ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span>   ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.55</span>     ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.33</span>        ‚îÇ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span>       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Stacking             ‚îÇ 0.89     ‚îÇ 0.86      ‚îÇ 0.83   ‚îÇ 0.85     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagged DT            ‚îÇ 0.88     ‚îÇ 0.85      ‚îÇ 0.83   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagging              ‚îÇ 0.89     ‚îÇ 0.86      ‚îÇ 0.83   ‚îÇ 0.85     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ LGBMClassifier       ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.83   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ GradientBoosting     ‚îÇ 0.88     ‚îÇ 0.85      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ HistGradientBoosting ‚îÇ 0.87     ‚îÇ 0.84      ‚îÇ 0.82   ‚îÇ 0.83     ‚îÇ 0.89        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Soft Voting          ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ CatBoost             ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ XGBoost              ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Hard Voting          ‚îÇ 0.88     ‚îÇ 0.85      ‚îÇ 0.82   ‚îÇ 0.83     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RandomForest         ‚îÇ 0.88     ‚îÇ 0.87      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ ExtraTrees           ‚îÇ 0.87     ‚îÇ 0.84      ‚îÇ 0.81   ‚îÇ 0.83     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ SVC                  ‚îÇ 0.84     ‚îÇ 0.77      ‚îÇ 0.81   ‚îÇ 0.79     ‚îÇ 0.84        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ DecisionTree         ‚îÇ 0.85     ‚îÇ 0.81      ‚îÇ 0.80   ‚îÇ 0.80     ‚îÇ 0.86        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ AdaBoost             ‚îÇ 0.83     ‚îÇ 0.76      ‚îÇ 0.80   ‚îÇ 0.78     ‚îÇ 0.83        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Passive Aggressive   ‚îÇ 0.76     ‚îÇ 0.65      ‚îÇ 0.79   ‚îÇ 0.71     ‚îÇ 0.73        ‚îÇ 0.02       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ KNN                  ‚îÇ 0.78     ‚îÇ 0.68      ‚îÇ 0.79   ‚îÇ 0.73     ‚îÇ 0.83        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ MLPC                 ‚îÇ 0.84     ‚îÇ 0.78      ‚îÇ 0.78   ‚îÇ 0.78     ‚îÇ 0.85        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Logistic Regression  ‚îÇ 0.79     ‚îÇ 0.70      ‚îÇ 0.77   ‚îÇ 0.74     ‚îÇ 0.79        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RidgeClassifier      ‚îÇ 0.80     ‚îÇ 0.71      ‚îÇ 0.77   ‚îÇ 0.74     ‚îÇ 0.79        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">DummyClassifier</span>      ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.62</span>     ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>      ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>   ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>     ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.33</span>        ‚îÇ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>       ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                            Optuna                                            \u001b[0m\n",
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mAlgorithm           \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mAccuracy\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mPrecision\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mRecall\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mF1-score\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mK-Fold mean\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mK-Fold std\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ \u001b[1;32mSGDC\u001b[0m                 ‚îÇ \u001b[1;32m0.38\u001b[0m     ‚îÇ \u001b[1;32m0.38\u001b[0m      ‚îÇ \u001b[1;32m1.00\u001b[0m   ‚îÇ \u001b[1;32m0.55\u001b[0m     ‚îÇ \u001b[1;32m0.33\u001b[0m        ‚îÇ \u001b[1;32m0.00\u001b[0m       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Stacking             ‚îÇ 0.89     ‚îÇ 0.86      ‚îÇ 0.83   ‚îÇ 0.85     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagged DT            ‚îÇ 0.88     ‚îÇ 0.85      ‚îÇ 0.83   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Bagging              ‚îÇ 0.89     ‚îÇ 0.86      ‚îÇ 0.83   ‚îÇ 0.85     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ LGBMClassifier       ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.83   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ GradientBoosting     ‚îÇ 0.88     ‚îÇ 0.85      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ HistGradientBoosting ‚îÇ 0.87     ‚îÇ 0.84      ‚îÇ 0.82   ‚îÇ 0.83     ‚îÇ 0.89        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Soft Voting          ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ CatBoost             ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ XGBoost              ‚îÇ 0.88     ‚îÇ 0.86      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Hard Voting          ‚îÇ 0.88     ‚îÇ 0.85      ‚îÇ 0.82   ‚îÇ 0.83     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RandomForest         ‚îÇ 0.88     ‚îÇ 0.87      ‚îÇ 0.82   ‚îÇ 0.84     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ ExtraTrees           ‚îÇ 0.87     ‚îÇ 0.84      ‚îÇ 0.81   ‚îÇ 0.83     ‚îÇ 0.90        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ SVC                  ‚îÇ 0.84     ‚îÇ 0.77      ‚îÇ 0.81   ‚îÇ 0.79     ‚îÇ 0.84        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ DecisionTree         ‚îÇ 0.85     ‚îÇ 0.81      ‚îÇ 0.80   ‚îÇ 0.80     ‚îÇ 0.86        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ AdaBoost             ‚îÇ 0.83     ‚îÇ 0.76      ‚îÇ 0.80   ‚îÇ 0.78     ‚îÇ 0.83        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Passive Aggressive   ‚îÇ 0.76     ‚îÇ 0.65      ‚îÇ 0.79   ‚îÇ 0.71     ‚îÇ 0.73        ‚îÇ 0.02       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ KNN                  ‚îÇ 0.78     ‚îÇ 0.68      ‚îÇ 0.79   ‚îÇ 0.73     ‚îÇ 0.83        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ MLPC                 ‚îÇ 0.84     ‚îÇ 0.78      ‚îÇ 0.78   ‚îÇ 0.78     ‚îÇ 0.85        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Logistic Regression  ‚îÇ 0.79     ‚îÇ 0.70      ‚îÇ 0.77   ‚îÇ 0.74     ‚îÇ 0.79        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ RidgeClassifier      ‚îÇ 0.80     ‚îÇ 0.71      ‚îÇ 0.77   ‚îÇ 0.74     ‚îÇ 0.79        ‚îÇ 0.00       ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ \u001b[1;31mDummyClassifier\u001b[0m      ‚îÇ \u001b[1;31m0.62\u001b[0m     ‚îÇ \u001b[1;31m0.00\u001b[0m      ‚îÇ \u001b[1;31m0.00\u001b[0m   ‚îÇ \u001b[1;31m0.00\u001b[0m     ‚îÇ \u001b[1;31m0.33\u001b[0m        ‚îÇ \u001b[1;31m0.00\u001b[0m       ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_console = Console(record=True)\n",
    "temp_console.print(table)\n",
    "text = temp_console.export_text()\n",
    "with open('results/Tuning.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d84bf7",
   "metadata": {},
   "source": [
    "# Another Tunings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ca834",
   "metadata": {},
   "source": [
    "<a href=\"../Tuning/manual_search.ipynb\" target=\"_blank\" style=\"text-decoration: none;\">\n",
    "    <button style=\"\n",
    "        background-color: #45a049;\n",
    "        color: white; \n",
    "        padding: 12px 24px; \n",
    "        font-size: 16px; \n",
    "        border: none; \n",
    "        border-radius: 8px;\n",
    "        cursor: pointer;\n",
    "        transition: background-color 0.3s;\n",
    "    \" onmouseover=\"this.style.backgroundColor='#45a049'\" onmouseout=\"this.style.backgroundColor='#4CAF50'\">\n",
    "        Manual Search\n",
    "    </button>\n",
    "</a>\n",
    "\n",
    "<a href=\"../Tuning/optuna.ipynb\" target=\"_blank\" style=\"text-decoration: none;\">\n",
    "    <button style=\"\n",
    "        background-color: #45a049;\n",
    "        color: white; \n",
    "        padding: 12px 24px; \n",
    "        font-size: 16px; \n",
    "        border: none; \n",
    "        border-radius: 8px;\n",
    "        cursor: pointer;\n",
    "        transition: background-color 0.3s;\n",
    "    \" onmouseover=\"this.style.backgroundColor='#45a049'\" onmouseout=\"this.style.backgroundColor='#4CAF50'\">\n",
    "        optuna\n",
    "    </button>\n",
    "</a>\n",
    "\n",
    "<a href=\"../Tuning/random_search.ipynb\" target=\"_blank\" style=\"text-decoration: none;\">\n",
    "    <button style=\"\n",
    "        background-color: #45a049;\n",
    "        color: white; \n",
    "        padding: 12px 24px; \n",
    "        font-size: 16px; \n",
    "        border: none; \n",
    "        border-radius: 8px;\n",
    "        cursor: pointer;\n",
    "        transition: background-color 0.3s;\n",
    "    \" onmouseover=\"this.style.backgroundColor='#45a049'\" onmouseout=\"this.style.backgroundColor='#4CAF50'\">\n",
    "        Random Search\n",
    "    </button>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21380bf5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
