{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0ec5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "901af526",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\SML_Projects\\SML_CVE_type_cwe_predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "504cf8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95da7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/filled/filled_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10e5736b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102963 entries, 0 to 102962\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   cve_id        102963 non-null  object\n",
      " 1   description   102963 non-null  object\n",
      " 2   cvss_score    102963 non-null  object\n",
      " 3   cwe           102963 non-null  object\n",
      " 4   vendor        102963 non-null  object\n",
      " 5   product       102963 non-null  object\n",
      " 6   publish_date  102963 non-null  object\n",
      " 7   type          102963 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "db23c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Preprocessing(df, target=['type', 'cvss_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a621f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing.encode(include_targets=True).scale().get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a003ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "284fbd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10296 entries, 0 to 10295\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   cve_id        10296 non-null  float64\n",
      " 1   description   10296 non-null  float64\n",
      " 2   cvss_score    10296 non-null  float64\n",
      " 3   cwe           10296 non-null  float64\n",
      " 4   vendor        10296 non-null  float64\n",
      " 5   product       10296 non-null  float64\n",
      " 6   publish_date  10296 non-null  float64\n",
      " 7   type          10296 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 643.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0ca31acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bd02ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['type', 'cvss_score'], axis=1)   \n",
    "y = df[['type', 'cvss_score']] \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c22dc13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21185bd",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "338fbed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy for 'type': 0.36650485436893204\n",
      "Logistic Regression Accuracy for 'cvss_score' : 0.5373786407766991\n",
      "K-Fold mean F1 (type): 0.08376498810155399\n",
      "K-Fold std  F1 (type): 0.0033207295646636107\n",
      "K-Fold mean F1 (cvss_score): 0.23475904634961933\n",
      "K-Fold std  F1 (cvss_score): 0.007096396172015192\n",
      "\n",
      "Classification Report for 'type':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        28\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "         2.0       0.00      0.00      0.00       103\n",
      "         3.0       0.06      0.04      0.05       200\n",
      "         4.0       0.40      0.79      0.53       834\n",
      "         5.0       0.00      0.00      0.00        41\n",
      "         6.0       0.00      0.00      0.00        36\n",
      "         7.0       0.00      0.00      0.00       155\n",
      "         8.0       0.30      0.05      0.09       176\n",
      "         9.0       0.00      0.00      0.00        14\n",
      "        10.0       0.32      0.19      0.24       423\n",
      "\n",
      "    accuracy                           0.37      2060\n",
      "   macro avg       0.10      0.10      0.08      2060\n",
      "weighted avg       0.26      0.37      0.28      2060\n",
      "\n",
      "\n",
      "Classification Report for 'cvss_score':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       234\n",
      "         1.0       0.42      0.17      0.24       637\n",
      "         2.0       0.00      0.00      0.00        87\n",
      "         3.0       0.55      0.91      0.69      1102\n",
      "\n",
      "    accuracy                           0.54      2060\n",
      "   macro avg       0.24      0.27      0.23      2060\n",
      "weighted avg       0.43      0.54      0.44      2060\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "multi_lr = MultiOutputClassifier(lr)\n",
    "\n",
    "multi_lr.fit(x_train, y_train)\n",
    "y_pred = multi_lr.predict(x_test)\n",
    "\n",
    "lr_accuracy_type = accuracy_score(y_test['type'], y_pred[:, 0])\n",
    "lr_accuracy_cvss_score  = accuracy_score(y_test['cvss_score'], y_pred[:, 1])\n",
    "\n",
    "lr_scores_type = cross_val_score(lr, x, y['type'], cv=kf, scoring='f1_macro')\n",
    "lr_scores_cvss_score  = cross_val_score(lr, x, y['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"Logistic Regression Accuracy for 'type':\", lr_accuracy_type)\n",
    "print(\"Logistic Regression Accuracy for 'cvss_score' :\", lr_accuracy_cvss_score)\n",
    "\n",
    "print(\"K-Fold mean F1 (type):\", lr_scores_type.mean())\n",
    "print(\"K-Fold std  F1 (type):\", lr_scores_type.std())\n",
    "\n",
    "print(\"K-Fold mean F1 (cvss_score):\", lr_scores_cvss_score.mean())\n",
    "print(\"K-Fold std  F1 (cvss_score):\", lr_scores_cvss_score.std())\n",
    "\n",
    "print(\"\\nClassification Report for 'type':\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print(\"\\nClassification Report for 'cvss_score':\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb268c",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "37f2676f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy for 'type': 0.8063106796116505\n",
      "Gradient Boosting Accuracy for 'cvss_score' : 0.5844660194174758\n",
      "K-Fold mean F1 (type): 0.7243119835518702\n",
      "K-Fold std  F1 (type): 0.0037779433085536537\n",
      "K-Fold mean F1 (cvss_score): 0.45656365815339933\n",
      "K-Fold std  F1 (cvss_score): 0.006227443254244629\n",
      "\n",
      "Classification Report for 'type':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.79      0.80        28\n",
      "         1.0       0.70      0.78      0.74        50\n",
      "         2.0       0.40      0.47      0.43       103\n",
      "         3.0       0.82      0.83      0.83       200\n",
      "         4.0       0.84      0.81      0.83       834\n",
      "         5.0       0.74      0.78      0.76        41\n",
      "         6.0       0.49      0.50      0.49        36\n",
      "         7.0       0.50      0.53      0.51       155\n",
      "         8.0       0.95      0.96      0.96       176\n",
      "         9.0       0.93      1.00      0.97        14\n",
      "        10.0       0.95      0.93      0.94       423\n",
      "\n",
      "    accuracy                           0.81      2060\n",
      "   macro avg       0.74      0.76      0.75      2060\n",
      "weighted avg       0.81      0.81      0.81      2060\n",
      "\n",
      "\n",
      "Classification Report for 'cvss_score':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.31      0.34       234\n",
      "         1.0       0.48      0.49      0.48       637\n",
      "         2.0       0.41      0.44      0.42        87\n",
      "         3.0       0.70      0.71      0.70      1102\n",
      "\n",
      "    accuracy                           0.58      2060\n",
      "   macro avg       0.49      0.49      0.49      2060\n",
      "weighted avg       0.58      0.58      0.58      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "multi_dt = MultiOutputClassifier(dt)\n",
    "\n",
    "multi_dt.fit(x_train, y_train)\n",
    "y_pred = multi_dt.predict(x_test)\n",
    "\n",
    "dt_accuracy_type = accuracy_score(y_test['type'], y_pred[:, 0])\n",
    "dt_accuracy_cvss_score  = accuracy_score(y_test['cvss_score'], y_pred[:, 1])\n",
    "\n",
    "dt_scores_type = cross_val_score(dt, x , y['type'], cv=kf, scoring='f1_macro')\n",
    "dt_scores_cvss_score  = cross_val_score(dt, x , y['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"Gradient Boosting Accuracy for 'type':\", dt_accuracy_type)\n",
    "print(\"Gradient Boosting Accuracy for 'cvss_score' :\", dt_accuracy_cvss_score)\n",
    "\n",
    "print(\"K-Fold mean F1 (type):\", dt_scores_type.mean())\n",
    "print(\"K-Fold std  F1 (type):\", dt_scores_type.std())\n",
    "\n",
    "print(\"K-Fold mean F1 (cvss_score):\", dt_scores_cvss_score.mean())\n",
    "print(\"K-Fold std  F1 (cvss_score):\", dt_scores_cvss_score.std())\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report for 'type':\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print(\"\\nClassification Report for 'cvss_score':\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe949042",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "517f7369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy for 'type': 0.8354368932038835\n",
      "Gradient Boosting Accuracy for 'cvss_score' : 0.6286407766990292\n",
      "K-Fold mean F1 (type): 0.669436773865622\n",
      "K-Fold std  F1 (type): 0.008765196181456427\n",
      "K-Fold mean F1 (cvss_score): 0.4960713737041411\n",
      "K-Fold std  F1 (cvss_score): 0.014303723378917456\n",
      "\n",
      "Classification Report for 'type':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.29      0.44        28\n",
      "         1.0       0.80      0.70      0.74        50\n",
      "         2.0       0.71      0.38      0.49       103\n",
      "         3.0       0.74      0.88      0.80       200\n",
      "         4.0       0.80      0.95      0.87       834\n",
      "         5.0       0.84      0.63      0.72        41\n",
      "         6.0       0.88      0.19      0.32        36\n",
      "         7.0       0.77      0.39      0.52       155\n",
      "         8.0       0.94      0.95      0.95       176\n",
      "         9.0       1.00      0.50      0.67        14\n",
      "        10.0       0.95      0.96      0.96       423\n",
      "\n",
      "    accuracy                           0.84      2060\n",
      "   macro avg       0.86      0.62      0.68      2060\n",
      "weighted avg       0.84      0.84      0.82      2060\n",
      "\n",
      "\n",
      "Classification Report for 'cvss_score':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.23      0.32       234\n",
      "         1.0       0.53      0.51      0.52       637\n",
      "         2.0       0.75      0.34      0.47        87\n",
      "         3.0       0.68      0.81      0.74      1102\n",
      "\n",
      "    accuracy                           0.63      2060\n",
      "   macro avg       0.62      0.47      0.51      2060\n",
      "weighted avg       0.62      0.63      0.61      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "multi_rf = MultiOutputClassifier(rf)\n",
    "\n",
    "multi_rf.fit(x_train, y_train)\n",
    "y_pred = multi_rf.predict(x_test)\n",
    "\n",
    "rf_accuracy_type = accuracy_score(y_test['type'], y_pred[:, 0])\n",
    "rf_accuracy_cvss_score  = accuracy_score(y_test['cvss_score'], y_pred[:, 1])\n",
    "\n",
    "rf_scores_type = cross_val_score(rf, x , y['type'], cv=kf, scoring='f1_macro')\n",
    "rf_scores_cvss_score  = cross_val_score(rf, x , y['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"Gradient Boosting Accuracy for 'type':\", rf_accuracy_type)\n",
    "print(\"Gradient Boosting Accuracy for 'cvss_score' :\", rf_accuracy_cvss_score)\n",
    "\n",
    "print(\"K-Fold mean F1 (type):\", rf_scores_type.mean())\n",
    "print(\"K-Fold std  F1 (type):\", rf_scores_type.std())\n",
    "\n",
    "print(\"K-Fold mean F1 (cvss_score):\", rf_scores_cvss_score.mean())\n",
    "print(\"K-Fold std  F1 (cvss_score):\", rf_scores_cvss_score.std())\n",
    "\n",
    "print(\"\\nClassification Report for 'type':\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print(\"\\nClassification Report for 'cvss_score':\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec042ccb",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bba9e13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy for 'type': 0.8475728155339806\n",
      "Gradient Boosting Accuracy for 'cvss_score' : 0.6014563106796117\n",
      "K-Fold mean F1 (type): 0.7631757854678933\n",
      "K-Fold std  F1 (type): 0.0072637667710975075\n",
      "K-Fold mean F1 (cvss_score): 0.42026741909962545\n",
      "K-Fold std  F1 (cvss_score): 0.010788339491158684\n",
      "\n",
      "Classification Report for 'type':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.79      0.77        28\n",
      "         1.0       0.67      0.80      0.73        50\n",
      "         2.0       0.76      0.18      0.30       103\n",
      "         3.0       0.91      0.88      0.90       200\n",
      "         4.0       0.80      0.95      0.87       834\n",
      "         5.0       0.80      0.90      0.85        41\n",
      "         6.0       0.79      0.53      0.63        36\n",
      "         7.0       0.86      0.35      0.50       155\n",
      "         8.0       0.96      0.98      0.97       176\n",
      "         9.0       0.93      1.00      0.97        14\n",
      "        10.0       0.93      0.95      0.94       423\n",
      "\n",
      "    accuracy                           0.85      2060\n",
      "   macro avg       0.83      0.76      0.77      2060\n",
      "weighted avg       0.85      0.85      0.83      2060\n",
      "\n",
      "\n",
      "Classification Report for 'cvss_score':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.15      0.26       234\n",
      "         1.0       0.50      0.35      0.41       637\n",
      "         2.0       0.75      0.14      0.23        87\n",
      "         3.0       0.63      0.88      0.73      1102\n",
      "\n",
      "    accuracy                           0.60      2060\n",
      "   macro avg       0.66      0.38      0.41      2060\n",
      "weighted avg       0.61      0.60      0.56      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=50, max_depth=3, random_state=42)\n",
    "multi_gbr = MultiOutputClassifier(gb)\n",
    "\n",
    "multi_gbr.fit(x_train, y_train)\n",
    "y_pred = multi_gbr.predict(x_test )\n",
    "\n",
    "gb_accuracy_type = accuracy_score(y_test['type'], y_pred[:, 0])\n",
    "gb_accuracy_cvss_score  = accuracy_score(y_test['cvss_score'], y_pred[:, 1])\n",
    "\n",
    "gb_scores_type = cross_val_score(gb, x , y['type'], cv=kf, scoring='f1_macro')\n",
    "gb_scores_cvss_score  = cross_val_score(gb, x , y['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"Gradient Boosting Accuracy for 'type':\", gb_accuracy_type)\n",
    "print(\"Gradient Boosting Accuracy for 'cvss_score' :\", gb_accuracy_cvss_score)\n",
    "\n",
    "print(\"K-Fold mean F1 (type):\", gb_scores_type.mean())\n",
    "print(\"K-Fold std  F1 (type):\", gb_scores_type.std())\n",
    "\n",
    "print(\"K-Fold mean F1 (cvss_score):\", gb_scores_cvss_score.mean())\n",
    "print(\"K-Fold std  F1 (cvss_score):\", gb_scores_cvss_score.std())\n",
    "\n",
    "print(\"\\nClassification Report for 'type':\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print(\"\\nClassification Report for 'cvss_score':\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17ada56",
   "metadata": {},
   "source": [
    "# Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3536f8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Accuracy for 'type': 0.8189320388349515\n",
      "Extra Trees Accuracy for 'cvss_score' : 0.6077669902912621\n",
      "K-Fold mean F1 (type): 0.6422477770245637\n",
      "K-Fold std  F1 (type): 0.0216231975689129\n",
      "K-Fold mean F1 (cvss_score): 0.4442371529175239\n",
      "K-Fold std  F1 (cvss_score): 0.012618745880562178\n",
      "\n",
      "Classification Report for 'type':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.18      0.29        28\n",
      "         1.0       0.71      0.70      0.71        50\n",
      "         2.0       0.66      0.39      0.49       103\n",
      "         3.0       0.72      0.84      0.77       200\n",
      "         4.0       0.80      0.93      0.86       834\n",
      "         5.0       0.75      0.59      0.66        41\n",
      "         6.0       0.78      0.19      0.31        36\n",
      "         7.0       0.76      0.44      0.56       155\n",
      "         8.0       0.94      0.90      0.92       176\n",
      "         9.0       1.00      0.50      0.67        14\n",
      "        10.0       0.93      0.93      0.93       423\n",
      "\n",
      "    accuracy                           0.82      2060\n",
      "   macro avg       0.81      0.60      0.65      2060\n",
      "weighted avg       0.82      0.82      0.80      2060\n",
      "\n",
      "\n",
      "Classification Report for 'cvss_score':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.20      0.30       234\n",
      "         1.0       0.52      0.47      0.49       637\n",
      "         2.0       0.62      0.24      0.35        87\n",
      "         3.0       0.65      0.80      0.72      1102\n",
      "\n",
      "    accuracy                           0.61      2060\n",
      "   macro avg       0.59      0.43      0.46      2060\n",
      "weighted avg       0.60      0.61      0.58      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(random_state=42)\n",
    "multi_et = MultiOutputClassifier(et)\n",
    "\n",
    "multi_et.fit(x_train, y_train)\n",
    "y_pred = multi_et.predict(x_test )\n",
    "\n",
    "et_accuracy_type = accuracy_score(y_test['type'], y_pred[:, 0])\n",
    "et_accuracy_cvss_score  = accuracy_score(y_test['cvss_score'], y_pred[:, 1])\n",
    "\n",
    "et_scores_type = cross_val_score(et, x , y['type'], cv=kf, scoring='f1_macro')\n",
    "et_scores_cvss_score  = cross_val_score(et, x , y['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"Extra Trees Accuracy for 'type':\", et_accuracy_type)\n",
    "print(\"Extra Trees Accuracy for 'cvss_score' :\", et_accuracy_cvss_score)\n",
    "\n",
    "print(\"K-Fold mean F1 (type):\", et_scores_type.mean())\n",
    "print(\"K-Fold std  F1 (type):\", et_scores_type.std())\n",
    "\n",
    "print(\"K-Fold mean F1 (cvss_score):\", et_scores_cvss_score.mean())\n",
    "print(\"K-Fold std  F1 (cvss_score):\", et_scores_cvss_score.std())\n",
    "\n",
    "print(\"\\nClassification Report for 'type':\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print(\"\\nClassification Report for 'cvss_score':\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbf9ced",
   "metadata": {},
   "source": [
    "# Hist Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9cb35c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoosting Accuracy for 'type': 0.3864077669902913\n",
      "HistGradientBoosting Accuracy for 'cvss_score' : 0.6315533980582524\n",
      "K-Fold mean F1 (type): 0.5434096370006727\n",
      "K-Fold std  F1 (type): 0.3130459824121466\n",
      "K-Fold mean F1 (cvss_score): 0.5129551889768581\n",
      "K-Fold std  F1 (cvss_score): 0.013877171229916484\n",
      "\n",
      "Classification Report for 'type':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.05      0.04      0.04        28\n",
      "         1.0       0.18      0.24      0.20        50\n",
      "         2.0       0.13      0.21      0.16       103\n",
      "         3.0       0.43      0.42      0.43       200\n",
      "         4.0       0.43      0.68      0.53       834\n",
      "         5.0       0.29      0.41      0.34        41\n",
      "         6.0       0.17      0.08      0.11        36\n",
      "         7.0       0.22      0.16      0.19       155\n",
      "         8.0       0.00      0.00      0.00       176\n",
      "         9.0       0.00      0.00      0.00        14\n",
      "        10.0       0.91      0.15      0.26       423\n",
      "\n",
      "    accuracy                           0.39      2060\n",
      "   macro avg       0.26      0.22      0.21      2060\n",
      "weighted avg       0.44      0.39      0.34      2060\n",
      "\n",
      "\n",
      "Classification Report for 'cvss_score':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.27      0.35       234\n",
      "         1.0       0.53      0.52      0.53       637\n",
      "         2.0       0.72      0.32      0.44        87\n",
      "         3.0       0.69      0.80      0.74      1102\n",
      "\n",
      "    accuracy                           0.63      2060\n",
      "   macro avg       0.61      0.48      0.52      2060\n",
      "weighted avg       0.62      0.63      0.62      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hgb = HistGradientBoostingClassifier(max_iter=220, max_depth=5, random_state=42)\n",
    "multi_hgb = MultiOutputClassifier(hgb)\n",
    "\n",
    "multi_hgb.fit(x_train, y_train)\n",
    "y_pred = multi_hgb.predict(x_test )\n",
    "\n",
    "hgb_accuracy_type = accuracy_score(y_test['type'], y_pred[:, 0])\n",
    "hgb_accuracy_cvss_score  = accuracy_score(y_test['cvss_score'], y_pred[:, 1])\n",
    "\n",
    "hgb_scores_type = cross_val_score(hgb, x , y['type'], cv=kf, scoring='f1_macro')\n",
    "hgb_scores_cvss_score  = cross_val_score(hgb, x , y['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"HistGradientBoosting Accuracy for 'type':\", hgb_accuracy_type)\n",
    "print(\"HistGradientBoosting Accuracy for 'cvss_score' :\", hgb_accuracy_cvss_score)\n",
    "\n",
    "print(\"K-Fold mean F1 (type):\", hgb_scores_type.mean())\n",
    "print(\"K-Fold std  F1 (type):\", hgb_scores_type.std())\n",
    "\n",
    "print(\"K-Fold mean F1 (cvss_score):\", hgb_scores_cvss_score.mean())\n",
    "print(\"K-Fold std  F1 (cvss_score):\", hgb_scores_cvss_score.std())\n",
    "\n",
    "print(\"\\nClassification Report for 'type':\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print(\"\\nClassification Report for 'cvss_score':\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4b43d8",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "651a2441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy for 'type': 0.5684466019417476\n",
      "KNN Accuracy for 'cvss_score' : 0.512621359223301\n",
      "K-Fold mean F1 (type): 0.330016286586144\n",
      "K-Fold std  F1 (type): 0.010084356247648993\n",
      "K-Fold mean F1 (cvss_score): 0.36856246764355155\n",
      "K-Fold std  F1 (cvss_score): 0.007590915335924097\n",
      "\n",
      "Classification Report for 'type':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.06      0.04      0.04        28\n",
      "         1.0       0.32      0.44      0.37        50\n",
      "         2.0       0.31      0.31      0.31       103\n",
      "         3.0       0.52      0.65      0.58       200\n",
      "         4.0       0.65      0.73      0.69       834\n",
      "         5.0       0.14      0.10      0.11        41\n",
      "         6.0       0.08      0.03      0.04        36\n",
      "         7.0       0.43      0.19      0.26       155\n",
      "         8.0       0.54      0.50      0.52       176\n",
      "         9.0       0.00      0.00      0.00        14\n",
      "        10.0       0.64      0.61      0.62       423\n",
      "\n",
      "    accuracy                           0.57      2060\n",
      "   macro avg       0.33      0.33      0.32      2060\n",
      "weighted avg       0.55      0.57      0.55      2060\n",
      "\n",
      "\n",
      "Classification Report for 'cvss_score':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.31      0.22      0.26       234\n",
      "         1.0       0.40      0.44      0.42       637\n",
      "         2.0       0.25      0.11      0.16        87\n",
      "         3.0       0.62      0.65      0.63      1102\n",
      "\n",
      "    accuracy                           0.51      2060\n",
      "   macro avg       0.40      0.36      0.37      2060\n",
      "weighted avg       0.50      0.51      0.50      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "multi_knn = MultiOutputClassifier(knn)\n",
    "\n",
    "multi_knn.fit(x_train, y_train)\n",
    "y_pred = multi_knn.predict(x_test )\n",
    "\n",
    "knn_accuracy_type = accuracy_score(y_test['type'], y_pred[:, 0])\n",
    "knn_accuracy_cvss_score  = accuracy_score(y_test['cvss_score'], y_pred[:, 1])\n",
    "\n",
    "knn_scores_type = cross_val_score(knn, x , y['type'], cv=kf, scoring='f1_macro')\n",
    "knn_scores_cvss_score  = cross_val_score(knn, x , y['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"KNN Accuracy for 'type':\", knn_accuracy_type)\n",
    "print(\"KNN Accuracy for 'cvss_score' :\", knn_accuracy_cvss_score)\n",
    "\n",
    "print(\"K-Fold mean F1 (type):\", knn_scores_type.mean())\n",
    "print(\"K-Fold std  F1 (type):\", knn_scores_type.std())\n",
    "\n",
    "print(\"K-Fold mean F1 (cvss_score):\", knn_scores_cvss_score.mean())\n",
    "print(\"K-Fold std  F1 (cvss_score):\", knn_scores_cvss_score.std())\n",
    "\n",
    "print(\"\\nClassification Report for 'type':\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print(\"\\nClassification Report for 'cvss_score':\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9910235",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "31d69d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy for 'type': 0.5713592233009709\n",
      "AdaBoost Accuracy for 'cvss_score' : 0.566990291262136\n",
      "K-Fold mean F1 (type): 0.32742661050711813\n",
      "K-Fold std  F1 (type): 0.0406210086984585\n",
      "K-Fold mean F1 (cvss_score): 0.27226543362069083\n",
      "K-Fold std  F1 (cvss_score): 0.00583889772768262\n",
      "\n",
      "Classification Report for 'type':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.11      0.19        28\n",
      "         1.0       0.75      0.12      0.21        50\n",
      "         2.0       0.00      0.00      0.00       103\n",
      "         3.0       0.65      0.76      0.70       200\n",
      "         4.0       0.54      0.89      0.67       834\n",
      "         5.0       0.10      0.17      0.12        41\n",
      "         6.0       0.00      0.00      0.00        36\n",
      "         7.0       0.00      0.00      0.00       155\n",
      "         8.0       0.30      0.11      0.17       176\n",
      "         9.0       0.00      0.00      0.00        14\n",
      "        10.0       0.87      0.58      0.69       423\n",
      "\n",
      "    accuracy                           0.57      2060\n",
      "   macro avg       0.38      0.25      0.25      2060\n",
      "weighted avg       0.52      0.57      0.51      2060\n",
      "\n",
      "\n",
      "Classification Report for 'cvss_score':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       234\n",
      "         1.0       0.44      0.35      0.39       637\n",
      "         2.0       0.00      0.00      0.00        87\n",
      "         3.0       0.61      0.86      0.71      1102\n",
      "\n",
      "    accuracy                           0.57      2060\n",
      "   macro avg       0.26      0.30      0.27      2060\n",
      "weighted avg       0.46      0.57      0.50      2060\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier(n_estimators=220, random_state=42)\n",
    "multi_ada = MultiOutputClassifier(ab)\n",
    "\n",
    "multi_ada.fit(x_train, y_train)\n",
    "y_pred = multi_ada.predict(x_test )\n",
    "\n",
    "ab_accuracy_type = accuracy_score(y_test['type'], y_pred[:, 0])\n",
    "ab_accuracy_cvss_score  = accuracy_score(y_test['cvss_score'], y_pred[:, 1])\n",
    "\n",
    "ab_scores_type = cross_val_score(ab, x , y['type'], cv=kf, scoring='f1_macro')\n",
    "ab_scores_cvss_score  = cross_val_score(ab, x , y['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"AdaBoost Accuracy for 'type':\", ab_accuracy_type)\n",
    "print(\"AdaBoost Accuracy for 'cvss_score' :\", ab_accuracy_cvss_score)\n",
    "\n",
    "print(\"K-Fold mean F1 (type):\", ab_scores_type.mean())\n",
    "print(\"K-Fold std  F1 (type):\", ab_scores_type.std())\n",
    "\n",
    "print(\"K-Fold mean F1 (cvss_score):\", ab_scores_cvss_score.mean())\n",
    "print(\"K-Fold std  F1 (cvss_score):\", ab_scores_cvss_score.std())\n",
    "\n",
    "print(\"\\nClassification Report for 'type':\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print(\"\\nClassification Report for 'cvss_score':\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01407b94",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b2d00e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy for 'type': 0.8679611650485437\n",
      "Bagging Accuracy for 'cvss_score' : 0.6223300970873786\n",
      "K-Fold mean F1 (type): 0.7838282165585465\n",
      "K-Fold std  F1 (type): 0.007316027792375406\n",
      "K-Fold mean F1 (cvss_score): 0.5156276774678378\n",
      "K-Fold std  F1 (cvss_score): 0.010810655997815114\n",
      "\n",
      "Classification Report for 'type':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.75      0.82        28\n",
      "         1.0       0.75      0.80      0.78        50\n",
      "         2.0       0.69      0.50      0.58       103\n",
      "         3.0       0.89      0.87      0.88       200\n",
      "         4.0       0.84      0.94      0.89       834\n",
      "         5.0       0.86      0.88      0.87        41\n",
      "         6.0       0.82      0.50      0.62        36\n",
      "         7.0       0.72      0.47      0.57       155\n",
      "         8.0       0.97      0.98      0.97       176\n",
      "         9.0       1.00      1.00      1.00        14\n",
      "        10.0       0.96      0.96      0.96       423\n",
      "\n",
      "    accuracy                           0.87      2060\n",
      "   macro avg       0.85      0.79      0.81      2060\n",
      "weighted avg       0.86      0.87      0.86      2060\n",
      "\n",
      "\n",
      "Classification Report for 'cvss_score':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.25      0.33       234\n",
      "         1.0       0.50      0.52      0.51       637\n",
      "         2.0       0.71      0.39      0.50        87\n",
      "         3.0       0.69      0.78      0.73      1102\n",
      "\n",
      "    accuracy                           0.62      2060\n",
      "   macro avg       0.60      0.48      0.52      2060\n",
      "weighted avg       0.61      0.62      0.61      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging = BaggingClassifier(n_estimators=100, random_state=42)\n",
    "multi_bagging = MultiOutputClassifier(bagging)\n",
    "\n",
    "multi_bagging.fit(x_train, y_train)\n",
    "y_pred = multi_bagging.predict(x_test )\n",
    "\n",
    "bag_accuracy_type = accuracy_score(y_test['type'], y_pred[:, 0])\n",
    "bag_accuracy_cvss_score  = accuracy_score(y_test['cvss_score'], y_pred[:, 1])\n",
    "\n",
    "bag_scores_type = cross_val_score(bagging, x , y['type'], cv=kf, scoring='f1_macro')\n",
    "bag_scores_cvss_score  = cross_val_score(bagging, x , y['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"Bagging Accuracy for 'type':\", bag_accuracy_type)\n",
    "print(\"Bagging Accuracy for 'cvss_score' :\", bag_accuracy_cvss_score)\n",
    "\n",
    "print(\"K-Fold mean F1 (type):\", bag_scores_type.mean())\n",
    "print(\"K-Fold std  F1 (type):\", bag_scores_type.std())\n",
    "\n",
    "print(\"K-Fold mean F1 (cvss_score):\", bag_scores_cvss_score.mean())\n",
    "print(\"K-Fold std  F1 (cvss_score):\", bag_scores_cvss_score.std())\n",
    "\n",
    "print(\"\\nClassification Report for 'type':\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print(\"\\nClassification Report for 'cvss_score':\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc371f6",
   "metadata": {},
   "source": [
    "# Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "538f2035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Accuracy for type: 0.8242718446601942\n",
      "Hard Voting Accuracy for cvss_score : 0.6174757281553398\n",
      "K-fold F1 mean (type): 0.6515998759084775\n",
      "K-fold F1 std  (type): 0.015156760433302432\n",
      "K-fold F1 mean (cvss_score) : 0.4503310811762777\n",
      "K-fold F1 std  (cvss_score) : 0.013775987678280118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.32      0.49        28\n",
      "         1.0       0.76      0.70      0.73        50\n",
      "         2.0       0.67      0.35      0.46       103\n",
      "         3.0       0.73      0.86      0.79       200\n",
      "         4.0       0.78      0.95      0.86       834\n",
      "         5.0       0.84      0.63      0.72        41\n",
      "         6.0       1.00      0.17      0.29        36\n",
      "         7.0       0.80      0.37      0.50       155\n",
      "         8.0       0.95      0.90      0.92       176\n",
      "         9.0       1.00      0.36      0.53        14\n",
      "        10.0       0.95      0.94      0.95       423\n",
      "\n",
      "    accuracy                           0.82      2060\n",
      "   macro avg       0.86      0.60      0.66      2060\n",
      "weighted avg       0.83      0.82      0.81      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "model1 = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model2 = ExtraTreesClassifier(n_estimators=200, random_state=42)\n",
    "model3 = LogisticRegression(max_iter=500)\n",
    "\n",
    "voting_hard = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', model1),\n",
    "        ('et', model2),\n",
    "        ('lr', model3)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "multi_voting_hard = MultiOutputClassifier(voting_hard)\n",
    "\n",
    "multi_voting_hard.fit(x_train, y_train)\n",
    "y_pred = multi_voting_hard.predict(x_test)\n",
    "\n",
    "hard_acc_type = accuracy_score(y_test[\"type\"], y_pred[:, 0])\n",
    "hard_acc_cvss_score  = accuracy_score(y_test[\"cvss_score\"],  y_pred[:, 1])\n",
    "\n",
    "\n",
    "hard_scores_type = cross_val_score(voting_hard, x, y['type'], cv=kf, scoring='f1_macro')\n",
    "hard_scores_cvss_score  = cross_val_score(voting_hard, x, y['cvss_score'],  cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"Hard Voting Accuracy for type:\", hard_acc_type)\n",
    "print(\"Hard Voting Accuracy for cvss_score :\", hard_acc_cvss_score)\n",
    "\n",
    "print(\"K-fold F1 mean (type):\", hard_scores_type.mean())\n",
    "print(\"K-fold F1 std  (type):\", hard_scores_type.std())\n",
    "\n",
    "print(\"K-fold F1 mean (cvss_score) :\", hard_scores_cvss_score.mean())\n",
    "print(\"K-fold F1 std  (cvss_score) :\", hard_scores_cvss_score.std())\n",
    "\n",
    "print(classification_report(y_test[\"type\"], y_pred[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e5efdc",
   "metadata": {},
   "source": [
    "# Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ce25fb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Accuracy for type: 0.8203883495145631\n",
      "Hard Voting Accuracy for cvss_score : 0.6257281553398059\n",
      "K-fold F1 mean (type): 0.6132945415392504\n",
      "K-fold F1 std  (type): 0.01750175151507526\n",
      "K-fold F1 mean (cvss_score) : 0.4169114820496899\n",
      "K-fold F1 std  (cvss_score) : 0.0161809637880913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.18      0.30        28\n",
      "         1.0       0.80      0.66      0.73        50\n",
      "         2.0       0.80      0.34      0.48       103\n",
      "         3.0       0.74      0.88      0.80       200\n",
      "         4.0       0.76      0.96      0.85       834\n",
      "         5.0       0.89      0.59      0.71        41\n",
      "         6.0       1.00      0.14      0.24        36\n",
      "         7.0       0.83      0.32      0.46       155\n",
      "         8.0       0.95      0.88      0.91       176\n",
      "         9.0       1.00      0.43      0.60        14\n",
      "        10.0       0.95      0.94      0.95       423\n",
      "\n",
      "    accuracy                           0.82      2060\n",
      "   macro avg       0.88      0.57      0.64      2060\n",
      "weighted avg       0.83      0.82      0.80      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model2 = ExtraTreesClassifier(n_estimators=200, random_state=42)\n",
    "model3 = LogisticRegression(max_iter=500)\n",
    "\n",
    "voting_hard = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', model1),\n",
    "        ('et', model2),\n",
    "        ('lr', model3)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "multi_voting_hard = MultiOutputClassifier(voting_hard)\n",
    "\n",
    "multi_voting_hard.fit(x_train, y_train)\n",
    "y_pred = multi_voting_hard.predict(x_test)\n",
    "\n",
    "soft_acc_type = accuracy_score(y_test[\"type\"], y_pred[:, 0])\n",
    "soft_acc_cvss_score  = accuracy_score(y_test[\"cvss_score\"],  y_pred[:, 1])\n",
    "\n",
    "soft_scores_type = cross_val_score(voting_hard, x, y['type'], cv=kf, scoring='f1_macro')\n",
    "soft_scores_cvss_score  = cross_val_score(voting_hard, x, y['cvss_score'],  cv=kf, scoring='f1_macro')\n",
    "\n",
    "\n",
    "print(\"Hard Voting Accuracy for type:\", soft_acc_type)\n",
    "print(\"Hard Voting Accuracy for cvss_score :\", soft_acc_cvss_score)\n",
    "\n",
    "print(\"K-fold F1 mean (type):\", soft_scores_type.mean())\n",
    "print(\"K-fold F1 std  (type):\", soft_scores_type.std())\n",
    "\n",
    "print(\"K-fold F1 mean (cvss_score) :\", soft_scores_cvss_score.mean())\n",
    "print(\"K-fold F1 std  (cvss_score) :\", soft_scores_cvss_score.std())\n",
    "\n",
    "print(classification_report(y_test[\"type\"], y_pred[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412ea80c",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "afca3c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Accuracy for type: 0.8446601941747572\n",
      "Stacking Accuracy for cvss_score : 0.6368932038834951\n",
      "K-fold F1 mean (type): 0.6972474531579157\n",
      "K-fold F1 std  (type): 0.014847204394619819\n",
      "K-fold F1 mean (cvss_score): 0.4949531750271971\n",
      "K-fold F1 std  (cvss_score): 0.013024863581860117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.36      0.53        28\n",
      "         1.0       0.81      0.68      0.74        50\n",
      "         2.0       0.68      0.38      0.49       103\n",
      "         3.0       0.80      0.86      0.83       200\n",
      "         4.0       0.81      0.95      0.87       834\n",
      "         5.0       0.80      0.80      0.80        41\n",
      "         6.0       0.80      0.22      0.35        36\n",
      "         7.0       0.76      0.44      0.56       155\n",
      "         8.0       0.95      0.95      0.95       176\n",
      "         9.0       0.90      0.64      0.75        14\n",
      "        10.0       0.95      0.96      0.95       423\n",
      "\n",
      "    accuracy                           0.84      2060\n",
      "   macro avg       0.84      0.66      0.71      2060\n",
      "weighted avg       0.84      0.84      0.83      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "base1 = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "base2 = ExtraTreesClassifier(n_estimators=200, random_state=42)\n",
    "base3 = LogisticRegression(max_iter=500)\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', base1),\n",
    "        ('et', base2),\n",
    "        ('lr', base3)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=500)\n",
    ")\n",
    "\n",
    "multi_stacking = MultiOutputClassifier(stacking)\n",
    "\n",
    "multi_stacking.fit(x_train, y_train)\n",
    "y_pred = multi_stacking.predict(x_test)\n",
    "\n",
    "stacking_acc_type = accuracy_score(y_test[\"type\"], y_pred[:, 0])\n",
    "stacking_acc_cvss_score  = accuracy_score(y_test[\"cvss_score\"],  y_pred[:, 1])\n",
    "\n",
    "stacking_scores_type = cross_val_score(stacking, x, y['type'], cv=kf, scoring='f1_macro')\n",
    "stacking_scores_cvss_score  = cross_val_score(stacking, x, y['cvss_score'],  cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"Stacking Accuracy for type:\", stacking_acc_type)\n",
    "print(\"Stacking Accuracy for cvss_score :\", stacking_acc_cvss_score)\n",
    "\n",
    "print(\"K-fold F1 mean (type):\", stacking_scores_type.mean())\n",
    "print(\"K-fold F1 std  (type):\", stacking_scores_type.std())\n",
    "\n",
    "print(\"K-fold F1 mean (cvss_score):\", stacking_scores_cvss_score.mean())\n",
    "print(\"K-fold F1 std  (cvss_score):\", stacking_scores_cvss_score.std())\n",
    "\n",
    "print(classification_report(y_test[\"type\"], y_pred[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200f43a6",
   "metadata": {},
   "source": [
    "# Bagged KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "defb8228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging KNN Accuracy for 'type': 0.5864077669902913\n",
      "Bagging KNN Accuracy for 'cvss_score': 0.5485436893203883\n",
      "K-Fold mean F1 (type): 0.33302250573585085\n",
      "K-Fold std  F1 (type): 0.012939165059061506\n",
      "K-Fold mean F1 (cvss_score): 0.3532474713754801\n",
      "K-Fold std  F1 (cvss_score): 0.0077456764758699415\n",
      "\n",
      "Classification Report for 'type':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.04      0.06        28\n",
      "         1.0       0.42      0.50      0.46        50\n",
      "         2.0       0.42      0.28      0.34       103\n",
      "         3.0       0.54      0.65      0.59       200\n",
      "         4.0       0.66      0.73      0.69       834\n",
      "         5.0       0.14      0.12      0.13        41\n",
      "         6.0       0.08      0.03      0.04        36\n",
      "         7.0       0.40      0.20      0.27       155\n",
      "         8.0       0.54      0.51      0.53       176\n",
      "         9.0       0.33      0.07      0.12        14\n",
      "        10.0       0.61      0.67      0.64       423\n",
      "\n",
      "    accuracy                           0.59      2060\n",
      "   macro avg       0.41      0.35      0.35      2060\n",
      "weighted avg       0.56      0.59      0.57      2060\n",
      "\n",
      "\n",
      "Classification Report for 'cvss_score':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      0.17      0.24       234\n",
      "         1.0       0.44      0.42      0.43       637\n",
      "         2.0       0.29      0.09      0.14        87\n",
      "         3.0       0.61      0.74      0.67      1102\n",
      "\n",
      "    accuracy                           0.55      2060\n",
      "   macro avg       0.44      0.35      0.37      2060\n",
      "weighted avg       0.52      0.55      0.52      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "bag_knn = BaggingClassifier(estimator=knn, n_estimators=100, random_state=42)\n",
    "multi_bag_knn = MultiOutputClassifier(bag_knn)\n",
    "\n",
    "multi_bag_knn.fit(x_train, y_train)\n",
    "y_pred = multi_bag_knn.predict(x_test )\n",
    "\n",
    "bag_knn_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "bag_knn_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "bag_knn_scores_type = cross_val_score(bag_knn, x , y['type'], cv=kf, scoring='f1_macro')\n",
    "bag_knn_scores_cvss_score = cross_val_score(bag_knn, x , y['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"Bagging KNN Accuracy for 'type':\", bag_knn_accuracy_type)\n",
    "print(\"Bagging KNN Accuracy for 'cvss_score':\", bag_knn_accuracy_cvss_score)\n",
    "\n",
    "print(\"K-Fold mean F1 (type):\", bag_knn_scores_type.mean())\n",
    "print(\"K-Fold std  F1 (type):\", bag_knn_scores_type.std())\n",
    "\n",
    "print(\"K-Fold mean F1 (cvss_score):\", bag_knn_scores_cvss_score.mean())\n",
    "print(\"K-Fold std  F1 (cvss_score):\", bag_knn_scores_cvss_score.std())\n",
    "\n",
    "print(\"\\nClassification Report for 'type':\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print(\"\\nClassification Report for 'cvss_score':\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85b564f",
   "metadata": {},
   "source": [
    "# Bagged DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e56e53ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Decision Tree Accuracy for 'type': 0.8679611650485437\n",
      "Bagging Decision Tree Accuracy for 'cvss_score': 0.6223300970873786\n",
      "K-Fold mean F1 (type): 0.7838282165585465\n",
      "K-Fold std  F1 (type): 0.007316027792375406\n",
      "K-Fold mean F1 (cvss_score): 0.5156276774678378\n",
      "K-Fold std  F1 (cvss_score): 0.010810655997815114\n",
      "\n",
      "Classification Report for 'type':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.75      0.82        28\n",
      "         1.0       0.75      0.80      0.78        50\n",
      "         2.0       0.69      0.50      0.58       103\n",
      "         3.0       0.89      0.87      0.88       200\n",
      "         4.0       0.84      0.94      0.89       834\n",
      "         5.0       0.86      0.88      0.87        41\n",
      "         6.0       0.82      0.50      0.62        36\n",
      "         7.0       0.72      0.47      0.57       155\n",
      "         8.0       0.97      0.98      0.97       176\n",
      "         9.0       1.00      1.00      1.00        14\n",
      "        10.0       0.96      0.96      0.96       423\n",
      "\n",
      "    accuracy                           0.87      2060\n",
      "   macro avg       0.85      0.79      0.81      2060\n",
      "weighted avg       0.86      0.87      0.86      2060\n",
      "\n",
      "\n",
      "Classification Report for 'cvss_score':\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.25      0.33       234\n",
      "         1.0       0.50      0.52      0.51       637\n",
      "         2.0       0.71      0.39      0.50        87\n",
      "         3.0       0.69      0.78      0.73      1102\n",
      "\n",
      "    accuracy                           0.62      2060\n",
      "   macro avg       0.60      0.48      0.52      2060\n",
      "weighted avg       0.61      0.62      0.61      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "bag_dt = BaggingClassifier(estimator=dt, n_estimators=100, random_state=42)\n",
    "multi_bag_dt = MultiOutputClassifier(bag_dt)\n",
    "\n",
    "multi_bag_dt.fit(x_train, y_train)\n",
    "y_pred = multi_bag_dt.predict(x_test)\n",
    "\n",
    "bag_dt_accuracy_type = accuracy_score(y_test['type'], y_pred[:,0])\n",
    "bag_dt_accuracy_cvss_score = accuracy_score(y_test['cvss_score'], y_pred[:,1])\n",
    "\n",
    "bag_dt_scores_type = cross_val_score(bag_dt, x , y['type'], cv=kf, scoring='f1_macro')\n",
    "bag_dt_scores_cvss_score = cross_val_score(bag_dt, x , y['cvss_score'], cv=kf, scoring='f1_macro')\n",
    "\n",
    "print(\"Bagging Decision Tree Accuracy for 'type':\", bag_dt_accuracy_type)\n",
    "print(\"Bagging Decision Tree Accuracy for 'cvss_score':\", bag_dt_accuracy_cvss_score)\n",
    "\n",
    "print(\"K-Fold mean F1 (type):\", bag_dt_scores_type.mean())\n",
    "print(\"K-Fold std  F1 (type):\", bag_dt_scores_type.std())\n",
    "\n",
    "print(\"K-Fold mean F1 (cvss_score):\", bag_dt_scores_cvss_score.mean())\n",
    "print(\"K-Fold std  F1 (cvss_score):\", bag_dt_scores_cvss_score.std())\n",
    "\n",
    "print(\"\\nClassification Report for 'type':\\n\", classification_report(y_test['type'], y_pred[:,0]))\n",
    "print(\"\\nClassification Report for 'cvss_score':\\n\", classification_report(y_test['cvss_score'], y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f6d3a93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                             Filter Method Comparison                                              </span>\n",
       "\n",
       "<span style=\"font-weight: bold\"> Algorithm          </span><span style=\"font-weight: bold\"> Type Acc </span><span style=\"font-weight: bold\"> K-Fold Mean </span><span style=\"font-weight: bold\"> K-Fold Std </span><span style=\"font-weight: bold\"> cvss_score Acc </span><span style=\"font-weight: bold\"> K-Fold Mean </span><span style=\"font-weight: bold\"> K-Fold Std </span><span style=\"font-weight: bold\"> Combined </span>\n",
       "\n",
       " <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Bagging</span>             <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.87</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.78</span>         <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.01</span>        <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.62</span>            <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.52</span>         <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.01</span>            <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.75</span> \n",
       "\n",
       " Bagged DT           0.87      0.78         0.01        0.62            0.52         0.01            0.75 \n",
       "\n",
       " Stacking            0.84      0.70         0.01        0.64            0.49         0.01            0.74 \n",
       "\n",
       " RandomForest        0.84      0.67         0.01        0.63            0.50         0.01            0.73 \n",
       "\n",
       " GradientBoosting    0.85      0.76         0.01        0.60            0.42         0.01            0.72 \n",
       "\n",
       " Soft Voting         0.82      0.61         0.02        0.63            0.42         0.02            0.72 \n",
       "\n",
       " Hard Voting         0.82      0.65         0.02        0.62            0.45         0.01            0.72 \n",
       "\n",
       " ExtraTrees          0.82      0.64         0.02        0.61            0.44         0.01            0.71 \n",
       "\n",
       " DecisionTree        0.81      0.72         0.00        0.58            0.46         0.01            0.70 \n",
       "\n",
       " AdaBoost            0.57      0.33         0.04        0.57            0.27         0.01            0.57 \n",
       "\n",
       " Bagged KNN          0.59      0.33         0.01        0.55            0.35         0.01            0.57 \n",
       "\n",
       " KNN                 0.57      0.33         0.01        0.51            0.37         0.01            0.54 \n",
       "\n",
       " HistGradientBoost  0.39      0.54         0.31        0.63            0.51         0.01            0.51 \n",
       "\n",
       " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">LogisticRegression</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.37</span>      <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.08</span>         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>        <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.54</span>            <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.23</span>         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.01</span>            <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.45</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                             Filter Method Comparison                                              \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mAlgorithm         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mType Acc\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mK-Fold Mean\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mK-Fold Std\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mcvss_score Acc\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mK-Fold Mean\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mK-Fold Std\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCombined\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " \u001b[1;32mBagging\u001b[0m             \u001b[1;32m0.87\u001b[0m      \u001b[1;32m0.78\u001b[0m         \u001b[1;32m0.01\u001b[0m        \u001b[1;32m0.62\u001b[0m            \u001b[1;32m0.52\u001b[0m         \u001b[1;32m0.01\u001b[0m            \u001b[1;32m0.75\u001b[0m \n",
       "\n",
       " Bagged DT           0.87      0.78         0.01        0.62            0.52         0.01            0.75 \n",
       "\n",
       " Stacking            0.84      0.70         0.01        0.64            0.49         0.01            0.74 \n",
       "\n",
       " RandomForest        0.84      0.67         0.01        0.63            0.50         0.01            0.73 \n",
       "\n",
       " GradientBoosting    0.85      0.76         0.01        0.60            0.42         0.01            0.72 \n",
       "\n",
       " Soft Voting         0.82      0.61         0.02        0.63            0.42         0.02            0.72 \n",
       "\n",
       " Hard Voting         0.82      0.65         0.02        0.62            0.45         0.01            0.72 \n",
       "\n",
       " ExtraTrees          0.82      0.64         0.02        0.61            0.44         0.01            0.71 \n",
       "\n",
       " DecisionTree        0.81      0.72         0.00        0.58            0.46         0.01            0.70 \n",
       "\n",
       " AdaBoost            0.57      0.33         0.04        0.57            0.27         0.01            0.57 \n",
       "\n",
       " Bagged KNN          0.59      0.33         0.01        0.55            0.35         0.01            0.57 \n",
       "\n",
       " KNN                 0.57      0.33         0.01        0.51            0.37         0.01            0.54 \n",
       "\n",
       " HistGradientBoost  0.39      0.54         0.31        0.63            0.51         0.01            0.51 \n",
       "\n",
       " \u001b[1;31mLogisticRegression\u001b[0m  \u001b[1;31m0.37\u001b[0m      \u001b[1;31m0.08\u001b[0m         \u001b[1;31m0.00\u001b[0m        \u001b[1;31m0.54\u001b[0m            \u001b[1;31m0.23\u001b[0m         \u001b[1;31m0.01\u001b[0m            \u001b[1;31m0.45\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "\n",
    "results = [\n",
    "    ['LogisticRegression', lr_accuracy_type, lr_scores_type.mean(), lr_scores_type.std(), lr_accuracy_cvss_score, lr_scores_cvss_score.mean(), lr_scores_cvss_score.std()],\n",
    "    ['DecisionTree', dt_accuracy_type, dt_scores_type.mean(), dt_scores_type.std(), dt_accuracy_cvss_score, dt_scores_cvss_score.mean(), dt_scores_cvss_score.std()],\n",
    "    ['RandomForest', rf_accuracy_type, rf_scores_type.mean(), rf_scores_type.std(), rf_accuracy_cvss_score, rf_scores_cvss_score.mean(), rf_scores_cvss_score.std()],\n",
    "    ['ExtraTrees', et_accuracy_type, et_scores_type.mean(), et_scores_type.std(), et_accuracy_cvss_score, et_scores_cvss_score.mean(), et_scores_cvss_score.std()],\n",
    "    ['GradientBoosting', gb_accuracy_type, gb_scores_type.mean(), gb_scores_type.std(), gb_accuracy_cvss_score, gb_scores_cvss_score.mean(), gb_scores_cvss_score.std()],\n",
    "    ['HistGradientBoosting', hgb_accuracy_type, hgb_scores_type.mean(), hgb_scores_type.std(), hgb_accuracy_cvss_score, hgb_scores_cvss_score.mean(), hgb_scores_cvss_score.std()],\n",
    "    ['KNN', knn_accuracy_type, knn_scores_type.mean(), knn_scores_type.std(), knn_accuracy_cvss_score, knn_scores_cvss_score.mean(), knn_scores_cvss_score.std()],\n",
    "    ['AdaBoost', ab_accuracy_type, ab_scores_type.mean(), ab_scores_type.std(), ab_accuracy_cvss_score, ab_scores_cvss_score.mean(), ab_scores_cvss_score.std()],\n",
    "    ['Bagging', bag_accuracy_type, bag_scores_type.mean(), bag_scores_type.std(), bag_accuracy_cvss_score, bag_scores_cvss_score.mean(), bag_scores_cvss_score.std()],\n",
    "    ['Hard Voting', hard_acc_type, hard_scores_type.mean(), hard_scores_type.std(), hard_acc_cvss_score, hard_scores_cvss_score.mean(), hard_scores_cvss_score.std()],\n",
    "    ['Soft Voting', soft_acc_type, soft_scores_type.mean(), soft_scores_type.std(), soft_acc_cvss_score, soft_scores_cvss_score.mean(), soft_scores_cvss_score.std()],\n",
    "    ['Stacking', stacking_acc_type, stacking_scores_type.mean(), stacking_scores_type.std(), stacking_acc_cvss_score, stacking_scores_cvss_score.mean(), stacking_scores_cvss_score.std()],\n",
    "    ['Bagged KNN', bag_knn_accuracy_type, bag_knn_scores_type.mean(), bag_knn_scores_type.std(), bag_knn_accuracy_cvss_score, bag_knn_scores_cvss_score.mean(), bag_knn_scores_cvss_score.std()],\n",
    "    ['Bagged DT', bag_dt_accuracy_type, bag_dt_scores_type.mean(), bag_dt_scores_type.std(), bag_dt_accuracy_cvss_score, bag_dt_scores_cvss_score.mean(), bag_dt_scores_cvss_score.std()],\n",
    "]\n",
    "\n",
    "\n",
    "for row in results:\n",
    "    type_acc = row[1]\n",
    "    cvss_score_acc = row[4]\n",
    "    combined = (type_acc + cvss_score_acc) / 2\n",
    "    row.append(combined)\n",
    "\n",
    "result_sorted = sorted(results, key=lambda i: i[-1], reverse=True)\n",
    "\n",
    "best_model = max(results, key=lambda x: x[-1])\n",
    "worst_model = min(results, key=lambda x: x[-1])\n",
    "\n",
    "table = Table(title=\"Filter Method Comparison\", show_lines=True)\n",
    "table.add_column(\"Algorithm\")\n",
    "table.add_column(\"Type Acc\")\n",
    "table.add_column(\"K-Fold Mean\")\n",
    "table.add_column(\"K-Fold Std\")\n",
    "table.add_column(\"cvss_score Acc\")\n",
    "table.add_column(\"K-Fold Mean\")\n",
    "table.add_column(\"K-Fold Std\")\n",
    "table.add_column(\"Combined\", justify=\"right\")\n",
    "\n",
    "for row in result_sorted:\n",
    "    algo, type_acc, kmean_type, kstd_type, cvss_score_acc, kmean_cvss_score, kstd_cvss_score, combined = row\n",
    "\n",
    "    if row == best_model:\n",
    "        table.add_row(\n",
    "            f\"[bold green]{algo}[/bold green]\",\n",
    "            f\"[bold green]{type_acc:.2f}[/bold green]\",\n",
    "            f\"[bold green]{kmean_type:.2f}[/bold green]\",\n",
    "            f\"[bold green]{kstd_type:.2f}[/bold green]\",\n",
    "            f\"[bold green]{cvss_score_acc:.2f}[/bold green]\",\n",
    "            f\"[bold green]{kmean_cvss_score:.2f}[/bold green]\",\n",
    "            f\"[bold green]{kstd_cvss_score:.2f}[/bold green]\",\n",
    "            f\"[bold green]{combined:.2f}[/bold green]\",\n",
    "        )\n",
    "    elif row == worst_model:\n",
    "        table.add_row(\n",
    "            f\"[bold red]{algo}[/bold red]\",\n",
    "            f\"[bold red]{type_acc:.2f}[/bold red]\",\n",
    "            f\"[bold red]{kmean_type:.2f}[/bold red]\",\n",
    "            f\"[bold red]{kstd_type:.2f}[/bold red]\",\n",
    "            f\"[bold red]{cvss_score_acc:.2f}[/bold red]\",\n",
    "            f\"[bold red]{kmean_cvss_score:.2f}[/bold red]\",\n",
    "            f\"[bold red]{kstd_cvss_score:.2f}[/bold red]\",\n",
    "            f\"[bold red]{combined:.2f}[/bold red]\",\n",
    "        )\n",
    "    else:\n",
    "        table.add_row(\n",
    "            algo, f\"{type_acc:.2f}\", f\"{kmean_type:.2f}\", f\"{kstd_type:.2f}\",\n",
    "            f\"{cvss_score_acc:.2f}\", f\"{kmean_cvss_score:.2f}\", f\"{kstd_cvss_score:.2f}\", f\"{combined:.2f}\"\n",
    "        )\n",
    "\n",
    "console.print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a7070111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                             Filter Method Comparison                                              </span>\n",
       "\n",
       "<span style=\"font-weight: bold\"> Algorithm          </span><span style=\"font-weight: bold\"> Type Acc </span><span style=\"font-weight: bold\"> K-Fold Mean </span><span style=\"font-weight: bold\"> K-Fold Std </span><span style=\"font-weight: bold\"> cvss_score Acc </span><span style=\"font-weight: bold\"> K-Fold Mean </span><span style=\"font-weight: bold\"> K-Fold Std </span><span style=\"font-weight: bold\"> Combined </span>\n",
       "\n",
       " <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Bagging</span>             <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.87</span>      <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.78</span>         <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.01</span>        <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.62</span>            <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.52</span>         <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.01</span>            <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.75</span> \n",
       "\n",
       " Bagged DT           0.87      0.78         0.01        0.62            0.52         0.01            0.75 \n",
       "\n",
       " Stacking            0.84      0.70         0.01        0.64            0.49         0.01            0.74 \n",
       "\n",
       " RandomForest        0.84      0.67         0.01        0.63            0.50         0.01            0.73 \n",
       "\n",
       " GradientBoosting    0.85      0.76         0.01        0.60            0.42         0.01            0.72 \n",
       "\n",
       " Soft Voting         0.82      0.61         0.02        0.63            0.42         0.02            0.72 \n",
       "\n",
       " Hard Voting         0.82      0.65         0.02        0.62            0.45         0.01            0.72 \n",
       "\n",
       " ExtraTrees          0.82      0.64         0.02        0.61            0.44         0.01            0.71 \n",
       "\n",
       " DecisionTree        0.81      0.72         0.00        0.58            0.46         0.01            0.70 \n",
       "\n",
       " AdaBoost            0.57      0.33         0.04        0.57            0.27         0.01            0.57 \n",
       "\n",
       " Bagged KNN          0.59      0.33         0.01        0.55            0.35         0.01            0.57 \n",
       "\n",
       " KNN                 0.57      0.33         0.01        0.51            0.37         0.01            0.54 \n",
       "\n",
       " HistGradientBoost  0.39      0.54         0.31        0.63            0.51         0.01            0.51 \n",
       "\n",
       " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">LogisticRegression</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.37</span>      <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.08</span>         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span>        <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.54</span>            <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.23</span>         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.01</span>            <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.45</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                             Filter Method Comparison                                              \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mAlgorithm         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mType Acc\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mK-Fold Mean\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mK-Fold Std\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mcvss_score Acc\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mK-Fold Mean\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mK-Fold Std\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCombined\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " \u001b[1;32mBagging\u001b[0m             \u001b[1;32m0.87\u001b[0m      \u001b[1;32m0.78\u001b[0m         \u001b[1;32m0.01\u001b[0m        \u001b[1;32m0.62\u001b[0m            \u001b[1;32m0.52\u001b[0m         \u001b[1;32m0.01\u001b[0m            \u001b[1;32m0.75\u001b[0m \n",
       "\n",
       " Bagged DT           0.87      0.78         0.01        0.62            0.52         0.01            0.75 \n",
       "\n",
       " Stacking            0.84      0.70         0.01        0.64            0.49         0.01            0.74 \n",
       "\n",
       " RandomForest        0.84      0.67         0.01        0.63            0.50         0.01            0.73 \n",
       "\n",
       " GradientBoosting    0.85      0.76         0.01        0.60            0.42         0.01            0.72 \n",
       "\n",
       " Soft Voting         0.82      0.61         0.02        0.63            0.42         0.02            0.72 \n",
       "\n",
       " Hard Voting         0.82      0.65         0.02        0.62            0.45         0.01            0.72 \n",
       "\n",
       " ExtraTrees          0.82      0.64         0.02        0.61            0.44         0.01            0.71 \n",
       "\n",
       " DecisionTree        0.81      0.72         0.00        0.58            0.46         0.01            0.70 \n",
       "\n",
       " AdaBoost            0.57      0.33         0.04        0.57            0.27         0.01            0.57 \n",
       "\n",
       " Bagged KNN          0.59      0.33         0.01        0.55            0.35         0.01            0.57 \n",
       "\n",
       " KNN                 0.57      0.33         0.01        0.51            0.37         0.01            0.54 \n",
       "\n",
       " HistGradientBoost  0.39      0.54         0.31        0.63            0.51         0.01            0.51 \n",
       "\n",
       " \u001b[1;31mLogisticRegression\u001b[0m  \u001b[1;31m0.37\u001b[0m      \u001b[1;31m0.08\u001b[0m         \u001b[1;31m0.00\u001b[0m        \u001b[1;31m0.54\u001b[0m            \u001b[1;31m0.23\u001b[0m         \u001b[1;31m0.01\u001b[0m            \u001b[1;31m0.45\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "temp_console = Console(record=True)\n",
    "temp_console.print(table)\n",
    "text = temp_console.export_text()\n",
    "with open('results/baseline_model.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4ac75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
